{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '056b (main experiment)  - Face Shifter 2'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, alldata, allimages, allindexpath, manipulation_type, transform = None):\n",
    "               \n",
    "        self.alldata = torch.load(alldata)\n",
    "        \n",
    "        self.folders = ['real', 'Deepfakes', 'Face2Face','FaceShifter','FaceSwap', 'NeuralTextures']\n",
    "        \n",
    "        self.transform = transform    \n",
    "        \n",
    "        print('Loading all images data')\n",
    "        \n",
    "        self.allimages = torch.load(allimages)\n",
    "        \n",
    "        print('Loading images complete')\n",
    "        \n",
    "        allindex = torch.load(allindexpath)\n",
    "        \n",
    "        self.allindex = allindex[manipulation_type]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return 1997\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        actualIndex = self.allindex[index]\n",
    "        \n",
    "        data = self.alldata[actualIndex]\n",
    "        \n",
    "        label = data['label']\n",
    "        \n",
    "        vidTensor = self.allimages[actualIndex]\n",
    "        \n",
    "        if(label != 0):\n",
    "            label = 1\n",
    "        \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "\n",
    "        return (vidTensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a8acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_types = ['real-deepfake' , 'real-f2f', 'real-faceshifter', 'real-faceswap', 'real-neuraltextures']\n",
    "\n",
    "manipulation = manipulation_types[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d14981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alldatapath = '/home/biometricgpu09/datasets/FF++/allData.pt'\n",
    "\n",
    "allimagespath = '/home/biometricgpu09/datasets/FF++/allImages.pt'\n",
    "\n",
    "allindexpath = '/home/biometricgpu09/datasets/FF++/allIndexes.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 1500\n",
    "num_samples_validation = 200\n",
    "num_samples_test = 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all images data\n",
      "Loading images complete\n"
     ]
    }
   ],
   "source": [
    "# dataset = FFClassification(rootPath, alldatapath, allimagespath,\n",
    "#                            allindexpath, manipulation, \n",
    "#                            transform = transformation)\n",
    "\n",
    "dataset = FFClassification(alldatapath, allimagespath,\n",
    "                           allindexpath, manipulation, \n",
    "                           transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "9\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.69556501 \n",
      "Epoch 1, Batch 20, Loss 0.68859819 \n",
      "Epoch 1, Batch 30, Loss 0.69556628 \n",
      "Epoch 1, Batch 40, Loss 0.69019762 \n",
      "Epoch 1, Batch 50, Loss 0.68669719 \n",
      "Epoch 1, Batch 60, Loss 0.68080152 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  3716\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.580625\n",
      "---------\n",
      "Epoch time :  36.908579\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.5e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.67199737 \n",
      "Epoch 2, Batch 20, Loss 0.65732164 \n",
      "Epoch 2, Batch 30, Loss 0.64051313 \n",
      "Epoch 2, Batch 40, Loss 0.61791681 \n",
      "Epoch 2, Batch 50, Loss 0.59699470 \n",
      "Epoch 2, Batch 60, Loss 0.56039549 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5140\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.803125\n",
      "---------\n",
      "Epoch time :  29.870077\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.025e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.52436733 \n",
      "Epoch 3, Batch 20, Loss 0.48808141 \n",
      "Epoch 3, Batch 30, Loss 0.45549949 \n",
      "Epoch 3, Batch 40, Loss 0.41615041 \n",
      "Epoch 3, Batch 50, Loss 0.38350023 \n",
      "Epoch 3, Batch 60, Loss 0.34580830 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5714\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8928125\n",
      "---------\n",
      "Epoch time :  30.068749\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.573749999999999e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.31409440 \n",
      "Epoch 4, Batch 20, Loss 0.29302553 \n",
      "Epoch 4, Batch 30, Loss 0.29804804 \n",
      "Epoch 4, Batch 40, Loss 0.28926978 \n",
      "Epoch 4, Batch 50, Loss 0.30373334 \n",
      "Epoch 4, Batch 60, Loss 0.30774782 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5779\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.90296875\n",
      "---------\n",
      "Epoch time :  29.705789\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.145062499999998e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.27696477 \n",
      "Epoch 5, Batch 20, Loss 0.28686438 \n",
      "Epoch 5, Batch 30, Loss 0.27285849 \n",
      "Epoch 5, Batch 40, Loss 0.25108804 \n",
      "Epoch 5, Batch 50, Loss 0.25021377 \n",
      "Epoch 5, Batch 60, Loss 0.21222125 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5707\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.89171875\n",
      "---------\n",
      "Epoch time :  30.469634\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.737809374999998e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.20129241 \n",
      "Epoch 6, Batch 20, Loss 0.22564300 \n",
      "Epoch 6, Batch 30, Loss 0.24197755 \n",
      "Epoch 6, Batch 40, Loss 0.20760000 \n",
      "Epoch 6, Batch 50, Loss 0.17979775 \n",
      "Epoch 6, Batch 60, Loss 0.20915710 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5613\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.87703125\n",
      "---------\n",
      "Epoch time :  30.568388\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.350918906249998e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.24636213 \n",
      "Epoch 7, Batch 20, Loss 0.21950535 \n",
      "Epoch 7, Batch 30, Loss 0.24531559 \n",
      "Epoch 7, Batch 40, Loss 0.22545325 \n",
      "Epoch 7, Batch 50, Loss 0.17176932 \n",
      "Epoch 7, Batch 60, Loss 0.19721045 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6022\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9409375\n",
      "---------\n",
      "Epoch time :  31.42104\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.983372960937497e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.17759034 \n",
      "Epoch 8, Batch 20, Loss 0.12586324 \n",
      "Epoch 8, Batch 30, Loss 0.15070038 \n",
      "Epoch 8, Batch 40, Loss 0.18787891 \n",
      "Epoch 8, Batch 50, Loss 0.20827896 \n",
      "Epoch 8, Batch 60, Loss 0.19381913 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5896\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92125\n",
      "---------\n",
      "Epoch time :  30.629684\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.634204312890622e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.19515261 \n",
      "Epoch 9, Batch 20, Loss 0.18609940 \n",
      "Epoch 9, Batch 30, Loss 0.18121226 \n",
      "Epoch 9, Batch 40, Loss 0.19862410 \n",
      "Epoch 9, Batch 50, Loss 0.13201248 \n",
      "Epoch 9, Batch 60, Loss 0.16495350 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5982\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9346875\n",
      "---------\n",
      "Epoch time :  30.24383\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.30249409724609e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.16351648 \n",
      "Epoch 10, Batch 20, Loss 0.13128771 \n",
      "Epoch 10, Batch 30, Loss 0.14235895 \n",
      "Epoch 10, Batch 40, Loss 0.13490049 \n",
      "Epoch 10, Batch 50, Loss 0.15197660 \n",
      "Epoch 10, Batch 60, Loss 0.16220516 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6031\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94234375\n",
      "---------\n",
      "Epoch time :  30.281143\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.987369392383786e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.11387735 \n",
      "Epoch 11, Batch 20, Loss 0.16879624 \n",
      "Epoch 11, Batch 30, Loss 0.14996849 \n",
      "Epoch 11, Batch 40, Loss 0.10855049 \n",
      "Epoch 11, Batch 50, Loss 0.13907072 \n",
      "Epoch 11, Batch 60, Loss 0.16327084 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5874\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9178125\n",
      "---------\n",
      "Epoch time :  30.351565\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.688000922764596e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.14064415 \n",
      "Epoch 12, Batch 20, Loss 0.16232771 \n",
      "Epoch 12, Batch 30, Loss 0.14857581 \n",
      "Epoch 12, Batch 40, Loss 0.16631062 \n",
      "Epoch 12, Batch 50, Loss 0.10003422 \n",
      "Epoch 12, Batch 60, Loss 0.16784372 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6074\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9490625\n",
      "---------\n",
      "Epoch time :  30.802163\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.4036008766263664e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.17018848 \n",
      "Epoch 13, Batch 20, Loss 0.13550888 \n",
      "Epoch 13, Batch 30, Loss 0.18899346 \n",
      "Epoch 13, Batch 40, Loss 0.15174108 \n",
      "Epoch 13, Batch 50, Loss 0.11280423 \n",
      "Epoch 13, Batch 60, Loss 0.11031141 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5953\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93015625\n",
      "---------\n",
      "Epoch time :  30.45097\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.133420832795048e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.16192451 \n",
      "Epoch 14, Batch 20, Loss 0.11617392 \n",
      "Epoch 14, Batch 30, Loss 0.11607666 \n",
      "Epoch 14, Batch 40, Loss 0.13855623 \n",
      "Epoch 14, Batch 50, Loss 0.12382757 \n",
      "Epoch 14, Batch 60, Loss 0.10844296 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6055\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94609375\n",
      "---------\n",
      "Epoch time :  30.247411\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.876749791155295e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.10624414 \n",
      "Epoch 15, Batch 20, Loss 0.14852895 \n",
      "Epoch 15, Batch 30, Loss 0.14939118 \n",
      "Epoch 15, Batch 40, Loss 0.06736752 \n",
      "Epoch 15, Batch 50, Loss 0.17760379 \n",
      "Epoch 15, Batch 60, Loss 0.11375982 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6075\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94921875\n",
      "---------\n",
      "Epoch time :  30.723036\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.6329123015975305e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.08257331 \n",
      "Epoch 16, Batch 20, Loss 0.10502746 \n",
      "Epoch 16, Batch 30, Loss 0.17388344 \n",
      "Epoch 16, Batch 40, Loss 0.11238756 \n",
      "Epoch 16, Batch 50, Loss 0.09038377 \n",
      "Epoch 16, Batch 60, Loss 0.11522523 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5799\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.90609375\n",
      "---------\n",
      "Epoch time :  31.016732\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.4012666865176535e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.08327391 \n",
      "Epoch 17, Batch 20, Loss 0.05334776 \n",
      "Epoch 17, Batch 30, Loss 0.09280654 \n",
      "Epoch 17, Batch 40, Loss 0.07795013 \n",
      "Epoch 17, Batch 50, Loss 0.13492457 \n",
      "Epoch 17, Batch 60, Loss 0.07152458 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6075\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94921875\n",
      "---------\n",
      "Epoch time :  30.813821\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.181203352191771e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.08707063 \n",
      "Epoch 18, Batch 20, Loss 0.07806993 \n",
      "Epoch 18, Batch 30, Loss 0.09946016 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 40, Loss 0.06493207 \n",
      "Epoch 18, Batch 50, Loss 0.08708057 \n",
      "Epoch 18, Batch 60, Loss 0.06918314 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6065\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94765625\n",
      "---------\n",
      "Epoch time :  30.844444\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.972143184582182e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.07566413 \n",
      "Epoch 19, Batch 20, Loss 0.08004967 \n",
      "Epoch 19, Batch 30, Loss 0.06599918 \n",
      "Epoch 19, Batch 40, Loss 0.10852347 \n",
      "Epoch 19, Batch 50, Loss 0.08188182 \n",
      "Epoch 19, Batch 60, Loss 0.07847414 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5993\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93640625\n",
      "---------\n",
      "Epoch time :  31.196267\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.7735360253530726e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.09303006 \n",
      "Epoch 20, Batch 20, Loss 0.09984055 \n",
      "Epoch 20, Batch 30, Loss 0.05653656 \n",
      "Epoch 20, Batch 40, Loss 0.07028391 \n",
      "Epoch 20, Batch 50, Loss 0.04978930 \n",
      "Epoch 20, Batch 60, Loss 0.07219690 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6033\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94265625\n",
      "---------\n",
      "Epoch time :  31.837464\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.584859224085419e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.04948954 \n",
      "Epoch 21, Batch 20, Loss 0.05302791 \n",
      "Epoch 21, Batch 30, Loss 0.09280354 \n",
      "Epoch 21, Batch 40, Loss 0.07642630 \n",
      "Epoch 21, Batch 50, Loss 0.20494795 \n",
      "Epoch 21, Batch 60, Loss 0.05082963 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6098\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9528125\n",
      "---------\n",
      "Epoch time :  31.931718\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.405616262881148e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.06359496 \n",
      "Epoch 22, Batch 20, Loss 0.09725169 \n",
      "Epoch 22, Batch 30, Loss 0.08257947 \n",
      "Epoch 22, Batch 40, Loss 0.05357597 \n",
      "Epoch 22, Batch 50, Loss 0.04844999 \n",
      "Epoch 22, Batch 60, Loss 0.05420687 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6065\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94765625\n",
      "---------\n",
      "Epoch time :  32.061758\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.2353354497370904e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.06181431 \n",
      "Epoch 23, Batch 20, Loss 0.06845696 \n",
      "Epoch 23, Batch 30, Loss 0.10735864 \n",
      "Epoch 23, Batch 40, Loss 0.07145305 \n",
      "Epoch 23, Batch 50, Loss 0.05322033 \n",
      "Epoch 23, Batch 60, Loss 0.09353390 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6097\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95265625\n",
      "---------\n",
      "Epoch time :  31.966845\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.0735686772502355e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.11817784 \n",
      "Epoch 24, Batch 20, Loss 0.06266913 \n",
      "Epoch 24, Batch 30, Loss 0.05822979 \n",
      "Epoch 24, Batch 40, Loss 0.05938190 \n",
      "Epoch 24, Batch 50, Loss 0.05935805 \n",
      "Epoch 24, Batch 60, Loss 0.07135919 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6126\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9571875\n",
      "---------\n",
      "Epoch time :  32.20984\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.9198902433877236e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.04682535 \n",
      "Epoch 25, Batch 20, Loss 0.04742300 \n",
      "Epoch 25, Batch 30, Loss 0.05731045 \n",
      "Epoch 25, Batch 40, Loss 0.11997007 \n",
      "Epoch 25, Batch 50, Loss 0.06350301 \n",
      "Epoch 25, Batch 60, Loss 0.06747469 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5970\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9328125\n",
      "---------\n",
      "Epoch time :  30.176982\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.7738957312183373e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.08886539 \n",
      "Epoch 26, Batch 20, Loss 0.05194783 \n",
      "Epoch 26, Batch 30, Loss 0.09197411 \n",
      "Epoch 26, Batch 40, Loss 0.04046401 \n",
      "Epoch 26, Batch 50, Loss 0.06229308 \n",
      "Epoch 26, Batch 60, Loss 0.06757126 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6109\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95453125\n",
      "---------\n",
      "Epoch time :  30.651236\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.6352009446574204e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.05463804 \n",
      "Epoch 27, Batch 20, Loss 0.05091425 \n",
      "Epoch 27, Batch 30, Loss 0.05544291 \n",
      "Epoch 27, Batch 40, Loss 0.08748004 \n",
      "Epoch 27, Batch 50, Loss 0.03487821 \n",
      "Epoch 27, Batch 60, Loss 0.06256170 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6091\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95171875\n",
      "---------\n",
      "Epoch time :  30.58245\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.5034408974245492e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.05588715 \n",
      "Epoch 28, Batch 20, Loss 0.09953089 \n",
      "Epoch 28, Batch 30, Loss 0.06003295 \n",
      "Epoch 28, Batch 40, Loss 0.05594293 \n",
      "Epoch 28, Batch 50, Loss 0.07162016 \n",
      "Epoch 28, Batch 60, Loss 0.04843468 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6074\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9490625\n",
      "---------\n",
      "Epoch time :  30.418972\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.3782688525533216e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.04057881 \n",
      "Epoch 29, Batch 20, Loss 0.03258351 \n",
      "Epoch 29, Batch 30, Loss 0.04953776 \n",
      "Epoch 29, Batch 40, Loss 0.03737465 \n",
      "Epoch 29, Batch 50, Loss 0.07311954 \n",
      "Epoch 29, Batch 60, Loss 0.06583303 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6068\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.948125\n",
      "---------\n",
      "Epoch time :  30.487224\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.2593554099256555e-05]\n",
      "------------------------\n",
      "Epoch 30, Batch 10, Loss 0.04212260 \n",
      "Epoch 30, Batch 20, Loss 0.06006218 \n",
      "Epoch 30, Batch 30, Loss 0.06067378 \n",
      "Epoch 30, Batch 40, Loss 0.03369170 \n",
      "Epoch 30, Batch 50, Loss 0.03443990 \n",
      "Epoch 30, Batch 60, Loss 0.07032273 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6059\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94671875\n",
      "---------\n",
      "Epoch time :  29.977739\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.1463876394293726e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  9139\n",
      "Total :  9504\n",
      "Test accuracy is  0.9615951178451179\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4350  290]\n",
      " [  75 4789]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240147642509026\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9429021460917504, 0.9845805921052632, 0.9632907573167051)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912116685926158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9615951178451179,\n",
       " 'precision': 0.9429021460917504,\n",
       " 'recall': 0.9845805921052632,\n",
       " 'f1': 0.9632907573167051,\n",
       " 'auc': 0.9912116685926158,\n",
       " 'mcc': 0.9240147642509026}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00411184 0.00719572 0.00822368 0.00884046 0.00925164\n",
      " 0.01007401 0.01069079 0.01110197 0.01171875 0.01254112 0.01377467\n",
      " 0.01398026 0.01459704 0.01480263 0.01541941 0.01603618 0.01665296\n",
      " 0.01747533 0.01809211 0.01850329 0.01912007 0.01953125 0.0207648\n",
      " 0.02179276 0.02240954 0.02261513 0.02302632 0.02323191 0.02364309\n",
      " 0.02384868 0.02446546 0.02487664 0.02528783 0.0261102  0.02693257\n",
      " 0.02713816 0.02775493 0.0285773  0.02981086 0.03001645 0.03125\n",
      " 0.03186678 0.03268914 0.03412829 0.03453947 0.03474507 0.03515625\n",
      " 0.03597862 0.03680099 0.03700658 0.03762336 0.03782895 0.03824013\n",
      " 0.03926809 0.03967928 0.04050164 0.04091283 0.04194079 0.04276316\n",
      " 0.04317434 0.04440789 0.04584704 0.04625822 0.04831414 0.04872533\n",
      " 0.04934211 0.05016447 0.05057566 0.05098684 0.05139803 0.05633224\n",
      " 0.05674342 0.05756579 0.05797697 0.05818257 0.05859375 0.05941612\n",
      " 0.0598273  0.07010691 0.07051809 0.07134046 0.07175164 0.07195724\n",
      " 0.07236842 0.07277961 0.07319079 0.07401316 0.07442434 0.07606908\n",
      " 0.07648026 0.078125   0.07853618 0.08059211 0.08100329 0.08675987\n",
      " 0.08717105 0.08737664 0.08778783 0.08799342 0.08840461 0.09210526\n",
      " 0.09251645 0.11883224 0.11924342 0.11965461 0.12006579 0.12129934\n",
      " 0.12171053 0.12438322 0.12479441 0.12623355 0.12664474 0.12890625\n",
      " 0.12931743 0.14165296 0.14206414 0.14514803 0.14555921 0.1640625\n",
      " 0.16488487 0.16550164 0.16591283 0.16652961 0.16735197 0.1848273\n",
      " 0.18523849 0.19058388 0.19099507 0.19366776 0.19407895 0.20394737\n",
      " 0.20435855 0.2057977  0.20620888 0.2082648  0.20867599 0.20949836\n",
      " 0.20990954 0.22245066 0.22286184 0.22430099 0.22471217 0.22512336\n",
      " 0.22553454 0.23149671 0.23190789 0.23416941 0.23458059 0.23910362\n",
      " 0.2395148  0.24424342 0.24465461 0.24773849 0.24773849 0.24897204\n",
      " 0.24938322 0.25       0.25041118 0.25143914 0.25185033 0.26521382\n",
      " 0.265625   0.26809211 0.26850329 0.26912007 0.26953125 0.27220395\n",
      " 0.27261513 0.27981086 0.28022204 0.28351151 0.2839227  0.28495066\n",
      " 0.28536184 0.29337993 0.29379112 0.29584704 0.29625822 0.29790296\n",
      " 0.29831414 0.30571546 0.30612664 0.30674342 0.30715461 0.30818257\n",
      " 0.30859375 0.30941612 0.3098273  0.3151727  0.31558388 0.31990132\n",
      " 0.3203125  0.32833059 0.32833059 0.32935855 0.32935855 0.32997533\n",
      " 0.33038651 0.35217928 0.35259046 0.35382401 0.35382401 0.3542352\n",
      " 0.36101974 0.36143092 0.36800987 0.36800987 0.3723273  0.3723273\n",
      " 0.37273849 0.37273849 0.37602796 0.37643914 0.38486842 0.38527961\n",
      " 0.38569079 0.38569079 0.40028783 0.40069901 0.40213816 0.40254934\n",
      " 0.41570724 0.41611842 0.42310855 0.42351974 0.44222862 0.4426398\n",
      " 0.44901316 0.44942434 0.46402138 0.46443257 0.47265625 0.47306743\n",
      " 0.47471217 0.47512336 0.47779605 0.47820724 0.47882401 0.47882401\n",
      " 0.47902961 0.47985197 0.48787007 0.48787007 0.49876645 0.49876645\n",
      " 0.50143914 0.50185033 0.51439145 0.51480263 0.51665296 0.51665296\n",
      " 0.53248355 0.53289474 0.54070724 0.54111842 0.54440789 0.54440789\n",
      " 0.55407072 0.55407072 0.55550987 0.55571546 0.56866776 0.56907895\n",
      " 0.56969572 0.56969572 0.57874178 0.57874178 0.57935855 0.57935855\n",
      " 0.58388158 0.58388158 0.59498355 0.59498355 0.59580592 0.59580592\n",
      " 0.60217928 0.60259046 0.60464638 0.60464638 0.60505757 0.60505757\n",
      " 0.60916941 0.60916941 0.61657072 0.61657072 0.62602796 0.62602796\n",
      " 0.62705592 0.62746711 0.63466283 0.63466283 0.63671875 0.63671875\n",
      " 0.63712993 0.64638158 0.64638158 0.65069901 0.65069901 0.65172697\n",
      " 0.65172697 0.65953947 0.65995066 0.67804276 0.67804276 0.68441612\n",
      " 0.68441612 0.68544408 0.68585526 0.69613487 0.69613487 0.69675164\n",
      " 0.69716283 0.69880757 0.69921875 0.70538651 0.70538651 0.73293586\n",
      " 0.73293586 0.73766447 0.73766447 0.76500822 0.76500822 0.76541941\n",
      " 0.76541941 0.7682977  0.7682977  0.77138158 0.77138158 0.7761102\n",
      " 0.77652138 0.79523026 0.79564145 0.79564145 0.81064967 0.81064967\n",
      " 0.81907895 0.81907895 0.82113487 0.82113487 0.82894737 0.82894737\n",
      " 0.83984375 0.83984375 0.84745066 0.84745066 0.85094572 0.85094572\n",
      " 0.85875822 0.85875822 0.86698191 0.86698191 0.86739309 0.86739309\n",
      " 0.87047697 0.87047697 0.87458882 0.87458882 0.87561678 0.87561678\n",
      " 0.87911184 0.87911184 0.88589638 0.88589638 0.88671875 0.88671875\n",
      " 0.88836349 0.88898026 0.89165296 0.89165296 0.89494243 0.89494243\n",
      " 0.89514803 0.89514803 0.89864309 0.89864309 0.89967105 0.89967105\n",
      " 0.90028783 0.90028783 0.9035773  0.9035773  0.90378289 0.90378289\n",
      " 0.90912829 0.90912829 0.91077303 0.91077303 0.91467928 0.91467928\n",
      " 0.9167352  0.9167352  0.91837993 0.91837993 0.91899671 0.91899671\n",
      " 0.91940789 0.91940789 0.92146382 0.92146382 0.92166941 0.92166941\n",
      " 0.921875   0.921875   0.92598684 0.92598684 0.92639803 0.92639803\n",
      " 0.92680921 0.92680921 0.92722039 0.92722039 0.92824836 0.92824836\n",
      " 0.92907072 0.92907072 0.93153783 0.93153783 0.93379934 0.93379934\n",
      " 0.93400493 0.93400493 0.93503289 0.93503289 0.93647204 0.93647204\n",
      " 0.93770559 0.93770559 0.93955592 0.93955592 0.94099507 0.94099507\n",
      " 0.94243421 0.94243421 0.94469572 0.94469572 0.94634046 0.94634046\n",
      " 0.9479852  0.9479852  0.94819079 0.94819079 0.94880757 0.94880757\n",
      " 0.94901316 0.94901316 0.9504523  0.9504523  0.95086349 0.95086349\n",
      " 0.95230263 0.95230263 0.95374178 0.95374178 0.95435855 0.95435855\n",
      " 0.95518092 0.95518092 0.95559211 0.95559211 0.9557977  0.9557977\n",
      " 0.95600329 0.95600329 0.95662007 0.95662007 0.95723684 0.95723684\n",
      " 0.95764803 0.95764803 0.95785362 0.95785362 0.95847039 0.95847039\n",
      " 0.95888158 0.95888158 0.95908717 0.95908717 0.96011513 0.96011513\n",
      " 0.96032072 0.96032072 0.96052632 0.96052632 0.96073191 0.96073191\n",
      " 0.9609375  0.9609375  0.96402138 0.96402138 0.96484375 0.96484375\n",
      " 0.96525493 0.96525493 0.96546053 0.96546053 0.96587171 0.96587171\n",
      " 0.96689967 0.96689967 0.96710526 0.96710526 0.96731086 0.96731086\n",
      " 0.96751645 0.96751645 0.96772204 0.96772204 0.96875    0.96875\n",
      " 0.96895559 0.96895559 0.96916118 0.96916118 0.96936678 0.96936678\n",
      " 0.96957237 0.96957237 0.96977796 0.96977796 0.96998355 0.96998355\n",
      " 0.97039474 0.97039474 0.97080592 0.97080592 0.97121711 0.97121711\n",
      " 0.97183388 0.97183388 0.97245066 0.97245066 0.97306743 0.97306743\n",
      " 0.97327303 0.97327303 0.97347862 0.97347862 0.97450658 0.97450658\n",
      " 0.97553454 0.97553454 0.97574013 0.97574013 0.97615132 0.97615132\n",
      " 0.97676809 0.97676809 0.97717928 0.97717928 0.97759046 0.97759046\n",
      " 0.97800164 0.97800164 0.97841283 0.97841283 0.97882401 0.97882401\n",
      " 0.97902961 0.97902961 0.9792352  0.9792352  0.97964638 0.97964638\n",
      " 0.97985197 0.97985197 0.98005757 0.98005757 0.98026316 0.98026316\n",
      " 0.98046875 0.98046875 0.98067434 0.98067434 0.98087993 0.98087993\n",
      " 0.98108553 0.98108553 0.98129112 0.98129112 0.98190789 0.98190789\n",
      " 0.98231908 0.98231908 0.98314145 0.98314145 0.98334704 0.98334704\n",
      " 0.98355263 0.98355263 0.98375822 0.98375822 0.98396382 0.98396382\n",
      " 0.98416941 0.98416941 0.984375   0.984375   0.98458059 0.98458059\n",
      " 0.98499178 0.98499178 0.98519737 0.98519737 0.98540296 0.98540296\n",
      " 0.98560855 0.98560855 0.98581414 0.98581414 0.98601974 0.98601974\n",
      " 0.98622533 0.98622533 0.98684211 0.98684211 0.9870477  0.9870477\n",
      " 0.98725329 0.98725329 0.98745888 0.98745888 0.98766447 0.98766447\n",
      " 0.98787007 0.98787007 0.98807566 0.98807566 0.98828125 0.98828125\n",
      " 0.98848684 0.98848684 0.98889803 0.98889803 0.98910362 0.98910362\n",
      " 0.98930921 0.98930921 0.9895148  0.9895148  0.98972039 0.98972039\n",
      " 0.98992599 0.98992599 0.99013158 0.99013158 0.99033717 0.99033717\n",
      " 0.99054276 0.99054276 0.99074836 0.99074836 0.99095395 0.99095395\n",
      " 0.99115954 0.99115954 0.99136513 0.99136513 0.99157072 0.99157072\n",
      " 0.99177632 0.99177632 0.99198191 0.99198191 0.9921875  0.9921875\n",
      " 0.99239309 0.99239309 0.99259868 0.99259868 0.99280428 0.99280428\n",
      " 0.99300987 0.99300987 0.99321546 0.99321546 0.99342105 0.99342105\n",
      " 0.99362664 0.99362664 0.99383224 0.99383224 0.99403783 0.99403783\n",
      " 0.99424342 0.99424342 0.99444901 0.99444901 0.99465461 0.99465461\n",
      " 0.9948602  0.9948602  0.99506579 0.99506579 0.99527138 0.99527138\n",
      " 0.99547697 0.99547697 0.99568257 0.99568257 0.99588816 0.99588816\n",
      " 0.99609375 0.99609375 0.99629934 0.99629934 0.99650493 0.99650493\n",
      " 0.99671053 0.99671053 0.99691612 0.99691612 0.99712171 0.99712171\n",
      " 0.99712171 0.99712171 0.9973273  0.9973273  0.99753289 0.99753289\n",
      " 0.99773849 0.99773849 0.99794408 0.99794408 0.99794408 0.99794408\n",
      " 0.99814967 0.99814967 0.99835526 0.99835526 0.99856086 0.99856086\n",
      " 0.99876645 0.99876645 0.99897204 0.99897204 0.99917763 0.99917763\n",
      " 0.99938322 0.99938322 0.99958882 0.99958882 0.99958882 0.99958882\n",
      " 0.99979441 0.99979441 1.         1.        ]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 2.15517241e-04 2.15517241e-04\n",
      " 2.15517241e-04 2.15517241e-04 4.31034483e-04 4.31034483e-04\n",
      " 6.46551724e-04 6.46551724e-04 6.46551724e-04 6.46551724e-04\n",
      " 6.46551724e-04 6.46551724e-04 8.62068966e-04 8.62068966e-04\n",
      " 8.62068966e-04 8.62068966e-04 8.62068966e-04 1.07758621e-03\n",
      " 1.07758621e-03 1.29310345e-03 1.29310345e-03 1.50862069e-03\n",
      " 1.50862069e-03 1.50862069e-03 1.50862069e-03 1.50862069e-03\n",
      " 1.50862069e-03 1.72413793e-03 1.72413793e-03 1.72413793e-03\n",
      " 1.72413793e-03 1.72413793e-03 1.72413793e-03 1.72413793e-03\n",
      " 1.72413793e-03 1.72413793e-03 1.72413793e-03 1.72413793e-03\n",
      " 1.72413793e-03 1.72413793e-03 1.72413793e-03 1.72413793e-03\n",
      " 1.72413793e-03 1.72413793e-03 1.72413793e-03 1.72413793e-03\n",
      " 1.72413793e-03 1.72413793e-03 1.72413793e-03 1.93965517e-03\n",
      " 1.93965517e-03 1.93965517e-03 1.93965517e-03 2.15517241e-03\n",
      " 2.15517241e-03 2.37068966e-03 2.37068966e-03 2.37068966e-03\n",
      " 2.37068966e-03 2.37068966e-03 2.37068966e-03 2.58620690e-03\n",
      " 2.58620690e-03 2.58620690e-03 2.58620690e-03 2.58620690e-03\n",
      " 2.58620690e-03 2.80172414e-03 2.80172414e-03 3.01724138e-03\n",
      " 3.01724138e-03 3.23275862e-03 3.23275862e-03 3.23275862e-03\n",
      " 3.23275862e-03 3.44827586e-03 3.44827586e-03 3.66379310e-03\n",
      " 3.66379310e-03 3.87931034e-03 3.87931034e-03 4.09482759e-03\n",
      " 4.09482759e-03 4.31034483e-03 4.31034483e-03 4.52586207e-03\n",
      " 4.52586207e-03 4.52586207e-03 4.52586207e-03 4.74137931e-03\n",
      " 4.74137931e-03 4.95689655e-03 4.95689655e-03 5.17241379e-03\n",
      " 5.17241379e-03 5.38793103e-03 5.38793103e-03 5.60344828e-03\n",
      " 5.60344828e-03 5.60344828e-03 5.60344828e-03 5.81896552e-03\n",
      " 5.81896552e-03 6.03448276e-03 6.03448276e-03 6.03448276e-03\n",
      " 6.25000000e-03 6.25000000e-03 6.46551724e-03 6.46551724e-03\n",
      " 6.68103448e-03 6.68103448e-03 6.68103448e-03 6.68103448e-03\n",
      " 6.89655172e-03 6.89655172e-03 7.11206897e-03 7.11206897e-03\n",
      " 7.11206897e-03 7.11206897e-03 7.32758621e-03 7.32758621e-03\n",
      " 7.32758621e-03 7.32758621e-03 7.32758621e-03 7.32758621e-03\n",
      " 7.54310345e-03 7.54310345e-03 7.75862069e-03 7.75862069e-03\n",
      " 7.97413793e-03 7.97413793e-03 8.18965517e-03 8.18965517e-03\n",
      " 8.40517241e-03 8.40517241e-03 8.62068966e-03 8.62068966e-03\n",
      " 8.83620690e-03 8.83620690e-03 8.83620690e-03 8.83620690e-03\n",
      " 8.83620690e-03 9.05172414e-03 9.05172414e-03 9.26724138e-03\n",
      " 9.26724138e-03 9.48275862e-03 9.48275862e-03 9.69827586e-03\n",
      " 9.69827586e-03 9.91379310e-03 9.91379310e-03 1.01293103e-02\n",
      " 1.01293103e-02 1.03448276e-02 1.03448276e-02 1.05603448e-02\n",
      " 1.05603448e-02 1.07758621e-02 1.07758621e-02 1.09913793e-02\n",
      " 1.09913793e-02 1.12068966e-02 1.12068966e-02 1.14224138e-02\n",
      " 1.14224138e-02 1.16379310e-02 1.16379310e-02 1.18534483e-02\n",
      " 1.18534483e-02 1.20689655e-02 1.20689655e-02 1.22844828e-02\n",
      " 1.22844828e-02 1.25000000e-02 1.25000000e-02 1.25000000e-02\n",
      " 1.25000000e-02 1.27155172e-02 1.27155172e-02 1.29310345e-02\n",
      " 1.29310345e-02 1.31465517e-02 1.31465517e-02 1.33620690e-02\n",
      " 1.33620690e-02 1.35775862e-02 1.35775862e-02 1.37931034e-02\n",
      " 1.37931034e-02 1.40086207e-02 1.40086207e-02 1.42241379e-02\n",
      " 1.42241379e-02 1.44396552e-02 1.44396552e-02 1.46551724e-02\n",
      " 1.46551724e-02 1.48706897e-02 1.48706897e-02 1.50862069e-02\n",
      " 1.50862069e-02 1.55172414e-02 1.55172414e-02 1.57327586e-02\n",
      " 1.57327586e-02 1.61637931e-02 1.61637931e-02 1.63793103e-02\n",
      " 1.63793103e-02 1.65948276e-02 1.65948276e-02 1.68103448e-02\n",
      " 1.68103448e-02 1.70258621e-02 1.70258621e-02 1.72413793e-02\n",
      " 1.72413793e-02 1.76724138e-02 1.76724138e-02 1.78879310e-02\n",
      " 1.78879310e-02 1.81034483e-02 1.81034483e-02 1.83189655e-02\n",
      " 1.83189655e-02 1.85344828e-02 1.85344828e-02 1.89655172e-02\n",
      " 1.89655172e-02 1.98275862e-02 1.98275862e-02 2.00431034e-02\n",
      " 2.00431034e-02 2.02586207e-02 2.02586207e-02 2.04741379e-02\n",
      " 2.04741379e-02 2.09051724e-02 2.09051724e-02 2.11206897e-02\n",
      " 2.11206897e-02 2.13362069e-02 2.13362069e-02 2.15517241e-02\n",
      " 2.15517241e-02 2.17672414e-02 2.17672414e-02 2.19827586e-02\n",
      " 2.19827586e-02 2.21982759e-02 2.21982759e-02 2.24137931e-02\n",
      " 2.24137931e-02 2.34913793e-02 2.34913793e-02 2.37068966e-02\n",
      " 2.37068966e-02 2.39224138e-02 2.39224138e-02 2.43534483e-02\n",
      " 2.43534483e-02 2.45689655e-02 2.45689655e-02 2.47844828e-02\n",
      " 2.47844828e-02 2.52155172e-02 2.52155172e-02 2.54310345e-02\n",
      " 2.54310345e-02 2.56465517e-02 2.56465517e-02 2.60775862e-02\n",
      " 2.60775862e-02 2.62931034e-02 2.62931034e-02 2.67241379e-02\n",
      " 2.67241379e-02 2.69396552e-02 2.69396552e-02 2.73706897e-02\n",
      " 2.73706897e-02 2.75862069e-02 2.75862069e-02 2.80172414e-02\n",
      " 2.80172414e-02 2.84482759e-02 2.84482759e-02 2.88793103e-02\n",
      " 2.88793103e-02 2.90948276e-02 2.90948276e-02 3.01724138e-02\n",
      " 3.01724138e-02 3.06034483e-02 3.06034483e-02 3.08189655e-02\n",
      " 3.08189655e-02 3.12500000e-02 3.12500000e-02 3.18965517e-02\n",
      " 3.18965517e-02 3.21120690e-02 3.21120690e-02 3.27586207e-02\n",
      " 3.27586207e-02 3.31896552e-02 3.31896552e-02 3.34051724e-02\n",
      " 3.34051724e-02 3.36206897e-02 3.36206897e-02 3.38362069e-02\n",
      " 3.38362069e-02 3.40517241e-02 3.40517241e-02 3.46982759e-02\n",
      " 3.46982759e-02 3.51293103e-02 3.51293103e-02 3.53448276e-02\n",
      " 3.53448276e-02 3.62068966e-02 3.62068966e-02 3.64224138e-02\n",
      " 3.64224138e-02 3.72844828e-02 3.72844828e-02 3.75000000e-02\n",
      " 3.75000000e-02 3.77155172e-02 3.77155172e-02 3.79310345e-02\n",
      " 3.79310345e-02 3.81465517e-02 3.81465517e-02 3.90086207e-02\n",
      " 3.90086207e-02 3.96551724e-02 3.96551724e-02 4.09482759e-02\n",
      " 4.09482759e-02 4.11637931e-02 4.11637931e-02 4.24568966e-02\n",
      " 4.24568966e-02 4.28879310e-02 4.28879310e-02 4.37500000e-02\n",
      " 4.37500000e-02 4.39655172e-02 4.39655172e-02 4.43965517e-02\n",
      " 4.43965517e-02 4.46120690e-02 4.46120690e-02 4.54741379e-02\n",
      " 4.54741379e-02 4.56896552e-02 4.56896552e-02 4.59051724e-02\n",
      " 4.59051724e-02 4.63362069e-02 4.63362069e-02 4.76293103e-02\n",
      " 4.76293103e-02 4.80603448e-02 4.80603448e-02 4.93534483e-02\n",
      " 4.93534483e-02 4.95689655e-02 4.95689655e-02 4.97844828e-02\n",
      " 4.97844828e-02 5.00000000e-02 5.00000000e-02 5.15086207e-02\n",
      " 5.15086207e-02 5.19396552e-02 5.19396552e-02 5.21551724e-02\n",
      " 5.21551724e-02 5.28017241e-02 5.28017241e-02 5.30172414e-02\n",
      " 5.30172414e-02 5.32327586e-02 5.32327586e-02 5.51724138e-02\n",
      " 5.51724138e-02 5.53879310e-02 5.53879310e-02 5.58189655e-02\n",
      " 5.58189655e-02 5.73275862e-02 5.73275862e-02 5.86206897e-02\n",
      " 5.86206897e-02 5.88362069e-02 5.88362069e-02 5.92672414e-02\n",
      " 5.92672414e-02 6.07758621e-02 6.07758621e-02 6.16379310e-02\n",
      " 6.16379310e-02 6.18534483e-02 6.18534483e-02 6.25000000e-02\n",
      " 6.25000000e-02 6.57327586e-02 6.57327586e-02 6.63793103e-02\n",
      " 6.63793103e-02 6.83189655e-02 6.83189655e-02 6.96120690e-02\n",
      " 6.96120690e-02 7.04741379e-02 7.04741379e-02 7.06896552e-02\n",
      " 7.06896552e-02 7.19827586e-02 7.19827586e-02 7.28448276e-02\n",
      " 7.28448276e-02 7.65086207e-02 7.65086207e-02 7.69396552e-02\n",
      " 7.69396552e-02 7.73706897e-02 7.73706897e-02 7.99568966e-02\n",
      " 7.99568966e-02 8.06034483e-02 8.06034483e-02 8.12500000e-02\n",
      " 8.12500000e-02 8.16810345e-02 8.16810345e-02 8.31896552e-02\n",
      " 8.31896552e-02 8.51293103e-02 8.51293103e-02 8.53448276e-02\n",
      " 8.53448276e-02 8.98706897e-02 8.98706897e-02 9.00862069e-02\n",
      " 9.00862069e-02 9.11637931e-02 9.11637931e-02 9.24568966e-02\n",
      " 9.24568966e-02 9.26724138e-02 9.26724138e-02 9.67672414e-02\n",
      " 9.67672414e-02 9.76293103e-02 9.76293103e-02 1.04525862e-01\n",
      " 1.04525862e-01 1.06681034e-01 1.06681034e-01 1.09051724e-01\n",
      " 1.09051724e-01 1.16163793e-01 1.16163793e-01 1.16810345e-01\n",
      " 1.16810345e-01 1.19827586e-01 1.19827586e-01 1.21120690e-01\n",
      " 1.21120690e-01 1.25215517e-01 1.25215517e-01 1.26293103e-01\n",
      " 1.26293103e-01 1.27586207e-01 1.27586207e-01 1.30603448e-01\n",
      " 1.30603448e-01 1.32327586e-01 1.32327586e-01 1.33189655e-01\n",
      " 1.33189655e-01 1.35775862e-01 1.35775862e-01 1.37284483e-01\n",
      " 1.37284483e-01 1.43750000e-01 1.43750000e-01 1.48491379e-01\n",
      " 1.48491379e-01 1.56465517e-01 1.56465517e-01 1.68965517e-01\n",
      " 1.68965517e-01 1.73706897e-01 1.73706897e-01 1.81465517e-01\n",
      " 1.81465517e-01 1.85129310e-01 1.85129310e-01 1.96767241e-01\n",
      " 1.96767241e-01 2.12284483e-01 2.12284483e-01 2.51293103e-01\n",
      " 2.51293103e-01 2.62715517e-01 2.62715517e-01 3.45905172e-01\n",
      " 3.45905172e-01 3.79310345e-01 3.79310345e-01 3.98706897e-01\n",
      " 3.98706897e-01 4.15517241e-01 4.15517241e-01 4.60344828e-01\n",
      " 4.60344828e-01 4.69181034e-01 4.69612069e-01 4.96120690e-01\n",
      " 4.96120690e-01 5.19827586e-01 5.19827586e-01 5.26293103e-01\n",
      " 5.26293103e-01 5.49137931e-01 5.49137931e-01 5.53663793e-01\n",
      " 5.54094828e-01 5.54525862e-01 5.54525862e-01 5.55387931e-01\n",
      " 5.55387931e-01 6.30818966e-01 6.30818966e-01 6.59698276e-01\n",
      " 6.59698276e-01 6.74784483e-01 6.74784483e-01 6.80387931e-01\n",
      " 6.80387931e-01 7.44612069e-01 7.44612069e-01 7.57543103e-01\n",
      " 7.57543103e-01 7.79741379e-01 7.80172414e-01 8.62068966e-01\n",
      " 8.62068966e-01 8.73706897e-01 8.73706897e-01 1.00000000e+00]\n",
      "748\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9ef9c19d10>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f118576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

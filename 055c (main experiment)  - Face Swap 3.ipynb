{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '055b (main experiment)  - Face Swap 2'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, alldata, allimages, allindexpath, manipulation_type, transform = None):\n",
    "               \n",
    "        self.alldata = torch.load(alldata)\n",
    "        \n",
    "        self.folders = ['real', 'Deepfakes', 'Face2Face','FaceShifter','FaceSwap', 'NeuralTextures']\n",
    "        \n",
    "        self.transform = transform    \n",
    "        \n",
    "        print('Loading all images data')\n",
    "        \n",
    "        self.allimages = torch.load(allimages)\n",
    "        \n",
    "        print('Loading images complete')\n",
    "        \n",
    "        allindex = torch.load(allindexpath)\n",
    "        \n",
    "        self.allindex = allindex[manipulation_type]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return 1997\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        actualIndex = self.allindex[index]\n",
    "        \n",
    "        data = self.alldata[actualIndex]\n",
    "        \n",
    "        label = data['label']\n",
    "        \n",
    "        vidTensor = self.allimages[actualIndex]\n",
    "        \n",
    "        if(label != 0):\n",
    "            label = 1\n",
    "        \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "\n",
    "        return (vidTensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a8acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_types = ['real-deepfake' , 'real-f2f', 'real-faceshifter', 'real-faceswap', 'real-neuraltextures']\n",
    "\n",
    "manipulation = manipulation_types[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d14981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alldatapath = '/home/biometricgpu09/datasets/FF++/allData.pt'\n",
    "\n",
    "allimagespath = '/home/biometricgpu09/datasets/FF++/allImages.pt'\n",
    "\n",
    "allindexpath = '/home/biometricgpu09/datasets/FF++/allIndexes.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 1500\n",
    "num_samples_validation = 200\n",
    "num_samples_test = 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all images data\n",
      "Loading images complete\n"
     ]
    }
   ],
   "source": [
    "# dataset = FFClassification(rootPath, alldatapath, allimagespath,\n",
    "#                            allindexpath, manipulation, \n",
    "#                            transform = transformation)\n",
    "\n",
    "dataset = FFClassification(alldatapath, allimagespath,\n",
    "                           allindexpath, manipulation, \n",
    "                           transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "9\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.69290177 \n",
      "Epoch 1, Batch 20, Loss 0.69484660 \n",
      "Epoch 1, Batch 30, Loss 0.69284240 \n",
      "Epoch 1, Batch 40, Loss 0.69374935 \n",
      "Epoch 1, Batch 50, Loss 0.69282824 \n",
      "Epoch 1, Batch 60, Loss 0.69065192 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  3346\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.5228125\n",
      "---------\n",
      "Epoch time :  35.664215\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.5e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.68919092 \n",
      "Epoch 2, Batch 20, Loss 0.68898760 \n",
      "Epoch 2, Batch 30, Loss 0.68463287 \n",
      "Epoch 2, Batch 40, Loss 0.67713146 \n",
      "Epoch 2, Batch 50, Loss 0.66619807 \n",
      "Epoch 2, Batch 60, Loss 0.66234360 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4422\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.6909375\n",
      "---------\n",
      "Epoch time :  29.34172\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.025e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.63806657 \n",
      "Epoch 3, Batch 20, Loss 0.61555399 \n",
      "Epoch 3, Batch 30, Loss 0.60064624 \n",
      "Epoch 3, Batch 40, Loss 0.57876300 \n",
      "Epoch 3, Batch 50, Loss 0.52787917 \n",
      "Epoch 3, Batch 60, Loss 0.50816921 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  3878\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.6059375\n",
      "---------\n",
      "Epoch time :  29.499837\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.573749999999999e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.46787505 \n",
      "Epoch 4, Batch 20, Loss 0.43607015 \n",
      "Epoch 4, Batch 30, Loss 0.39867486 \n",
      "Epoch 4, Batch 40, Loss 0.40332414 \n",
      "Epoch 4, Batch 50, Loss 0.37531936 \n",
      "Epoch 4, Batch 60, Loss 0.41439847 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4571\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.71421875\n",
      "---------\n",
      "Epoch time :  29.585801\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.145062499999998e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.34683015 \n",
      "Epoch 5, Batch 20, Loss 0.39027421 \n",
      "Epoch 5, Batch 30, Loss 0.35007107 \n",
      "Epoch 5, Batch 40, Loss 0.33776124 \n",
      "Epoch 5, Batch 50, Loss 0.33554537 \n",
      "Epoch 5, Batch 60, Loss 0.33973881 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5272\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.82375\n",
      "---------\n",
      "Epoch time :  29.753972\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.737809374999998e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.33713826 \n",
      "Epoch 6, Batch 20, Loss 0.29219477 \n",
      "Epoch 6, Batch 30, Loss 0.27632584 \n",
      "Epoch 6, Batch 40, Loss 0.28558574 \n",
      "Epoch 6, Batch 50, Loss 0.25590567 \n",
      "Epoch 6, Batch 60, Loss 0.33082581 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4255\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.66484375\n",
      "---------\n",
      "Epoch time :  29.635555\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.350918906249998e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.30566698 \n",
      "Epoch 7, Batch 20, Loss 0.26895378 \n",
      "Epoch 7, Batch 30, Loss 0.34977059 \n",
      "Epoch 7, Batch 40, Loss 0.24136828 \n",
      "Epoch 7, Batch 50, Loss 0.23446114 \n",
      "Epoch 7, Batch 60, Loss 0.24084305 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5993\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93640625\n",
      "---------\n",
      "Epoch time :  29.698607\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.983372960937497e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.25737213 \n",
      "Epoch 8, Batch 20, Loss 0.22787009 \n",
      "Epoch 8, Batch 30, Loss 0.28921693 \n",
      "Epoch 8, Batch 40, Loss 0.20938995 \n",
      "Epoch 8, Batch 50, Loss 0.20686106 \n",
      "Epoch 8, Batch 60, Loss 0.24376675 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5329\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.83265625\n",
      "---------\n",
      "Epoch time :  29.356518\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.634204312890622e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.19578604 \n",
      "Epoch 9, Batch 20, Loss 0.20458985 \n",
      "Epoch 9, Batch 30, Loss 0.17598196 \n",
      "Epoch 9, Batch 40, Loss 0.23317800 \n",
      "Epoch 9, Batch 50, Loss 0.22783749 \n",
      "Epoch 9, Batch 60, Loss 0.28778734 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6109\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95453125\n",
      "---------\n",
      "Epoch time :  29.284156\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.30249409724609e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.19206744 \n",
      "Epoch 10, Batch 20, Loss 0.16844879 \n",
      "Epoch 10, Batch 30, Loss 0.17896719 \n",
      "Epoch 10, Batch 40, Loss 0.25009532 \n",
      "Epoch 10, Batch 50, Loss 0.18066685 \n",
      "Epoch 10, Batch 60, Loss 0.26772091 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4501\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.70328125\n",
      "---------\n",
      "Epoch time :  29.501968\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.987369392383786e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.19453829 \n",
      "Epoch 11, Batch 20, Loss 0.24024305 \n",
      "Epoch 11, Batch 30, Loss 0.17583956 \n",
      "Epoch 11, Batch 40, Loss 0.20885035 \n",
      "Epoch 11, Batch 50, Loss 0.20593539 \n",
      "Epoch 11, Batch 60, Loss 0.22859677 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6078\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9496875\n",
      "---------\n",
      "Epoch time :  29.450311\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.688000922764596e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.18208563 \n",
      "Epoch 12, Batch 20, Loss 0.17661995 \n",
      "Epoch 12, Batch 30, Loss 0.14461372 \n",
      "Epoch 12, Batch 40, Loss 0.23277235 \n",
      "Epoch 12, Batch 50, Loss 0.18342655 \n",
      "Epoch 12, Batch 60, Loss 0.18717613 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6123\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95671875\n",
      "---------\n",
      "Epoch time :  29.475783\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.4036008766263664e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.17009761 \n",
      "Epoch 13, Batch 20, Loss 0.16405149 \n",
      "Epoch 13, Batch 30, Loss 0.14474360 \n",
      "Epoch 13, Batch 40, Loss 0.16237236 \n",
      "Epoch 13, Batch 50, Loss 0.23037699 \n",
      "Epoch 13, Batch 60, Loss 0.17210184 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5993\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93640625\n",
      "---------\n",
      "Epoch time :  29.716352\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.133420832795048e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.16288642 \n",
      "Epoch 14, Batch 20, Loss 0.17020141 \n",
      "Epoch 14, Batch 30, Loss 0.15204585 \n",
      "Epoch 14, Batch 40, Loss 0.19142625 \n",
      "Epoch 14, Batch 50, Loss 0.20569577 \n",
      "Epoch 14, Batch 60, Loss 0.17997422 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6058\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9465625\n",
      "---------\n",
      "Epoch time :  29.760346\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.876749791155295e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.10141945 \n",
      "Epoch 15, Batch 20, Loss 0.13421092 \n",
      "Epoch 15, Batch 30, Loss 0.17791649 \n",
      "Epoch 15, Batch 40, Loss 0.19692754 \n",
      "Epoch 15, Batch 50, Loss 0.19251806 \n",
      "Epoch 15, Batch 60, Loss 0.17585806 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5989\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93578125\n",
      "---------\n",
      "Epoch time :  29.647918\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.6329123015975305e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.13279164 \n",
      "Epoch 16, Batch 20, Loss 0.13314495 \n",
      "Epoch 16, Batch 30, Loss 0.12681658 \n",
      "Epoch 16, Batch 40, Loss 0.15318126 \n",
      "Epoch 16, Batch 50, Loss 0.17551527 \n",
      "Epoch 16, Batch 60, Loss 0.11869120 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6085\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95078125\n",
      "---------\n",
      "Epoch time :  29.547529\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.4012666865176535e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.13007982 \n",
      "Epoch 17, Batch 20, Loss 0.17068594 \n",
      "Epoch 17, Batch 30, Loss 0.11163603 \n",
      "Epoch 17, Batch 40, Loss 0.10539336 \n",
      "Epoch 17, Batch 50, Loss 0.16186815 \n",
      "Epoch 17, Batch 60, Loss 0.13150004 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5297\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.82765625\n",
      "---------\n",
      "Epoch time :  29.297248\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.181203352191771e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.14000962 \n",
      "Epoch 18, Batch 20, Loss 0.12522367 \n",
      "Epoch 18, Batch 30, Loss 0.17321966 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 40, Loss 0.09438939 \n",
      "Epoch 18, Batch 50, Loss 0.13508030 \n",
      "Epoch 18, Batch 60, Loss 0.10413669 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6111\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95484375\n",
      "---------\n",
      "Epoch time :  29.469262\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.972143184582182e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.14466717 \n",
      "Epoch 19, Batch 20, Loss 0.08726718 \n",
      "Epoch 19, Batch 30, Loss 0.10652189 \n",
      "Epoch 19, Batch 40, Loss 0.12442801 \n",
      "Epoch 19, Batch 50, Loss 0.08591629 \n",
      "Epoch 19, Batch 60, Loss 0.13927145 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6089\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95140625\n",
      "---------\n",
      "Epoch time :  29.408196\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.7735360253530726e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.09930500 \n",
      "Epoch 20, Batch 20, Loss 0.11992644 \n",
      "Epoch 20, Batch 30, Loss 0.12425718 \n",
      "Epoch 20, Batch 40, Loss 0.11384807 \n",
      "Epoch 20, Batch 50, Loss 0.10469546 \n",
      "Epoch 20, Batch 60, Loss 0.08409017 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5976\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93375\n",
      "---------\n",
      "Epoch time :  29.477677\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.584859224085419e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.09303579 \n",
      "Epoch 21, Batch 20, Loss 0.07421593 \n",
      "Epoch 21, Batch 30, Loss 0.14063978 \n",
      "Epoch 21, Batch 40, Loss 0.08655215 \n",
      "Epoch 21, Batch 50, Loss 0.07068211 \n",
      "Epoch 21, Batch 60, Loss 0.11368028 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5735\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.89609375\n",
      "---------\n",
      "Epoch time :  29.35061\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.405616262881148e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.12065268 \n",
      "Epoch 22, Batch 20, Loss 0.12332807 \n",
      "Epoch 22, Batch 30, Loss 0.18790793 \n",
      "Epoch 22, Batch 40, Loss 0.10118464 \n",
      "Epoch 22, Batch 50, Loss 0.10196886 \n",
      "Epoch 22, Batch 60, Loss 0.10398902 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6164\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.963125\n",
      "---------\n",
      "Epoch time :  29.608573\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.2353354497370904e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.09275186 \n",
      "Epoch 23, Batch 20, Loss 0.13281671 \n",
      "Epoch 23, Batch 30, Loss 0.11138205 \n",
      "Epoch 23, Batch 40, Loss 0.10114272 \n",
      "Epoch 23, Batch 50, Loss 0.06906971 \n",
      "Epoch 23, Batch 60, Loss 0.09604893 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6144\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.96\n",
      "---------\n",
      "Epoch time :  29.509856\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.0735686772502355e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.06884424 \n",
      "Epoch 24, Batch 20, Loss 0.09874101 \n",
      "Epoch 24, Batch 30, Loss 0.09453123 \n",
      "Epoch 24, Batch 40, Loss 0.09996026 \n",
      "Epoch 24, Batch 50, Loss 0.07534748 \n",
      "Epoch 24, Batch 60, Loss 0.08440269 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6185\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.96640625\n",
      "---------\n",
      "Epoch time :  29.410806\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.9198902433877236e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.08614151 \n",
      "Epoch 25, Batch 20, Loss 0.06673288 \n",
      "Epoch 25, Batch 30, Loss 0.07414157 \n",
      "Epoch 25, Batch 40, Loss 0.16376591 \n",
      "Epoch 25, Batch 50, Loss 0.07964875 \n",
      "Epoch 25, Batch 60, Loss 0.10734673 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6148\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.960625\n",
      "---------\n",
      "Epoch time :  29.590642\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.7738957312183373e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.08241316 \n",
      "Epoch 26, Batch 20, Loss 0.06719158 \n",
      "Epoch 26, Batch 30, Loss 0.08201245 \n",
      "Epoch 26, Batch 40, Loss 0.07314298 \n",
      "Epoch 26, Batch 50, Loss 0.09561719 \n",
      "Epoch 26, Batch 60, Loss 0.05685500 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6204\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.969375\n",
      "---------\n",
      "Epoch time :  29.380527\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.6352009446574204e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.08794642 \n",
      "Epoch 27, Batch 20, Loss 0.07785960 \n",
      "Epoch 27, Batch 30, Loss 0.06169104 \n",
      "Epoch 27, Batch 40, Loss 0.07388709 \n",
      "Epoch 27, Batch 50, Loss 0.05841900 \n",
      "Epoch 27, Batch 60, Loss 0.11204727 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6117\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95578125\n",
      "---------\n",
      "Epoch time :  29.496624\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.5034408974245492e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.06202405 \n",
      "Epoch 28, Batch 20, Loss 0.06959607 \n",
      "Epoch 28, Batch 30, Loss 0.08386165 \n",
      "Epoch 28, Batch 40, Loss 0.06699202 \n",
      "Epoch 28, Batch 50, Loss 0.07104590 \n",
      "Epoch 28, Batch 60, Loss 0.07294962 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6072\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94875\n",
      "---------\n",
      "Epoch time :  29.741671\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.3782688525533216e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.06649201 \n",
      "Epoch 29, Batch 20, Loss 0.06473396 \n",
      "Epoch 29, Batch 30, Loss 0.08876841 \n",
      "Epoch 29, Batch 40, Loss 0.10152366 \n",
      "Epoch 29, Batch 50, Loss 0.07287575 \n",
      "Epoch 29, Batch 60, Loss 0.05790087 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6172\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.964375\n",
      "---------\n",
      "Epoch time :  30.169271\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.2593554099256555e-05]\n",
      "------------------------\n",
      "Epoch 30, Batch 10, Loss 0.05734631 \n",
      "Epoch 30, Batch 20, Loss 0.07814005 \n",
      "Epoch 30, Batch 30, Loss 0.06421971 \n",
      "Epoch 30, Batch 40, Loss 0.06767516 \n",
      "Epoch 30, Batch 50, Loss 0.07939723 \n",
      "Epoch 30, Batch 60, Loss 0.06001765 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6184\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.96625\n",
      "---------\n",
      "Epoch time :  30.258271\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.1463876394293726e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  9072\n",
      "Total :  9504\n",
      "Test accuracy is  0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4551  153]\n",
      " [ 279 4521]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD6CAYAAAB9N4akAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAj2ElEQVR4nO3debxWVb3H8c83BMWJwSkFDS3Uq5ZoipY2qDecxdK6ZiUON0qwwcyxFIesnMtUFEdI08gsyetNUbTMrgoIgqDkySEhFZXJKZFzfvePvQ49Aud59oHznLPZ5/v2tV7P3r89rQeOv7NYe+21FRGYmVmxfKCjK2BmZstzcjYzKyAnZzOzAnJyNjMrICdnM7MCcnI2MysgJ2czsyokdZE0RdJdaf0mSc9JmprKgBSXpMslNUiaJmnninMMkfRMKkPyXHeNunybCu+99qwHUttyum/2qY6ughXQksVztKrnaE3O6brhVnmu9x3gKWD9itjJEXH7MvvtD/RPZTdgJLCbpN7ACGAXIIDJksZFxPxqF3XL2czKpakxf6lBUl/gQOC6HFceDIyJzCNAT0mbAvsC4yNiXkrI44H9ap3MydnMyiWa8pfafgacAiy78/mp6+IySWumWB/gxYp9ZqdYS/GqnJzNrFyamnIXSUMlTaooQ5tPI+kgYG5ETF7mCqcD2wK7Ar2BU+vxNere52xm1p4iX4s47RujgFEtbN4DOETSAcBawPqSbo6Ir6bt70q6Efh+Wp8DbF5xfN8UmwN8dpn4g7Xq5pazmZVL45L8pYqIOD0i+kZEP+AIYEJEfDX1IyNJwKHAk+mQccBRadTG7sDCiHgJuAcYJKmXpF7AoBSryi1nMyuXHDf6VtEtkjYCBEwFvpnidwMHAA3A28AxABExT9J5wMS037kRMa/WRVTvKUM9lM5WxEPpbEXaYijd4ucn5c453frtssrXqxe3nM2sXJry9zkXmZOzmZVKa24IFpmTs5mVi1vOZmYF1PheR9egTTg5m1m5uFvDzKyA3K1hZlZAbjmbmRWQW85mZsUTTb4haGZWPG45m5kVkPuczcwKqP4TH7ULJ2czKxe3nM3MCsh9zmZmBVRjEv3VhZOzmZVLSVrOfk2VmZVKRGPukoekLpKmSLorrW8p6VFJDZJ+Lalbiq+Z1hvS9n4V5zg9xWdJ2jfPdZ2czaxcWvH27Zy+AzxVsX4BcFlEfASYDxyX4scB81P8srQfkrYjewfh9sB+wFWSutS6qJOzmZVLNOUvNUjqCxwIXJfWBewN3J52GU32kleAwWmdtH2ftP9g4LaIeDciniN7x+DAWtd2cjazcmnblvPPgFOA5p03ABZERPNdx9lAn7TcB3gRIG1fmPZfGl/BMS1ycjazcmlckrtIGippUkUZ2nwaSQcBcyNickd8DY/WMLNyacVDKBExChjVwuY9gEMkHQCsBawP/BzoKWmN1DruC8xJ+88BNgdmS1oD6AG8XhFvVnlMi9xyNrNyaaNujYg4PSL6RkQ/sht6EyLiK8ADwOFptyHAnWl5XFonbZ8QEZHiR6TRHFsC/YHHan0Nt5zNrFzqP875VOA2ST8CpgDXp/j1wC8lNQDzyBI6ETFD0lhgJrAEGB45xvE5OZtZudRhbo2IeBB4MC0/ywpGW0TEv4AvtnD8+cD5rbmmk7OZlYsf3zYzK6CSPL7t5Gxm5eIpQ83MCsgtZzOzAuoMyVnS96ptj4hL27Y6ZmarKKKja9AmarWc12uXWpiZtZUlnWC0RkSc014VMTNrE53phqCktcjmKt2e7BlzACLi2DrVy8xs5ZSkzznv3Bq/BD4I7Av8iWzijjfqVSkzs5UWkb8UWN7k/JGIOBN4KyJGk00+vVv9qmVmtpLa/k0oHSLvULr30ucCSTsALwMb16dKZmaroOBJN6+8yXmUpF7AmWTT360LnFW3WpmZraRozPfi1qLLlZwj4rq0+Cdgq/pVx8xsFXWmlrOkNYHDgH6Vx0TEufWplpnZSupMQ+nIZvpfCEwG3q1fdczMVlFTsUdh5JU3OfeNiP3qWhMzs7bQRt0a6fmOPwNrkuXK2yNihKSbgM+QNVgBjo6IqZJE9o7BA4C3U/zxdK4hwA/T/j9Ko96qyjuU7q+SPppz306nsbGRw48ezrCTRwDwgx9dwr6HH81hQ4Zz2JDhPP23vwPw2OPT2H3QYUvjI2+4Zek5fvjjS/n0gUdw6Fe/2SHfwern2lGX8M/ZTzB1yv1LY2ed+T1eeG4Skybey6SJ97L/fnsDsOsuA5bGJk8az+DBbhO1WmNj/lLdu8DeEbEjMADYT9LuadvJETEglakptj/Z+wH7A0OBkQCSegMjyIYfDwRGpAEWVeVtOe8JHC3puVRhARERH8t5fKnd/Js72arfFrz51ttLYycNP45Be31quX133nEHrrpo+afiDz3gcxx52CGccd7Fda2rtb8xY8Zy1VU3cuONP39f/OeXX8ull13zvtiTM55mt933p7GxkQ9+cGMenzSeu+4aT2NJRiC0izZqOaeXs76ZVrumUq3PZDAwJh33iKSekjYFPguMj4h5AJLGA/sBt1a7ft6Wc/NvhEHAwcBB6bPTe3nuq/z5r49x2MH7rtJ5dhnwUXqs73mmyuihvzzKvPkLcu37zjv/WpqI11prTaLgT7EVUlPkLpKGSppUUYZWnkpSF0lTgblkCfbRtOl8SdMkXZYGTAD0AV6sOHx2irUUr6pqcpa0flp8o4XS6V3w82v43rDjkN7/R3n5NaP5/FHHc8HPr2Hx4sVL4088+RRfGDKMb550Jg3PvtDe1bUCGXb8MTw+eTzXjrqEnj17LI0P3HUnnpg6gamP38+wE05zq7m1oil3iYhREbFLRRn1vlNFNEbEALIpKwamh/BOB7YFdgV6k72Nu83Vajn/Kn1OBialz8kV653agw8/Su9ePdl+2/7vi3/3m8fwh1uv5dfX/ZyFi97g+pt/A8B223yY8b8dzR2jr+LIww7m26d7JGJndfU1Y9h620/y8V0G8fLLc7nown8/0/XYxCnsOGBvdv/kAZx2ygmsueaaVc5ky2lFyzmviFgAPADsFxEvReZd4Eb+/SbuOcDmFYf1TbGW4lVVTc4RcVD63DIitkqfzaXFh1Eq/6lw3Ziq3SqrtSnTZvLgXx5h0GFDOHnET3ls8hOces6FbLRhbyTRrVs3Dj1wENOf+hsA666zDmuv3R2AT39yIEuWLGH+goXVLmElNXfuazQ1NRERXHf9Ley664Dl9nn66QbefPNtdth+m/av4Gosmppyl2okbSSpZ1ruDnwOeDr1I5NGZxwKPJkOGQccpczuwMKIeAm4BxgkqVe6ETgoxarK+xDKzisILwReiIjlZrZO/zQYBfDea8+WttPsxOOP4cTjjwGykRg33fpbLhhxCq++No+NNuxNRDDhz3+l/1YfAuC11+exQe9eSGL6zFk0RdCzx/rVLmEl9cEPbszLL88F4NDB+zNjxiwA+vXbnBdf/CeNjY1ssUUfttnmwzz/wovVTmXLartuoE2B0ZK6kDVkx0bEXZImSNqIbGDEVKB5iNXdZMPoGsiG0h0DEBHzJJ0HTEz7ndt8c7CavKM1rgJ2BqalCn2U7LdFD0nHR8S9Oc/TKZx6zoXMX7CQiGCb/lsx4uRvAXDvA3/h17/7H7qs0YW1unXjonNOI/vlCyeP+CkTp0xjwYJF7HPoVxl23NdW+SajFcPNv7ySz3z6E2y4YW+ef3YS55x7MZ/5zCfZccftiAheeGE2xw/Lui332GMgp5w8nPfeW0JTUxMnfPsMXn99fgd/g9VMGz2EEhHTgJ1WEN+7hf0DGN7CthuAG1pzfeW5GyzpDuDMiJiR1rcDzgVOAe5IHeYrVOaWs6287pstP8zQbMniOVrVc7x19pdz55x1zr51la9XL3lbzls3J2aAiJgpaduIeLa55WdmVgid7PHtGZJGArel9f8CZqbxfe+1fJiZWTvrZBMfHQ0MA76b1h8Gvk+WmPdq81qZma2sztRyjoh3gEtSWdabK4iZmXWIWFKOh3aqJmdJYyPiS5Kms4Jnyj23hpkVTidpOX8nfR5U74qYmbWJztDnHBEvpQHYN0WE+5bNrPg6ScuZiGiU1CSpR0T4WWMzK7ToLMk5eROYnuYhfas5GBHfrkutzMxWVme4IVjhj8B9ZDcFlwDv1K1GZmarojO0nCWtAfwYOBZ4gWxejS3Ipsk7o+61MzNrrZIk51rzOV9ENpn0lhHx8YjYGdgK6JG2mZkVSkTkLkVWq1vjILJ5NZZ+i4hYJOl44Gn+/cSgmVkxlKTlXCs5R6zg10sawVGOPwEzK5eSJOda3RozJR21bFDSV8lazmZmhRJLmnKXaiStJekxSU9ImiHpnBTfUtKjkhok/VpStxRfM603pO39Ks51eorPkpRrovZaLefhwB2SjiV7byDALkB34PN5LmBm1q7a7gHBd4G9I+JNSV2Bv0j6X+B7wGURcZukq4HjgJHpc35EfETSEcAFwH+l+e+PALYHNgPuk7R1RFQd81frHYJzImI3son1n0/l3IgYGBE1X1BoZtbeoilyl6rnyTRP7NY1lQD2Bm5P8dFk7xEEGJzWSdv3Se8ZHAzcFhHvRsRzZK+xan4pbIvyzko3AZiQZ18zsw7Vhn3OafqKycBHgCuBvwMLKt6dOhvok5b7AC8CRMQSSQuBDVL8kYrTVh7Tolp9zmZmq5em/EXSUEmTKsrQylNFRGN6DV9fstbutu31NfI+IWhmtlpozdwaETEKGJVjvwWSHgA+AfSUtEZqPfcFmrt45wCbA7PTA3w9gNcr4s0qj2mRW85mViqxJHKXaiRtJKlnWu4OfA54CngAODztNgS4My2PS+uk7RPSUORxwBFpNMeWQH/gsVrfwy1nMyuXthutsSkwOvU7fwAYGxF3SZoJ3CbpR8AU4Pq0//XALyU1APPIRmgQETMkjQVmks1NNLzWSA0A1fsRxvdee7YcI8KtTXXf7FMdXQUroCWL52hVz/H6wZ/JnXM2+MOfVvl69eKWs5mVSzlehOLkbGblUpK3VDk5m1m5LB2BvJpzcjazUnHL2cysgJyczcyKKAo7AKNVnJzNrFTccjYzK6BocsvZzKxwmhqdnM3MCsfdGmZmBeRuDTOzAqrzdEHtxsnZzErFLWczswLyDUEzswJyy9nMrICiJE8I+jVVZlYq0ZS/VCNpc0kPSJopaYak76T42ZLmSJqaygEVx5wuqUHSLEn7VsT3S7EGSafl+R5uOZtZqTS1Xct5CXBSRDwuaT1gsqTxadtlEXFx5c6StiN7NdX2wGbAfZK2TpuvJHsH4WxgoqRxETGz2sWdnM2sVNqqWyMiXgJeSstvSHoK6FPlkMHAbRHxLvBcepfgwLStISKeBZB0W9q3anJ2t4aZlUpTo3KXvCT1A3YCHk2hEyRNk3SDpF4p1gd4seKw2SnWUrwqJ2czK5VoUu4iaaikSRVl6LLnk7Qu8FvguxGxCBgJfBgYQNayvqQe38PdGmZWKq3pc46IUcColrZL6kqWmG+JiDvSMa9UbL8WuCutzgE2rzi8b4pRJd4it5zNrFQilLtUI0nA9cBTEXFpRXzTit0+DzyZlscBR0haU9KWQH/gMWAi0F/SlpK6kd00HFfre7jlbGal0oZza+wBfA2YLmlqip0BfFnSACCA54FvZNeNGZLGkt3oWwIMj4hGAEknAPcAXYAbImJGrYsr6jxLyHuvPVuSaUisLXXf7FMdXQUroCWL56zyUIupHzokd84Z8MK4wj6x4pazmZVKkx/fNjMrnjZ8CKVD1T0599pin3pfwlZD78x+sKOrYCVVlrk13HI2s1Jxy9nMrIDKMgLBydnMSqWxqRyPbzg5m1mplOTl207OZlYugfuczcwKp6kknc5OzmZWKk1uOZuZFY+7NczMCqjRydnMrHg8WsPMrICcnM3MCsh9zmZmBVSSGUP9miozK5cmlLtUI2lzSQ9ImilphqTvpHhvSeMlPZM+e6W4JF0uqSG9mXvninMNSfs/I2lInu/h5GxmpdLYilLDEuCkiNgO2B0YLmk74DTg/ojoD9yf1gH2J3tvYH9gKNlbupHUGxgB7AYMBEY0J/RqnJzNrFSapNylmoh4KSIeT8tvAE8BfYDBwOi022jg0LQ8GBgTmUeAnullsPsC4yNiXkTMB8YD+9X6Hk7OZlYq0YoiaaikSRVl6IrOKakfsBPwKLBJRLyUNr0MbJKW+wAvVhw2O8VailflG4JmViqtGUoXEaOAUdX2kbQu8FvguxGxSBUt7ogISXWZzcMtZzMrlSblL7VI6kqWmG+JiDtS+JXUXUH6nJvic4DNKw7vm2ItxatycjazUmlEuUs1yprI1wNPRcSlFZvGAc0jLoYAd1bEj0qjNnYHFqbuj3uAQZJ6pRuBg1KsKndrmFmptOE45z2ArwHTJU1NsTOAnwJjJR0HvAB8KW27GzgAaADeBo4BiIh5ks4DJqb9zo2IebUu7uRsZqXSVo9vR8RfoMXm9T4r2D+A4S2c6wbghtZc38nZzEqlJHPtOzmbWbmU5fFtJ2czKxXPSmdmVkCNbjmbmRWPW85mZgXk5GxmVkAerWFmVkAerWFmVkBl6dbIPbeGpO6StqlnZczMVlUbTrbfoXIlZ0kHA1OBP6b1AZLG1bFeZmYrpS1npetIeVvOZ5O9XmUBQERMBbasS43MzFZBUytKkeXtc34vIhbq/a91KctNUTMrkbIkprzJeYakI4EukvoD3wb+Wr9qmZmtnKaSpOe83RrfArYH3gV+BSwCvlOvSpmZrayy3BDM23L+ckT8APhBc0DST/n3K8HNzAqh6H3JeeVtOR8m6SvNK5KuADaqT5XMzFZeG79D8AZJcyU9WRE7W9IcSVNTOaBi2+mSGiTNkrRvRXy/FGuQlKtRm7flfBgwTlITsB+wICKOy3msmVm7aeM+55uAK4Axy8Qvi4iLKwOStgOOIOsC3gy4T9LWafOVwOeA2cBESeMiYma1C1dNzpJ6V6z+N/B74GHgHEm987wHy8ysPbVlao6IP0vql3P3wcBtEfEu8JykBrIhyAANEfEsgKTb0r4rn5yByWTfVRWfB6YSwFY5K21m1i5a0+csaSgwtCI0KiJG5Tj0BElHAZOAkyJiPtAHeKRin9kpBvDiMvHdal2ganKOCD9oYmarlcZWtJ1TIs6TjCuNBM4ja6CeB1wCHNvKc9SUe+IjSTsA2wFrNcciYtl+GDOzDlXv0RoR8UrzsqRrgbvS6hxg84pd+6YYVeItyju3xgjgF6nsBVwIHJLnWDOz9tRE5C4rQ9KmFaufB5pHcowDjpC0pqQtgf7AY8BEoL+kLSV1I7tpWHNuorwt58OBHYEpEXGMpE2Am3Mea2bWbtryhqCkW4HPAhtKmg2MAD4raUC61PPANwAiYoaksWQ3+pYAwyOiMZ3nBOAeoAtwQ0TMqHXtvMn5nYhokrRE0vrAXN7fTDczK4S27NaIiC+vIHx9lf3PB85fQfxu4O7WXDtvcp4kqSdwLdkIjjeB/2vNhczM2kNrbggWWa1xzl+IiDsiYpikXhFxtaQ/AutHxLR2qqOZWW5lmfioVsv5h8Adafl+YOeIeL6uNVpN9emzKddedwkbb7whEcGNN9zKVVfdxOgxv6D/1tlw8B491mfhwkV8cvcD6dq1K5dfcT477/RRmpqCU04+h4ceerSDv4W1pcbGRv7r6yey8YYbcNWFI/jB+Zcx6YknWXedtQE4/4wT2bb/Vtx17wNcf8tvgWDttbtz5knD2PYj2c/MD3/yM/7814n07tWD34+5qgO/zeqjHKm5dnJWC8u2jCWNSzj99PN5YuoM1l13HR56+A9MmPAXhhz1raX7/PgnP2DRokUAHHPsEQDsNnB/NtpoA+74/Y18es/BRJTlR8tu/s04tvrQ5rz51ttLYycdfwyD9trzffv12fSD3HTFT+mx3ro89MgkzrnwCm4ddSkAh+7/nxz5hYM44/xL27Xuq7OytJxrDaXrLmknSR8H1krLOzeX9qjg6uKVl1/lianZDdg333yLWbMa2HSzD75vny8cdgC/GfsHALbdtj9/ejDrtn/11ddZuGARO3/8Y+1baaubl+e+xp//byKHHTSo5r47ffQ/6LHeugB8bPtteeXV15Zu22XADvRYf7261bOMyvImlFrJ+SXgUuBi4OW0fEkqF1c5rlPbYos+7LjjdkyaOHVpbI89BjJ37mv8/e/PAzB9+lMceOB/0qVLFz70ob4M2Omj9O2z6YpPaKudCy4fxfeGHYs+8P5/cF5+7S/5/JATuODya1m8+L3ljrvjrnvZc7dd2quapRSt+K/Iaj2+vdfKnLTyefVuXTeg6xqd5zf/OuuszS23juTUU87jjTfeXBr/4pcOXtpqBhgzeizbbPNhHnp4HP/4xxwefXQyjU1Fn/7b8njw4cfo3asn22/zER6b8u/75t/9xhA23KAX7723hLMv+gXX33I7xx/z75Fajz0+jTv+515+eeWFHVHt0ugUozWaSVoLGAbsSdbf/hBwdUT8a0X7Vz6vvu7aW5bjTyqHNdZYg1t+NZJf33Yn4+68Z2m8S5cuHHLIfuy558FLY42NjZx26o+Wrt834XYannmuXetr9TFl+kwefPhRHnpkEu8uXsxbb73DqedezAVnfR+Abt26cugB/8lNt/5u6TGzGp7jrAsu5+qLzqFnj/U7quqlUPTuirzyjnMeA7xB9vg2wJHAL4Ev1qNSq6urRl7ArFkNXPGL949R32vvPfjb3/7OP+e8vDTWvftaSOLtt99hr733pHFJI08/3dDeVbY6OPGbR3PiN48G4LEp07jp1t9xwVnf59XX5rHRhr2JCCY89Aj9t/oQAC+9Mpfv/vDH/OSHJ9Fviz5Vzmx5NJXkpnre5LxDRGxXsf6ApKpzkXY2n/jELhz5lS/w5PSn+esj/wPA2SMu4t57HuTwww/mN795/6P0G220Ab8fN4ZoauKf/3yZ/z7uex1RbWtHp553MfMXLCQi2OYjWzHi+8MBGHnjbSxcuIgfXZoNlevSpQtjr/sZACeffSETp0xnwcJF7POFIQw79iu5bjJ2ZuVIzaA8Q7ck3QxcERGPpPXdyJ4bP6rWsZ2pW8Pym//8vR1dBSugrhv3X+Uhu0d+6PO5c86vXvhdYYcI5205fxz4q6R/pPUtgFmSpgMRER4DZmaFUPRRGHnlTc771bUWZmZtZElJknOu+Zwj4gWyWej2TstvAR+IiBfSuplZIXSKcc7N0mT7uwDbADcC3cjmc96jflUzM2u9sgyly9VyJpvt/xCyFjMR8U+g8zxZYmarjYjIXWqRdIOkuZKerIj1ljRe0jPps1eKS9LlkhokTauc4kLSkLT/M5KG5PkeeZPz4si+SaQLrZPzODOzdtXGr6m6ieXvuZ0G3B8R/clm6zwtxfcnezVVf7InpEdClszJ3qCyGzAQGNGc0KvJm5zHSroG6Cnp68B9ZBPvm5kVSiORu9QSEX8G5i0THgyMTsujgUMr4mMi8whZvtwU2BcYHxHzImI+MJ4cgyxy9TlHxMWSPgcsIut3Pisixuc51sysPbXDlKGbRMRLafllYJO03Ad4sWK/2SnWUryqvEPpAP5GNqb5PklrS1ovIt5oxfFmZnXXmjnRKydpS0aluYHyXisk1eW3Qd7RGl8n+wK9gQ+TZf2rgX3qUSkzs5XVmtEalZO0tcIrkjaNiJdSt8XcFJ/D+1983TfF5pC9wbsy/mCti+Ttcx5ONmxuEUBEPANsnPNYM7N20w7jnMcBzSMuhgB3VsSPSqM2dgcWpu6Pe4BBknqlG4GDUqyqvN0a70bEYil7DF3SGpRnfhEzK5G27HOWdCtZq3dDSbPJRl38lGyQxHHAC8CX0u53AwcADcDbwDEAETFP0nnAxLTfuRGx7E3G5eRNzn+SdAbZa6s+Rza38x9qHGNm1u4ao+0eQ4mIL7ewabku3TTceHgL57kBuKE1187brXEa8CowHfgG2W+IH7bmQmZm7aFTPb4dEU2Sfg/8PiJerW+VzMxWXlkm26/ack4d22dLeg2YRTZN6KuSzmqf6pmZtU60ohRZrW6NE8lGaewaEb0jojfZI4h7SDqx7rUzM2ulNn58u8PUSs5fA74cEUvfPBoRzwJfBWq+BcXMrL2VJTnX6nPuGhGvLRuMiFclda1TnczMVlpbjtboSLWS8+KV3GZm1iGKPgojr1rJeUdJi1YQF7BWHepjZrZKWjO3RpFVTc4R0aW9KmJm1haK3pecV2tmpTMzK7xO0XI2M1vdNJbkLYJOzmZWKmV5QtDJ2cxKpbOM1jAzW6245WxmVkBuOZuZFVBZWs5553M2M1stNEZT7lKLpOclTZc0VdKkFOstabykZ9JnrxSXpMslNUiaJmnnVfkeTs5mVip1mGx/r4gYEBG7pPXTgPsjoj9wf1oH2B/on8pQYOSqfA8nZzMrlYim3GUlDQZGp+XRwKEV8TGReQTomd7OvVKcnM2sVNp4ytAA7pU0WdLQFNskvVUb4GVgk7TcB3ix4tjZKbZSfEPQzEqlNY9vp4Q7tCI0KiJGVazvGRFzJG0MjJf09DLXCkl1uQPp5GxmpdKaiY9SIh5VZfuc9DlX0u+AgcArkjaNiJdSt8XctPscYPOKw/um2Epxt4aZlUpjU1PuUo2kdSSt17wMDAKeBMYBQ9JuQ4A70/I44Kg0amN3YGFF90erueVsZqXShg+hbAL8ThJkufJXEfFHSROBsZKOA14AvpT2vxs4AGgA3gaOWZWLOzmbWam01ZSh6X2pO64g/jqwzwriAQxvk4vj5GxmJePJ9s3MCsiT7ZuZFVCtG32rCydnMysVd2uYmRWQuzXMzAqoLFOGOjmbWal4sn0zswJyy9nMrICaVn4q0EJxcjazUvENQTOzAnJyNjMroHKkZlBZfsusDiQNXWYibzP/XNgKeT7n9jW09i7WCfnnwpbj5GxmVkBOzmZmBeTk3L7cr2gr4p8LW45vCJqZFZBbzmZmBeTknIOkvpLulPSMpL9L+rmkbivYbzNJt+c4392Seq5kXc6W9P2VOdZWnqRGSVMlzZD0hKSTJLX5/z+SHpQ0K11rqqTDq+z7vKQN27oOVgxOzjUoe/XuHcDvI6I/sDWwLnD+MvutERH/jIgW/2dqFhEHRMSCetTX6uadiBgQEdsDnwP2B0bU6VpfSdcaEBE1f9lbOTk517Y38K+IuBEgIhqBE4FjJQ2TNE7SBOB+Sf0kPQkgaW1JYyXNlPQ7SY9K2iVte17Shmn/pyRdm1pk90rqnvb5uqSJqZX2W0lrd8zXt2VFxFyyscknKNNF0kXp72uapG807yvp5Ir4OSnWT9LTkm5Jf/+3V/v7lTRS0qT0M3LOCrZ3l/S/6WdmHUk3SHpM0hRJg+vxZ2D15+Rc2/bA5MpARCwC/kH2+PvOwOER8ZlljhsGzI+I7YAzgY+3cP7+wJWpRbYAOCzF74iIXSNiR+Ap4Lg2+C7WRiLiWaALsDHZ383CiNgV2BX4uqQtJQ0i+/sdCAwAPi7p0+kU2wBXRcR/AIvIfl6a3VLRrbEB8IOI2AX4GPAZSR+r2Hdd4A/ArRFxLfADYEJEDAT2Ai6StE49/gysvpycV934iJi3gviewG0AEfEkMK2F45+LiKlpeTLQLy3vIOkhSdOBr5D9krBiGgQcJWkq8CiwAVlSHpTKFOBxYNsUB3gxIh5OyzeT/bw0q+zWeB34kqTH03m2B7ar2PdO4MaIGFNRl9NSXR4E1gK2aLuvau3FEx/VNhN4Xz+ypPXJfuCXAG+t4vnfrVhuBLqn5ZuAQyPiCUlHA59dxetYG5K0Fdnf11xAwLci4p5l9tkX+ElEXLNMvB/Lz8+zwjGtkrYEvg/sGhHzJd1ElnCbPQzsJ+lXkY2LFXBYRMxa2e9mxeCWc233A2tLOgpAUhfgErLk+XaV4x4GvpSO2Q74aCuvux7wkqSuZC1nKwhJGwFXA1ekhHgPcHz6u0LS1qkr4R6yexPrpngfSRun02wh6RNp+UjgLy1cbn2yBsBCSZuQ3YisdBYwH7gyrd8DfCvdyEbSTqv2ba2jODnXkP7n+zzwRUnPAH8D/gWcUePQq4CNJM0EfgTMABa24tJnkv0T+WHg6dbW29pc9+ahdMB9wL1A882568j+hfV4uiF8DbBGRNwL/Ar4v9Q9dTvZL12AWcBwSU8BvYCRK7poRDxB1p3xdDrXwyvY7TupfhcC5wFdgWmpruet2te2juInBOsktbC7RsS/JH2Y7H/obSJicQdXzTpY6ta4KyJ26Oi6WHG5z7l+1gYeSP/UFTDMidnM8nLL2cysgNznbGZWQE7OZmYF5ORsZlZATs5mZgXk5GxmVkBOzmZmBfT/+cdP02r9E54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9094256167782172\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9672657252888318, 0.941875, 0.954401519949335)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884837815334466\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9545454545454546,\n",
       " 'precision': 0.9672657252888318,\n",
       " 'recall': 0.941875,\n",
       " 'f1': 0.954401519949335,\n",
       " 'auc': 0.9884837815334466,\n",
       " 'mcc': 0.9094256167782172}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.003125   0.00729167 0.01229167 0.01541667 0.01645833\n",
      " 0.019375   0.02145833 0.02229167 0.024375   0.02541667 0.02604167\n",
      " 0.02729167 0.028125   0.02854167 0.02916667 0.03       0.03166667\n",
      " 0.03208333 0.03291667 0.034375   0.03520833 0.03645833 0.03666667\n",
      " 0.03708333 0.03833333 0.03875    0.03895833 0.04       0.040625\n",
      " 0.04104167 0.041875   0.04229167 0.0425     0.04291667 0.04395833\n",
      " 0.04416667 0.04479167 0.04625    0.04729167 0.04770833 0.04833333\n",
      " 0.04875    0.04895833 0.04958333 0.05041667 0.05145833 0.05166667\n",
      " 0.05208333 0.05291667 0.05354167 0.05395833 0.05645833 0.05708333\n",
      " 0.05729167 0.05770833 0.05854167 0.05916667 0.05958333 0.05979167\n",
      " 0.060625   0.06104167 0.06229167 0.063125   0.06375    0.065\n",
      " 0.065625   0.06645833 0.06708333 0.06729167 0.068125   0.06916667\n",
      " 0.06958333 0.07083333 0.07145833 0.071875   0.07270833 0.07333333\n",
      " 0.07354167 0.074375   0.07479167 0.07520833 0.075625   0.07604167\n",
      " 0.07708333 0.0775     0.07833333 0.07895833 0.079375   0.07979167\n",
      " 0.08020833 0.08104167 0.08125    0.081875   0.08208333 0.0825\n",
      " 0.083125   0.08354167 0.08395833 0.08458333 0.08479167 0.08520833\n",
      " 0.085625   0.08604167 0.08729167 0.08770833 0.08833333 0.08916667\n",
      " 0.08958333 0.09       0.09041667 0.09083333 0.09104167 0.09166667\n",
      " 0.091875   0.09229167 0.0925     0.093125   0.09395833 0.094375\n",
      " 0.095625   0.09604167 0.09916667 0.09958333 0.100625   0.10145833\n",
      " 0.10270833 0.103125   0.10416667 0.10479167 0.10520833 0.10645833\n",
      " 0.106875   0.10770833 0.108125   0.10895833 0.10979167 0.11020833\n",
      " 0.11104167 0.11125    0.11166667 0.11208333 0.1125     0.11479167\n",
      " 0.11520833 0.11770833 0.118125   0.11854167 0.11895833 0.11979167\n",
      " 0.12020833 0.12083333 0.12125    0.12625    0.12666667 0.12854167\n",
      " 0.12916667 0.13104167 0.13145833 0.13291667 0.13354167 0.14208333\n",
      " 0.14270833 0.14354167 0.14395833 0.145      0.14541667 0.14583333\n",
      " 0.14625    0.15020833 0.150625   0.15104167 0.15145833 0.15166667\n",
      " 0.15208333 0.1525     0.15291667 0.155      0.15541667 0.15583333\n",
      " 0.15625    0.15645833 0.156875   0.15729167 0.15770833 0.160625\n",
      " 0.16104167 0.16166667 0.16291667 0.16458333 0.165      0.16770833\n",
      " 0.168125   0.16854167 0.16895833 0.16916667 0.16958333 0.17145833\n",
      " 0.171875   0.17270833 0.173125   0.17583333 0.17625    0.17854167\n",
      " 0.17895833 0.17979167 0.18020833 0.18333333 0.18416667 0.18958333\n",
      " 0.19       0.19125    0.19166667 0.19708333 0.1975     0.200625\n",
      " 0.20104167 0.20354167 0.20395833 0.20458333 0.205      0.20958333\n",
      " 0.21       0.21145833 0.211875   0.21458333 0.21520833 0.21645833\n",
      " 0.216875   0.220625   0.22104167 0.22979167 0.23020833 0.23875\n",
      " 0.23916667 0.24166667 0.24208333 0.24791667 0.24833333 0.2675\n",
      " 0.26791667 0.274375   0.27479167 0.2825     0.283125   0.29729167\n",
      " 0.29770833 0.30375    0.30416667 0.31104167 0.31145833 0.31875\n",
      " 0.31916667 0.35       0.35041667 0.361875   0.36270833 0.41604167\n",
      " 0.41645833 0.41916667 0.41979167 0.42270833 0.42270833 0.50145833\n",
      " 0.501875   0.52125    0.52166667 0.529375   0.52979167 0.53104167\n",
      " 0.53145833 0.539375   0.539375   0.54520833 0.545625   0.55270833\n",
      " 0.553125   0.575625   0.57604167 0.59520833 0.595625   0.60125\n",
      " 0.60166667 0.62604167 0.62604167 0.70979167 0.70979167 0.71520833\n",
      " 0.71520833 0.7475     0.7475     0.7525     0.7525     0.76270833\n",
      " 0.76270833 0.781875   0.781875   0.78291667 0.78291667 0.78479167\n",
      " 0.78479167 0.78583333 0.78583333 0.79520833 0.79520833 0.80270833\n",
      " 0.80270833 0.81479167 0.81479167 0.81770833 0.81770833 0.824375\n",
      " 0.824375   0.82458333 0.82458333 0.83145833 0.83145833 0.83270833\n",
      " 0.83270833 0.83291667 0.83291667 0.83791667 0.83791667 0.84416667\n",
      " 0.84416667 0.84583333 0.84583333 0.84604167 0.84604167 0.84916667\n",
      " 0.84916667 0.85270833 0.85270833 0.85333333 0.85333333 0.85458333\n",
      " 0.85458333 0.86041667 0.86041667 0.86145833 0.86145833 0.8625\n",
      " 0.8625     0.86666667 0.86666667 0.86791667 0.86791667 0.86791667\n",
      " 0.86916667 0.86916667 0.86958333 0.86958333 0.87166667 0.87166667\n",
      " 0.871875   0.871875   0.875      0.875      0.876875   0.876875\n",
      " 0.87729167 0.87729167 0.87979167 0.87979167 0.88458333 0.88458333\n",
      " 0.885      0.885      0.88520833 0.88520833 0.88645833 0.88645833\n",
      " 0.886875   0.886875   0.88791667 0.88791667 0.88854167 0.88854167\n",
      " 0.89       0.89       0.89208333 0.89208333 0.8925     0.8925\n",
      " 0.89520833 0.89520833 0.898125   0.898125   0.90083333 0.90083333\n",
      " 0.90145833 0.90145833 0.90208333 0.90208333 0.9025     0.9025\n",
      " 0.90333333 0.90333333 0.90520833 0.90520833 0.90645833 0.90645833\n",
      " 0.91041667 0.91041667 0.91083333 0.91083333 0.91166667 0.91166667\n",
      " 0.91229167 0.91229167 0.91270833 0.91270833 0.91375    0.91375\n",
      " 0.91625    0.91625    0.91729167 0.91729167 0.91833333 0.91833333\n",
      " 0.91916667 0.91916667 0.91979167 0.91979167 0.92020833 0.92020833\n",
      " 0.92354167 0.92354167 0.92395833 0.92395833 0.92520833 0.92520833\n",
      " 0.92645833 0.92645833 0.92708333 0.92708333 0.9275     0.9275\n",
      " 0.92770833 0.92770833 0.92875    0.92875    0.92895833 0.92895833\n",
      " 0.93020833 0.93020833 0.93104167 0.93104167 0.93145833 0.93145833\n",
      " 0.931875   0.931875   0.93270833 0.93270833 0.93333333 0.93333333\n",
      " 0.93375    0.93375    0.93395833 0.93395833 0.93416667 0.93416667\n",
      " 0.934375   0.934375   0.93541667 0.93541667 0.93583333 0.93583333\n",
      " 0.93645833 0.93645833 0.93666667 0.93666667 0.93708333 0.93708333\n",
      " 0.9375     0.9375     0.93791667 0.93791667 0.93875    0.93875\n",
      " 0.93979167 0.93979167 0.94       0.94       0.94020833 0.94020833\n",
      " 0.94104167 0.94104167 0.94125    0.94125    0.94145833 0.94145833\n",
      " 0.94166667 0.94166667 0.941875   0.941875   0.94208333 0.94208333\n",
      " 0.94291667 0.94291667 0.943125   0.943125   0.94333333 0.94333333\n",
      " 0.944375   0.944375   0.94479167 0.94479167 0.945      0.945\n",
      " 0.94520833 0.94520833 0.94583333 0.94583333 0.94645833 0.94645833\n",
      " 0.94666667 0.94666667 0.94791667 0.94791667 0.94833333 0.94833333\n",
      " 0.94854167 0.94854167 0.949375   0.949375   0.95       0.95\n",
      " 0.95020833 0.95020833 0.95083333 0.95083333 0.95104167 0.95104167\n",
      " 0.95125    0.95125    0.95270833 0.95270833 0.95354167 0.95354167\n",
      " 0.95416667 0.95416667 0.95458333 0.95458333 0.955      0.955\n",
      " 0.95520833 0.95520833 0.95541667 0.95541667 0.955625   0.955625\n",
      " 0.95583333 0.95583333 0.95604167 0.95604167 0.95645833 0.95645833\n",
      " 0.95666667 0.95666667 0.95729167 0.95729167 0.9575     0.9575\n",
      " 0.95770833 0.95770833 0.958125   0.958125   0.95895833 0.95895833\n",
      " 0.95916667 0.95916667 0.959375   0.959375   0.95958333 0.95958333\n",
      " 0.95979167 0.95979167 0.96020833 0.96020833 0.960625   0.960625\n",
      " 0.96083333 0.96083333 0.96104167 0.96104167 0.96125    0.96125\n",
      " 0.96166667 0.96166667 0.961875   0.961875   0.96208333 0.96208333\n",
      " 0.96229167 0.96229167 0.96270833 0.96270833 0.96291667 0.96291667\n",
      " 0.963125   0.963125   0.96333333 0.96333333 0.96354167 0.96354167\n",
      " 0.96375    0.96375    0.96395833 0.96395833 0.96416667 0.96416667\n",
      " 0.96458333 0.96458333 0.96479167 0.96479167 0.965      0.965\n",
      " 0.96541667 0.96541667 0.965625   0.965625   0.96604167 0.96604167\n",
      " 0.96604167 0.96625    0.96625    0.96645833 0.96645833 0.96666667\n",
      " 0.96666667 0.966875   0.966875   0.96708333 0.96708333 0.96729167\n",
      " 0.96729167 0.9675     0.9675     0.96770833 0.96770833 0.96833333\n",
      " 0.96833333 0.96854167 0.96854167 0.96875    0.96875    0.96895833\n",
      " 0.96895833 0.96916667 0.96916667 0.96979167 0.96979167 0.97\n",
      " 0.97       0.97020833 0.97020833 0.97041667 0.97041667 0.970625\n",
      " 0.970625   0.97083333 0.97083333 0.97104167 0.97104167 0.97125\n",
      " 0.97125    0.97166667 0.97166667 0.971875   0.971875   0.97208333\n",
      " 0.97208333 0.9725     0.9725     0.97270833 0.97270833 0.97291667\n",
      " 0.97291667 0.973125   0.973125   0.97333333 0.97333333 0.97375\n",
      " 0.97375    0.97395833 0.97395833 0.97416667 0.97416667 0.974375\n",
      " 0.974375   0.97458333 0.97458333 0.975      0.975      0.97520833\n",
      " 0.97520833 0.97541667 0.97541667 0.975625   0.975625   0.97583333\n",
      " 0.97583333 0.97604167 0.97604167 0.97625    0.97625    0.97645833\n",
      " 0.97645833 0.97666667 0.97666667 0.976875   0.976875   0.97708333\n",
      " 0.97708333 0.97729167 0.97729167 0.9775     0.9775     0.97770833\n",
      " 0.97770833 0.97791667 0.97791667 0.978125   0.978125   0.97833333\n",
      " 0.97833333 0.97875    0.97875    0.97895833 0.97895833 0.979375\n",
      " 0.979375   0.97958333 0.97958333 0.97979167 0.97979167 0.98\n",
      " 0.98       0.980625   0.980625   0.98083333 0.98083333 0.98104167\n",
      " 0.98104167 0.98125    0.98125    0.98145833 0.98145833 0.9825\n",
      " 0.9825     0.98333333 0.98333333 0.98395833 0.98395833 0.984375\n",
      " 0.984375   0.98458333 0.98458333 0.98479167 0.98479167 0.985\n",
      " 0.985      0.98520833 0.98520833 0.98541667 0.98541667 0.985625\n",
      " 0.985625   0.98583333 0.98583333 0.98604167 0.98604167 0.98625\n",
      " 0.98625    0.98645833 0.98645833 0.98666667 0.98666667 0.986875\n",
      " 0.986875   0.98708333 0.98708333 0.98729167 0.98729167 0.9875\n",
      " 0.9875     0.98791667 0.98791667 0.988125   0.988125   0.98833333\n",
      " 0.98833333 0.98854167 0.98854167 0.98875    0.98875    0.98895833\n",
      " 0.98895833 0.98916667 0.98916667 0.989375   0.989375   0.98958333\n",
      " 0.98958333 0.98979167 0.98979167 0.99       0.99       0.99020833\n",
      " 0.99020833 0.99041667 0.99041667 0.990625   0.990625   0.99083333\n",
      " 0.99083333 0.99104167 0.99104167 0.99125    0.99125    0.99145833\n",
      " 0.99145833 0.99166667 0.99166667 0.991875   0.991875   0.99208333\n",
      " 0.99208333 0.99229167 0.99229167 0.9925     0.9925     0.99270833\n",
      " 0.99270833 0.99291667 0.99291667 0.993125   0.993125   0.99333333\n",
      " 0.99333333 0.99354167 0.99354167 0.99395833 0.99395833 0.99416667\n",
      " 0.99416667 0.994375   0.994375   0.99458333 0.99458333 0.99479167\n",
      " 0.99479167 0.995      0.995      0.99520833 0.99520833 0.99541667\n",
      " 0.99541667 0.995625   0.995625   0.99583333 0.99583333 0.99604167\n",
      " 0.99604167 0.99625    0.99625    0.99645833 0.99645833 0.99666667\n",
      " 0.99666667 0.996875   0.996875   0.99708333 0.99708333 0.99729167\n",
      " 0.99729167 0.9975     0.9975     0.99770833 0.99770833 0.99791667\n",
      " 0.99791667 0.998125   0.998125   0.99833333 0.99833333 0.99854167\n",
      " 0.99854167 0.99875    0.99875    0.99895833 0.99895833 0.99916667\n",
      " 0.99916667 0.999375   0.999375   0.99958333 0.99958333 0.99979167\n",
      " 0.99979167 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.12585034e-04 2.12585034e-04\n",
      " 2.12585034e-04 2.12585034e-04 2.12585034e-04 2.12585034e-04\n",
      " 2.12585034e-04 2.12585034e-04 2.12585034e-04 2.12585034e-04\n",
      " 4.25170068e-04 4.25170068e-04 4.25170068e-04 4.25170068e-04\n",
      " 4.25170068e-04 4.25170068e-04 4.25170068e-04 4.25170068e-04\n",
      " 4.25170068e-04 4.25170068e-04 4.25170068e-04 4.25170068e-04\n",
      " 6.37755102e-04 6.37755102e-04 8.50340136e-04 8.50340136e-04\n",
      " 1.06292517e-03 1.06292517e-03 1.27551020e-03 1.27551020e-03\n",
      " 1.48809524e-03 1.48809524e-03 1.91326531e-03 1.91326531e-03\n",
      " 2.12585034e-03 2.12585034e-03 2.33843537e-03 2.33843537e-03\n",
      " 2.55102041e-03 2.55102041e-03 2.76360544e-03 2.76360544e-03\n",
      " 2.97619048e-03 2.97619048e-03 3.18877551e-03 3.18877551e-03\n",
      " 3.40136054e-03 3.40136054e-03 3.61394558e-03 3.61394558e-03\n",
      " 3.82653061e-03 3.82653061e-03 4.25170068e-03 4.25170068e-03\n",
      " 4.46428571e-03 4.46428571e-03 4.67687075e-03 4.67687075e-03\n",
      " 4.88945578e-03 4.88945578e-03 5.10204082e-03 5.10204082e-03\n",
      " 5.31462585e-03 5.31462585e-03 5.52721088e-03 5.52721088e-03\n",
      " 5.73979592e-03 5.73979592e-03 5.95238095e-03 5.95238095e-03\n",
      " 6.16496599e-03 6.16496599e-03 6.37755102e-03 6.37755102e-03\n",
      " 6.59013605e-03 6.59013605e-03 6.80272109e-03 6.80272109e-03\n",
      " 7.22789116e-03 7.22789116e-03 7.44047619e-03 7.44047619e-03\n",
      " 7.65306122e-03 7.65306122e-03 7.86564626e-03 1.14795918e-02\n",
      " 1.14795918e-02 1.16921769e-02 1.16921769e-02 1.19047619e-02\n",
      " 1.19047619e-02 1.21173469e-02 1.21173469e-02 1.23299320e-02\n",
      " 1.23299320e-02 1.25425170e-02 1.25425170e-02 1.29676871e-02\n",
      " 1.29676871e-02 1.31802721e-02 1.31802721e-02 1.33928571e-02\n",
      " 1.33928571e-02 1.36054422e-02 1.36054422e-02 1.38180272e-02\n",
      " 1.38180272e-02 1.40306122e-02 1.40306122e-02 1.42431973e-02\n",
      " 1.42431973e-02 1.44557823e-02 1.44557823e-02 1.46683673e-02\n",
      " 1.46683673e-02 1.48809524e-02 1.48809524e-02 1.50935374e-02\n",
      " 1.50935374e-02 1.53061224e-02 1.53061224e-02 1.55187075e-02\n",
      " 1.55187075e-02 1.57312925e-02 1.57312925e-02 1.61564626e-02\n",
      " 1.61564626e-02 1.63690476e-02 1.63690476e-02 1.65816327e-02\n",
      " 1.65816327e-02 1.67942177e-02 1.67942177e-02 1.70068027e-02\n",
      " 1.70068027e-02 1.72193878e-02 1.72193878e-02 1.74319728e-02\n",
      " 1.74319728e-02 1.76445578e-02 1.76445578e-02 1.78571429e-02\n",
      " 1.78571429e-02 1.80697279e-02 1.80697279e-02 1.82823129e-02\n",
      " 1.82823129e-02 1.87074830e-02 1.87074830e-02 1.89200680e-02\n",
      " 1.89200680e-02 1.91326531e-02 1.91326531e-02 1.93452381e-02\n",
      " 1.93452381e-02 1.95578231e-02 1.95578231e-02 1.97704082e-02\n",
      " 1.97704082e-02 1.99829932e-02 1.99829932e-02 2.01955782e-02\n",
      " 2.01955782e-02 2.08333333e-02 2.08333333e-02 2.16836735e-02\n",
      " 2.16836735e-02 2.18962585e-02 2.18962585e-02 2.23214286e-02\n",
      " 2.23214286e-02 2.25340136e-02 2.25340136e-02 2.27465986e-02\n",
      " 2.27465986e-02 2.31717687e-02 2.31717687e-02 2.35969388e-02\n",
      " 2.35969388e-02 2.38095238e-02 2.38095238e-02 2.40221088e-02\n",
      " 2.40221088e-02 2.42346939e-02 2.42346939e-02 2.44472789e-02\n",
      " 2.44472789e-02 2.48724490e-02 2.48724490e-02 2.50850340e-02\n",
      " 2.50850340e-02 2.52976190e-02 2.52976190e-02 2.55102041e-02\n",
      " 2.55102041e-02 2.59353741e-02 2.59353741e-02 2.61479592e-02\n",
      " 2.61479592e-02 2.69982993e-02 2.69982993e-02 2.72108844e-02\n",
      " 2.72108844e-02 2.74234694e-02 2.74234694e-02 2.76360544e-02\n",
      " 2.76360544e-02 2.78486395e-02 2.78486395e-02 2.80612245e-02\n",
      " 2.80612245e-02 2.86989796e-02 2.86989796e-02 2.89115646e-02\n",
      " 2.89115646e-02 2.91241497e-02 2.91241497e-02 2.95493197e-02\n",
      " 2.95493197e-02 2.99744898e-02 2.99744898e-02 3.01870748e-02\n",
      " 3.01870748e-02 3.03996599e-02 3.03996599e-02 3.06122449e-02\n",
      " 3.06122449e-02 3.08248299e-02 3.08248299e-02 3.14625850e-02\n",
      " 3.14625850e-02 3.21003401e-02 3.21003401e-02 3.25255102e-02\n",
      " 3.25255102e-02 3.29506803e-02 3.29506803e-02 3.33758503e-02\n",
      " 3.33758503e-02 3.35884354e-02 3.35884354e-02 3.42261905e-02\n",
      " 3.42261905e-02 3.44387755e-02 3.44387755e-02 3.46513605e-02\n",
      " 3.46513605e-02 3.52891156e-02 3.52891156e-02 3.57142857e-02\n",
      " 3.57142857e-02 3.59268707e-02 3.59268707e-02 3.65646259e-02\n",
      " 3.65646259e-02 3.67772109e-02 3.67772109e-02 3.69897959e-02\n",
      " 3.69897959e-02 3.72023810e-02 3.72023810e-02 3.78401361e-02\n",
      " 3.78401361e-02 3.86904762e-02 3.86904762e-02 3.91156463e-02\n",
      " 3.91156463e-02 3.93282313e-02 3.93282313e-02 3.97534014e-02\n",
      " 3.97534014e-02 3.99659864e-02 3.99659864e-02 4.08163265e-02\n",
      " 4.08163265e-02 4.10289116e-02 4.10289116e-02 4.12414966e-02\n",
      " 4.12414966e-02 4.20918367e-02 4.20918367e-02 4.27295918e-02\n",
      " 4.27295918e-02 4.33673469e-02 4.33673469e-02 4.42176871e-02\n",
      " 4.42176871e-02 4.46428571e-02 4.46428571e-02 4.48554422e-02\n",
      " 4.48554422e-02 4.59183673e-02 4.59183673e-02 4.61309524e-02\n",
      " 4.61309524e-02 4.67687075e-02 4.67687075e-02 4.69812925e-02\n",
      " 4.69812925e-02 4.71938776e-02 4.71938776e-02 4.82568027e-02\n",
      " 4.82568027e-02 4.84693878e-02 4.84693878e-02 4.88945578e-02\n",
      " 4.88945578e-02 5.05952381e-02 5.05952381e-02 5.22959184e-02\n",
      " 5.22959184e-02 5.25085034e-02 5.25085034e-02 5.35714286e-02\n",
      " 5.35714286e-02 5.52721088e-02 5.52721088e-02 5.54846939e-02\n",
      " 5.54846939e-02 5.82482993e-02 5.82482993e-02 5.84608844e-02\n",
      " 5.84608844e-02 5.86734694e-02 5.86734694e-02 5.95238095e-02\n",
      " 5.95238095e-02 5.99489796e-02 5.99489796e-02 6.16496599e-02\n",
      " 6.16496599e-02 6.18622449e-02 6.18622449e-02 6.35629252e-02\n",
      " 6.35629252e-02 6.42006803e-02 6.42006803e-02 6.56887755e-02\n",
      " 6.56887755e-02 6.63265306e-02 6.63265306e-02 6.73894558e-02\n",
      " 6.73894558e-02 6.76020408e-02 6.76020408e-02 6.78146259e-02\n",
      " 6.78146259e-02 6.86649660e-02 6.86649660e-02 6.95153061e-02\n",
      " 6.95153061e-02 7.20663265e-02 7.20663265e-02 7.35544218e-02\n",
      " 7.35544218e-02 7.37670068e-02 7.37670068e-02 7.41921769e-02\n",
      " 7.41921769e-02 7.56802721e-02 7.56802721e-02 7.65306122e-02\n",
      " 7.69557823e-02 7.69557823e-02 7.97193878e-02 7.97193878e-02\n",
      " 8.01445578e-02 8.01445578e-02 8.33333333e-02 8.33333333e-02\n",
      " 8.48214286e-02 8.48214286e-02 8.56717687e-02 8.56717687e-02\n",
      " 8.58843537e-02 8.58843537e-02 8.71598639e-02 8.71598639e-02\n",
      " 8.97108844e-02 8.97108844e-02 9.01360544e-02 9.01360544e-02\n",
      " 9.11989796e-02 9.11989796e-02 9.18367347e-02 9.18367347e-02\n",
      " 9.24744898e-02 9.24744898e-02 9.43877551e-02 9.43877551e-02\n",
      " 9.48129252e-02 9.48129252e-02 9.56632653e-02 9.56632653e-02\n",
      " 9.63010204e-02 9.63010204e-02 9.88520408e-02 9.88520408e-02\n",
      " 1.03103741e-01 1.03103741e-01 1.04166667e-01 1.04166667e-01\n",
      " 1.05229592e-01 1.05229592e-01 1.06930272e-01 1.06930272e-01\n",
      " 1.09481293e-01 1.09481293e-01 1.09693878e-01 1.09693878e-01\n",
      " 1.10544218e-01 1.10544218e-01 1.13732993e-01 1.13732993e-01\n",
      " 1.14583333e-01 1.14583333e-01 1.16284014e-01 1.16284014e-01\n",
      " 1.16709184e-01 1.16709184e-01 1.18835034e-01 1.18835034e-01\n",
      " 1.19260204e-01 1.19260204e-01 1.20535714e-01 1.20535714e-01\n",
      " 1.20748299e-01 1.20748299e-01 1.21386054e-01 1.21386054e-01\n",
      " 1.21811224e-01 1.21811224e-01 1.24149660e-01 1.24149660e-01\n",
      " 1.25000000e-01 1.25000000e-01 1.26913265e-01 1.26913265e-01\n",
      " 1.27125850e-01 1.27125850e-01 1.28826531e-01 1.28826531e-01\n",
      " 1.30952381e-01 1.30952381e-01 1.31590136e-01 1.31590136e-01\n",
      " 1.33715986e-01 1.33715986e-01 1.34141156e-01 1.34141156e-01\n",
      " 1.39030612e-01 1.39030612e-01 1.40093537e-01 1.40093537e-01\n",
      " 1.47108844e-01 1.47108844e-01 1.47959184e-01 1.47959184e-01\n",
      " 1.49447279e-01 1.49447279e-01 1.49659864e-01 1.49659864e-01\n",
      " 1.53911565e-01 1.53911565e-01 1.56462585e-01 1.56462585e-01\n",
      " 1.58588435e-01 1.58588435e-01 1.58801020e-01 1.58801020e-01\n",
      " 1.60926871e-01 1.60926871e-01 1.61564626e-01 1.61564626e-01\n",
      " 1.62627551e-01 1.62627551e-01 1.65391156e-01 1.65391156e-01\n",
      " 1.65816327e-01 1.65816327e-01 1.66028912e-01 1.66028912e-01\n",
      " 1.66241497e-01 1.66241497e-01 1.66879252e-01 1.66879252e-01\n",
      " 1.67304422e-01 1.67304422e-01 1.67729592e-01 1.67729592e-01\n",
      " 1.68367347e-01 1.68367347e-01 1.68792517e-01 1.68792517e-01\n",
      " 1.71556122e-01 1.71556122e-01 1.73044218e-01 1.73044218e-01\n",
      " 1.73894558e-01 1.73894558e-01 1.77721088e-01 1.77721088e-01\n",
      " 1.80059524e-01 1.80059524e-01 1.81547619e-01 1.81547619e-01\n",
      " 1.81760204e-01 1.81760204e-01 1.82397959e-01 1.82397959e-01\n",
      " 1.85374150e-01 1.85374150e-01 1.86862245e-01 1.86862245e-01\n",
      " 1.88988095e-01 1.88988095e-01 1.90901361e-01 1.90901361e-01\n",
      " 1.94090136e-01 1.94090136e-01 1.95578231e-01 1.95578231e-01\n",
      " 1.96428571e-01 1.96428571e-01 1.98129252e-01 1.98129252e-01\n",
      " 1.98554422e-01 1.98554422e-01 1.99617347e-01 1.99617347e-01\n",
      " 2.00892857e-01 2.00892857e-01 2.03656463e-01 2.03656463e-01\n",
      " 2.04294218e-01 2.04294218e-01 2.06207483e-01 2.06207483e-01\n",
      " 2.11096939e-01 2.11096939e-01 2.15773810e-01 2.15773810e-01\n",
      " 2.15986395e-01 2.15986395e-01 2.35969388e-01 2.35969388e-01\n",
      " 2.36607143e-01 2.36607143e-01 2.50850340e-01 2.50850340e-01\n",
      " 2.53613946e-01 2.53613946e-01 2.64668367e-01 2.64668367e-01\n",
      " 2.85076531e-01 2.85076531e-01 2.87202381e-01 2.87202381e-01\n",
      " 3.03996599e-01 3.03996599e-01 3.31845238e-01 3.31845238e-01\n",
      " 3.50127551e-01 3.50127551e-01 3.71386054e-01 3.71386054e-01\n",
      " 3.73511905e-01 3.73511905e-01 3.74574830e-01 3.74574830e-01\n",
      " 3.81802721e-01 3.81802721e-01 3.99447279e-01 3.99447279e-01\n",
      " 4.11777211e-01 4.11777211e-01 4.16879252e-01 4.16879252e-01\n",
      " 4.23894558e-01 4.23894558e-01 4.32823129e-01 4.32823129e-01\n",
      " 4.40263605e-01 4.40263605e-01 4.40688776e-01 4.40688776e-01\n",
      " 4.46428571e-01 4.46428571e-01 4.52593537e-01 4.52593537e-01\n",
      " 4.57695578e-01 4.57695578e-01 4.67049320e-01 4.67049320e-01\n",
      " 4.68962585e-01 4.68962585e-01 4.85331633e-01 4.85331633e-01\n",
      " 4.99149660e-01 4.99149660e-01 5.07440476e-01 5.07440476e-01\n",
      " 5.20833333e-01 5.20833333e-01 5.49957483e-01 5.49957483e-01\n",
      " 5.92049320e-01 5.92049320e-01 6.01615646e-01 6.01615646e-01\n",
      " 6.06079932e-01 6.06079932e-01 6.27551020e-01 6.27551020e-01\n",
      " 6.37755102e-01 6.37755102e-01 6.44770408e-01 6.44770408e-01\n",
      " 6.65603741e-01 6.65603741e-01 6.69217687e-01 6.69217687e-01\n",
      " 6.94515306e-01 6.94515306e-01 6.99192177e-01 6.99192177e-01\n",
      " 7.17261905e-01 7.17261905e-01 7.20025510e-01 7.20025510e-01\n",
      " 7.23001701e-01 7.23001701e-01 7.38732993e-01 7.38732993e-01\n",
      " 7.39795918e-01 7.39795918e-01 7.49149660e-01 7.49149660e-01\n",
      " 7.91028912e-01 7.91028912e-01 8.78401361e-01 8.78826531e-01\n",
      " 9.31972789e-01 9.32397959e-01 9.59821429e-01 9.60246599e-01\n",
      " 1.00000000e+00]\n",
      "909\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa944d23e90>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "7.98 M, %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402caa07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '057a (main experiment)  - F2F 1'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, alldata, allimages, allindexpath, manipulation_type, transform = None):\n",
    "               \n",
    "        self.alldata = torch.load(alldata)\n",
    "        \n",
    "        self.folders = ['real', 'Deepfakes', 'Face2Face','FaceShifter','FaceSwap', 'NeuralTextures']\n",
    "        \n",
    "        self.transform = transform    \n",
    "        \n",
    "        print('Loading all images data')\n",
    "        \n",
    "        self.allimages = torch.load(allimages)\n",
    "        \n",
    "        print('Loading images complete')\n",
    "        \n",
    "        allindex = torch.load(allindexpath)\n",
    "        \n",
    "        self.allindex = allindex[manipulation_type]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return 1997\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        actualIndex = self.allindex[index]\n",
    "        \n",
    "        data = self.alldata[actualIndex]\n",
    "        \n",
    "        label = data['label']\n",
    "        \n",
    "        vidTensor = self.allimages[actualIndex]\n",
    "        \n",
    "        if(label != 0):\n",
    "            label = 1\n",
    "        \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "\n",
    "        return (vidTensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a8acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_types = ['real-deepfake' , 'real-f2f', 'real-faceshifter', 'real-faceswap', 'real-neuraltextures']\n",
    "\n",
    "manipulation = manipulation_types[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d14981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alldatapath = '/home/biometricgpu09/datasets/FF++/allData.pt'\n",
    "\n",
    "allimagespath = '/home/biometricgpu09/datasets/FF++/allImages.pt'\n",
    "\n",
    "allindexpath = '/home/biometricgpu09/datasets/FF++/allIndexes.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 1500\n",
    "num_samples_validation = 200\n",
    "num_samples_test = 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all images data\n",
      "Loading images complete\n"
     ]
    }
   ],
   "source": [
    "# dataset = FFClassification(rootPath, alldatapath, allimagespath,\n",
    "#                            allindexpath, manipulation, \n",
    "#                            transform = transformation)\n",
    "\n",
    "dataset = FFClassification(alldatapath, allimagespath,\n",
    "                           allindexpath, manipulation, \n",
    "                           transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "9\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.69485006 \n",
      "Epoch 1, Batch 20, Loss 0.69336932 \n",
      "Epoch 1, Batch 30, Loss 0.69243179 \n",
      "Epoch 1, Batch 40, Loss 0.69221623 \n",
      "Epoch 1, Batch 50, Loss 0.69108412 \n",
      "Epoch 1, Batch 60, Loss 0.68997834 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  2784\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.435\n",
      "---------\n",
      "Epoch time :  37.65453\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.900000000000001e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.69248710 \n",
      "Epoch 2, Batch 20, Loss 0.68483543 \n",
      "Epoch 2, Batch 30, Loss 0.68975810 \n",
      "Epoch 2, Batch 40, Loss 0.68454705 \n",
      "Epoch 2, Batch 50, Loss 0.68068256 \n",
      "Epoch 2, Batch 60, Loss 0.67578667 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4144\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.6475\n",
      "---------\n",
      "Epoch time :  30.452942\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.801e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.65913517 \n",
      "Epoch 3, Batch 20, Loss 0.65059566 \n",
      "Epoch 3, Batch 30, Loss 0.62866347 \n",
      "Epoch 3, Batch 40, Loss 0.60117535 \n",
      "Epoch 3, Batch 50, Loss 0.57104940 \n",
      "Epoch 3, Batch 60, Loss 0.53930045 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  3651\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.57046875\n",
      "---------\n",
      "Epoch time :  30.027878\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.70299e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.50560442 \n",
      "Epoch 4, Batch 20, Loss 0.46828837 \n",
      "Epoch 4, Batch 30, Loss 0.41638599 \n",
      "Epoch 4, Batch 40, Loss 0.40372573 \n",
      "Epoch 4, Batch 50, Loss 0.34547007 \n",
      "Epoch 4, Batch 60, Loss 0.35976008 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4953\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.77390625\n",
      "---------\n",
      "Epoch time :  30.504714\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.605960100000001e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.34303906 \n",
      "Epoch 5, Batch 20, Loss 0.30394990 \n",
      "Epoch 5, Batch 30, Loss 0.32637549 \n",
      "Epoch 5, Batch 40, Loss 0.29285994 \n",
      "Epoch 5, Batch 50, Loss 0.32137087 \n",
      "Epoch 5, Batch 60, Loss 0.27717649 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4578\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.7153125\n",
      "---------\n",
      "Epoch time :  30.599965\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.509900499000001e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.30993878 \n",
      "Epoch 6, Batch 20, Loss 0.28057706 \n",
      "Epoch 6, Batch 30, Loss 0.26497697 \n",
      "Epoch 6, Batch 40, Loss 0.29055313 \n",
      "Epoch 6, Batch 50, Loss 0.20808845 \n",
      "Epoch 6, Batch 60, Loss 0.28170018 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4649\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.72640625\n",
      "---------\n",
      "Epoch time :  30.379948\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.414801494010001e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.26674518 \n",
      "Epoch 7, Batch 20, Loss 0.23094614 \n",
      "Epoch 7, Batch 30, Loss 0.19219164 \n",
      "Epoch 7, Batch 40, Loss 0.24857401 \n",
      "Epoch 7, Batch 50, Loss 0.19838474 \n",
      "Epoch 7, Batch 60, Loss 0.26149153 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5895\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92109375\n",
      "---------\n",
      "Epoch time :  30.479574\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.320653479069902e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.19714294 \n",
      "Epoch 8, Batch 20, Loss 0.25426702 \n",
      "Epoch 8, Batch 30, Loss 0.20428615 \n",
      "Epoch 8, Batch 40, Loss 0.27661015 \n",
      "Epoch 8, Batch 50, Loss 0.23322094 \n",
      "Epoch 8, Batch 60, Loss 0.20506996 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5840\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9125\n",
      "---------\n",
      "Epoch time :  30.979961\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.227446944279203e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.25092469 \n",
      "Epoch 9, Batch 20, Loss 0.17519700 \n",
      "Epoch 9, Batch 30, Loss 0.19322360 \n",
      "Epoch 9, Batch 40, Loss 0.14782356 \n",
      "Epoch 9, Batch 50, Loss 0.18782851 \n",
      "Epoch 9, Batch 60, Loss 0.18497414 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5910\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9234375\n",
      "---------\n",
      "Epoch time :  30.794284\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.13517247483641e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.15532175 \n",
      "Epoch 10, Batch 20, Loss 0.17664500 \n",
      "Epoch 10, Batch 30, Loss 0.18659241 \n",
      "Epoch 10, Batch 40, Loss 0.15279040 \n",
      "Epoch 10, Batch 50, Loss 0.18912212 \n",
      "Epoch 10, Batch 60, Loss 0.14273404 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5732\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.895625\n",
      "---------\n",
      "Epoch time :  30.143216\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.043820750088047e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.21566344 \n",
      "Epoch 11, Batch 20, Loss 0.12846311 \n",
      "Epoch 11, Batch 30, Loss 0.17992881 \n",
      "Epoch 11, Batch 40, Loss 0.15797904 \n",
      "Epoch 11, Batch 50, Loss 0.18845635 \n",
      "Epoch 11, Batch 60, Loss 0.17281749 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6077\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94953125\n",
      "---------\n",
      "Epoch time :  31.247683\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.953382542587167e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.14339108 \n",
      "Epoch 12, Batch 20, Loss 0.13904321 \n",
      "Epoch 12, Batch 30, Loss 0.30202011 \n",
      "Epoch 12, Batch 40, Loss 0.11482289 \n",
      "Epoch 12, Batch 50, Loss 0.15695957 \n",
      "Epoch 12, Batch 60, Loss 0.14853740 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5811\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.90796875\n",
      "---------\n",
      "Epoch time :  31.314063\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.863848717161295e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.19008258 \n",
      "Epoch 13, Batch 20, Loss 0.14553454 \n",
      "Epoch 13, Batch 30, Loss 0.11609361 \n",
      "Epoch 13, Batch 40, Loss 0.14676565 \n",
      "Epoch 13, Batch 50, Loss 0.13855575 \n",
      "Epoch 13, Batch 60, Loss 0.14616876 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6003\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93796875\n",
      "---------\n",
      "Epoch time :  30.251361\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.775210229989682e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.15149146 \n",
      "Epoch 14, Batch 20, Loss 0.13390112 \n",
      "Epoch 14, Batch 30, Loss 0.14294238 \n",
      "Epoch 14, Batch 40, Loss 0.11546815 \n",
      "Epoch 14, Batch 50, Loss 0.12030027 \n",
      "Epoch 14, Batch 60, Loss 0.17141144 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5622\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8784375\n",
      "---------\n",
      "Epoch time :  30.868513\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.687458127689785e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.09357540 \n",
      "Epoch 15, Batch 20, Loss 0.16062011 \n",
      "Epoch 15, Batch 30, Loss 0.12554599 \n",
      "Epoch 15, Batch 40, Loss 0.12017947 \n",
      "Epoch 15, Batch 50, Loss 0.15688610 \n",
      "Epoch 15, Batch 60, Loss 0.08261875 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5956\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.930625\n",
      "---------\n",
      "Epoch time :  30.490675\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.600583546412887e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.14460044 \n",
      "Epoch 16, Batch 20, Loss 0.09711561 \n",
      "Epoch 16, Batch 30, Loss 0.13530825 \n",
      "Epoch 16, Batch 40, Loss 0.16316640 \n",
      "Epoch 16, Batch 50, Loss 0.10632954 \n",
      "Epoch 16, Batch 60, Loss 0.10684844 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5730\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8953125\n",
      "---------\n",
      "Epoch time :  30.173021\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.514577710948758e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.10288732 \n",
      "Epoch 17, Batch 20, Loss 0.11411999 \n",
      "Epoch 17, Batch 30, Loss 0.13366748 \n",
      "Epoch 17, Batch 40, Loss 0.10902094 \n",
      "Epoch 17, Batch 50, Loss 0.09608680 \n",
      "Epoch 17, Batch 60, Loss 0.10774047 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6012\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.939375\n",
      "---------\n",
      "Epoch time :  30.761668\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.429431933839271e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.18404213 \n",
      "Epoch 18, Batch 20, Loss 0.07961344 \n",
      "Epoch 18, Batch 30, Loss 0.10138870 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 40, Loss 0.09253847 \n",
      "Epoch 18, Batch 50, Loss 0.09578316 \n",
      "Epoch 18, Batch 60, Loss 0.08154915 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6016\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94\n",
      "---------\n",
      "Epoch time :  30.736237\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.345137614500879e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.10223948 \n",
      "Epoch 19, Batch 20, Loss 0.08421389 \n",
      "Epoch 19, Batch 30, Loss 0.09215425 \n",
      "Epoch 19, Batch 40, Loss 0.13839242 \n",
      "Epoch 19, Batch 50, Loss 0.09659230 \n",
      "Epoch 19, Batch 60, Loss 0.08779733 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6008\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93875\n",
      "---------\n",
      "Epoch time :  30.854933\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.26168623835587e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.08659439 \n",
      "Epoch 20, Batch 20, Loss 0.08993110 \n",
      "Epoch 20, Batch 30, Loss 0.09452067 \n",
      "Epoch 20, Batch 40, Loss 0.09972453 \n",
      "Epoch 20, Batch 50, Loss 0.06589812 \n",
      "Epoch 20, Batch 60, Loss 0.11585149 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5970\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9328125\n",
      "---------\n",
      "Epoch time :  30.637685\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.17906937597231e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.07258726 \n",
      "Epoch 21, Batch 20, Loss 0.08293904 \n",
      "Epoch 21, Batch 30, Loss 0.08947560 \n",
      "Epoch 21, Batch 40, Loss 0.07038039 \n",
      "Epoch 21, Batch 50, Loss 0.06551636 \n",
      "Epoch 21, Batch 60, Loss 0.06291768 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6037\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94328125\n",
      "---------\n",
      "Epoch time :  30.860477\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.097278682212587e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.07053669 \n",
      "Epoch 22, Batch 20, Loss 0.10107449 \n",
      "Epoch 22, Batch 30, Loss 0.10444623 \n",
      "Epoch 22, Batch 40, Loss 0.12443952 \n",
      "Epoch 22, Batch 50, Loss 0.06638087 \n",
      "Epoch 22, Batch 60, Loss 0.09343812 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6085\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95078125\n",
      "---------\n",
      "Epoch time :  30.843901\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.016305895390461e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.09149580 \n",
      "Epoch 23, Batch 20, Loss 0.07762352 \n",
      "Epoch 23, Batch 30, Loss 0.06959904 \n",
      "Epoch 23, Batch 40, Loss 0.05251413 \n",
      "Epoch 23, Batch 50, Loss 0.07623450 \n",
      "Epoch 23, Batch 60, Loss 0.11893573 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6093\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95203125\n",
      "---------\n",
      "Epoch time :  31.02164\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.936142836436556e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.05228391 \n",
      "Epoch 24, Batch 20, Loss 0.04751728 \n",
      "Epoch 24, Batch 30, Loss 0.07742979 \n",
      "Epoch 24, Batch 40, Loss 0.08696743 \n",
      "Epoch 24, Batch 50, Loss 0.05877783 \n",
      "Epoch 24, Batch 60, Loss 0.05824561 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5624\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.87875\n",
      "---------\n",
      "Epoch time :  30.498452\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.856781408072191e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.06038132 \n",
      "Epoch 25, Batch 20, Loss 0.05754007 \n",
      "Epoch 25, Batch 30, Loss 0.06645202 \n",
      "Epoch 25, Batch 40, Loss 0.11983177 \n",
      "Epoch 25, Batch 50, Loss 0.09348016 \n",
      "Epoch 25, Batch 60, Loss 0.08369455 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4953\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.77390625\n",
      "---------\n",
      "Epoch time :  30.443394\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.778213593991469e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.17145358 \n",
      "Epoch 26, Batch 20, Loss 0.10415783 \n",
      "Epoch 26, Batch 30, Loss 0.10149545 \n",
      "Epoch 26, Batch 40, Loss 0.08421585 \n",
      "Epoch 26, Batch 50, Loss 0.05739801 \n",
      "Epoch 26, Batch 60, Loss 0.12125046 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4506\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.7040625\n",
      "---------\n",
      "Epoch time :  30.86078\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.700431458051554e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.05014965 \n",
      "Epoch 27, Batch 20, Loss 0.08772862 \n",
      "Epoch 27, Batch 30, Loss 0.05740459 \n",
      "Epoch 27, Batch 40, Loss 0.06174793 \n",
      "Epoch 27, Batch 50, Loss 0.06125724 \n",
      "Epoch 27, Batch 60, Loss 0.07384207 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6027\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94171875\n",
      "---------\n",
      "Epoch time :  30.724882\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.623427143471038e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.07196574 \n",
      "Epoch 28, Batch 20, Loss 0.07219825 \n",
      "Epoch 28, Batch 30, Loss 0.05896202 \n",
      "Epoch 28, Batch 40, Loss 0.04234392 \n",
      "Epoch 28, Batch 50, Loss 0.04922398 \n",
      "Epoch 28, Batch 60, Loss 0.05571185 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6102\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9534375\n",
      "---------\n",
      "Epoch time :  30.972312\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.547192872036328e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.05246590 \n",
      "Epoch 29, Batch 20, Loss 0.04789716 \n",
      "Epoch 29, Batch 30, Loss 0.03212975 \n",
      "Epoch 29, Batch 40, Loss 0.03445675 \n",
      "Epoch 29, Batch 50, Loss 0.05139490 \n",
      "Epoch 29, Batch 60, Loss 0.05880951 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5821\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.90953125\n",
      "---------\n",
      "Epoch time :  30.606209\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.471720943315964e-05]\n",
      "------------------------\n",
      "Epoch 30, Batch 10, Loss 0.04724213 \n",
      "Epoch 30, Batch 20, Loss 0.07806476 \n",
      "Epoch 30, Batch 30, Loss 0.04263217 \n",
      "Epoch 30, Batch 40, Loss 0.04909568 \n",
      "Epoch 30, Batch 50, Loss 0.03583542 \n",
      "Epoch 30, Batch 60, Loss 0.05264087 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6043\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94421875\n",
      "---------\n",
      "Epoch time :  30.900916\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.397003733882805e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  9203\n",
      "Total :  9504\n",
      "Test accuracy is  0.9683291245791246\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4990  162]\n",
      " [ 139 4213]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9362435215021729\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9629714285714286, 0.9680606617647058, 0.9655093388335052)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9917807476251371\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9683291245791246,\n",
       " 'precision': 0.9629714285714286,\n",
       " 'recall': 0.9680606617647058,\n",
       " 'f1': 0.9655093388335052,\n",
       " 'auc': 0.9917807476251371,\n",
       " 'mcc': 0.9362435215021729}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.07375919 0.08754596 0.09443934 0.10087316 0.10477941\n",
      " 0.10707721 0.10960478 0.11144301 0.11236213 0.11443015 0.11672794\n",
      " 0.11879596 0.11925551 0.12086397 0.12293199 0.12362132 0.12454044\n",
      " 0.1261489  0.12729779 0.12913603 0.13005515 0.1316636  0.13258272\n",
      " 0.13327206 0.13488051 0.13625919 0.13740809 0.13809743 0.13924632\n",
      " 0.14131434 0.14407169 0.14545037 0.14682904 0.14820772 0.1484375\n",
      " 0.14981618 0.15073529 0.15188419 0.15280331 0.15395221 0.15487132\n",
      " 0.15533088 0.15625    0.15716912 0.15854779 0.15923713 0.16038603\n",
      " 0.16084559 0.16176471 0.16268382 0.1629136  0.16429228 0.1652114\n",
      " 0.16590074 0.16636029 0.16704963 0.16750919 0.16773897 0.16842831\n",
      " 0.16865809 0.17003676 0.17141544 0.17164522 0.17256434 0.17371324\n",
      " 0.17417279 0.17486213 0.17532169 0.17555147 0.17601103 0.17693015\n",
      " 0.17761949 0.1785386  0.17899816 0.17991728 0.18106618 0.18175551\n",
      " 0.18198529 0.18244485 0.18267463 0.18359375 0.18451287 0.18681066\n",
      " 0.18704044 0.18795956 0.18818934 0.19002757 0.19071691 0.19094669\n",
      " 0.19232537 0.19301471 0.19347426 0.19485294 0.19508272 0.19554228\n",
      " 0.19623162 0.19715074 0.19738051 0.19784007 0.19852941 0.19875919\n",
      " 0.19921875 0.19967831 0.20013787 0.20059743 0.20105699 0.20174632\n",
      " 0.20289522 0.20335478 0.20496324 0.20542279 0.20588235 0.20634191\n",
      " 0.20657169 0.20749081 0.20863971 0.20955882 0.21116728 0.2120864\n",
      " 0.21231618 0.21323529 0.21461397 0.21645221 0.21714154 0.21829044\n",
      " 0.21852022 0.21920956 0.2198989  0.22035846 0.22104779 0.22150735\n",
      " 0.22196691 0.22242647 0.22265625 0.22311581 0.22334559 0.22472426\n",
      " 0.22564338 0.22587316 0.2277114  0.22886029 0.22977941 0.23092831\n",
      " 0.23161765 0.23184743 0.23368566 0.23391544 0.234375   0.23483456\n",
      " 0.23529412 0.23575368 0.23621324 0.23690257 0.23736213 0.23759191\n",
      " 0.23805147 0.23851103 0.23897059 0.23920037 0.23965993 0.23988971\n",
      " 0.24080882 0.24126838 0.24172794 0.24264706 0.24310662 0.24402574\n",
      " 0.24448529 0.24471507 0.24540441 0.24563419 0.24609375 0.24678309\n",
      " 0.24747243 0.24793199 0.2488511  0.24931066 0.25091912 0.25137868\n",
      " 0.25206801 0.25298713 0.25528493 0.25574449 0.25620404 0.25689338\n",
      " 0.25735294 0.25804228 0.25850184 0.25919118 0.26011029 0.26056985\n",
      " 0.26148897 0.26217831 0.26309743 0.26355699 0.26401654 0.26470588\n",
      " 0.26516544 0.26539522 0.26585478 0.26631434 0.2667739  0.26930147\n",
      " 0.27022059 0.27068015 0.27182904 0.2722886  0.27665441 0.27711397\n",
      " 0.27918199 0.27964154 0.28033088 0.28079044 0.28102022 0.2823989\n",
      " 0.28262868 0.28308824 0.28492647 0.28561581 0.28653493 0.28722426\n",
      " 0.28768382 0.28814338 0.28883272 0.29090074 0.29136029 0.29181985\n",
      " 0.29227941 0.29319853 0.29365809 0.296875   0.29733456 0.30078125\n",
      " 0.30147059 0.30284926 0.30376838 0.30698529 0.30744485 0.30882353\n",
      " 0.30951287 0.31043199 0.31089154 0.31318934 0.31410846 0.31502757\n",
      " 0.31548713 0.31732537 0.31778493 0.3191636  0.31985294 0.3214614\n",
      " 0.32192096 0.32306985 0.32375919 0.32398897 0.32444853 0.32628676\n",
      " 0.3269761  0.32950368 0.33042279 0.33065257 0.33111213 0.33318015\n",
      " 0.33363971 0.33432904 0.3347886  0.33547794 0.3359375  0.34237132\n",
      " 0.34329044 0.34375    0.34420956 0.34742647 0.34788603 0.35133272\n",
      " 0.35179228 0.35753676 0.35799632 0.35868566 0.35914522 0.37109375\n",
      " 0.37155331 0.37316176 0.37362132 0.38005515 0.38051471 0.38235294\n",
      " 0.38327206 0.38350184 0.3839614  0.39246324 0.39315257 0.40211397\n",
      " 0.40211397 0.40280331 0.40326287 0.40556066 0.40602022 0.41107537\n",
      " 0.41153493 0.41452206 0.41498162 0.43313419 0.43405331 0.44301471\n",
      " 0.44347426 0.44875919 0.44921875 0.45381434 0.4542739  0.45909926\n",
      " 0.4597886  0.46484375 0.46530331 0.47035846 0.47081801 0.47265625\n",
      " 0.47311581 0.47909007 0.47954963 0.48460478 0.48506434 0.49402574\n",
      " 0.49448529 0.49747243 0.49793199 0.50091912 0.50137868 0.50183824\n",
      " 0.50183824 0.50321691 0.50367647 0.51309743 0.51355699 0.51470588\n",
      " 0.51470588 0.52274816 0.52320772 0.52366728 0.52412684 0.54067096\n",
      " 0.54113051 0.55147059 0.55193015 0.57306985 0.57352941 0.57628676\n",
      " 0.57674632 0.60018382 0.60064338 0.60477941 0.60523897 0.61259191\n",
      " 0.61305147 0.62293199 0.62293199 0.62752757 0.62798713 0.64568015\n",
      " 0.64613971 0.65418199 0.65464154 0.65556066 0.65602022 0.6629136\n",
      " 0.6629136  0.68681066 0.68681066 0.71415441 0.71461397 0.74080882\n",
      " 0.74080882 0.75919118 0.75919118 0.81020221 0.81020221 0.81847426\n",
      " 0.81847426 0.84329044 0.84329044 0.85776654 0.85776654 0.86190257\n",
      " 0.86190257 0.86810662 0.86810662 0.86879596 0.86879596 0.88327206\n",
      " 0.88327206 0.88534007 0.88534007 0.89200368 0.89200368 0.8984375\n",
      " 0.8984375  0.90027574 0.90027574 0.90303309 0.90303309 0.90418199\n",
      " 0.90418199 0.90487132 0.90487132 0.90625    0.90625    0.90670956\n",
      " 0.90670956 0.9073989  0.9073989  0.90992647 0.90992647 0.91153493\n",
      " 0.91153493 0.91314338 0.91314338 0.91498162 0.91498162 0.91567096\n",
      " 0.91567096 0.91773897 0.91773897 0.91842831 0.91842831 0.9207261\n",
      " 0.9207261  0.9230239  0.9230239  0.92440257 0.92440257 0.92463235\n",
      " 0.92463235 0.92761949 0.92761949 0.92922794 0.92922794 0.9296875\n",
      " 0.9296875  0.92991728 0.92991728 0.93106618 0.93106618 0.93129596\n",
      " 0.93129596 0.93290441 0.93290441 0.93336397 0.93336397 0.93451287\n",
      " 0.93451287 0.93474265 0.93474265 0.93520221 0.93520221 0.93543199\n",
      " 0.93543199 0.93566176 0.93566176 0.93681066 0.93681066 0.9375\n",
      " 0.9375     0.93772978 0.93772978 0.93818934 0.93818934 0.93841912\n",
      " 0.93841912 0.93910846 0.93910846 0.94025735 0.94025735 0.94186581\n",
      " 0.94186581 0.94347426 0.94347426 0.94393382 0.94393382 0.9441636\n",
      " 0.9441636  0.94462316 0.94462316 0.94485294 0.94485294 0.94554228\n",
      " 0.94554228 0.94692096 0.94692096 0.94715074 0.94715074 0.94806985\n",
      " 0.94806985 0.94944853 0.94944853 0.94967831 0.94967831 0.95036765\n",
      " 0.95036765 0.95059743 0.95059743 0.95082721 0.95082721 0.95151654\n",
      " 0.95151654 0.95174632 0.95174632 0.9519761  0.9519761  0.95243566\n",
      " 0.95243566 0.953125   0.953125   0.95404412 0.95404412 0.9542739\n",
      " 0.9542739  0.95450368 0.95450368 0.95473346 0.95473346 0.95542279\n",
      " 0.95542279 0.95565257 0.95565257 0.95611213 0.95611213 0.95657169\n",
      " 0.95657169 0.95680147 0.95680147 0.95772059 0.95772059 0.95795037\n",
      " 0.95795037 0.95818015 0.95818015 0.95840993 0.95840993 0.95863971\n",
      " 0.95863971 0.95932904 0.95932904 0.96116728 0.96116728 0.96231618\n",
      " 0.96231618 0.96254596 0.96254596 0.96300551 0.96300551 0.96323529\n",
      " 0.96323529 0.96346507 0.96346507 0.96369485 0.96369485 0.96415441\n",
      " 0.96415441 0.96461397 0.96461397 0.96484375 0.96484375 0.96507353\n",
      " 0.96507353 0.96599265 0.96599265 0.96668199 0.96668199 0.96691176\n",
      " 0.96691176 0.96737132 0.96737132 0.96806066 0.96806066 0.96829044\n",
      " 0.96829044 0.96852022 0.96852022 0.96897978 0.96897978 0.96920956\n",
      " 0.96920956 0.96966912 0.96966912 0.9698989  0.9698989  0.97012868\n",
      " 0.97012868 0.97035846 0.97035846 0.97058824 0.97058824 0.97081801\n",
      " 0.97081801 0.97104779 0.97104779 0.97150735 0.97150735 0.97173713\n",
      " 0.97173713 0.97219669 0.97219669 0.97288603 0.97288603 0.97311581\n",
      " 0.97311581 0.97334559 0.97334559 0.97357537 0.97357537 0.97403493\n",
      " 0.97403493 0.97426471 0.97426471 0.97472426 0.97472426 0.97495404\n",
      " 0.97495404 0.97518382 0.97518382 0.9754136  0.9754136  0.97564338\n",
      " 0.97564338 0.97587316 0.97587316 0.97610294 0.97610294 0.97633272\n",
      " 0.97633272 0.97679228 0.97679228 0.97702206 0.97702206 0.97725184\n",
      " 0.97725184 0.97748162 0.97748162 0.9777114  0.9777114  0.97794118\n",
      " 0.97794118 0.97817096 0.97817096 0.97840074 0.97840074 0.97863051\n",
      " 0.97863051 0.97886029 0.97886029 0.97909007 0.97909007 0.97931985\n",
      " 0.97931985 0.97954963 0.97954963 0.97977941 0.97977941 0.98000919\n",
      " 0.98000919 0.98023897 0.98023897 0.98046875 0.98046875 0.98069853\n",
      " 0.98069853 0.98092831 0.98092831 0.98138787 0.98138787 0.98161765\n",
      " 0.98161765 0.98184743 0.98184743 0.98230699 0.98230699 0.98253676\n",
      " 0.98253676 0.98276654 0.98276654 0.98299632 0.98299632 0.9832261\n",
      " 0.9832261  0.98345588 0.98345588 0.98368566 0.98368566 0.98391544\n",
      " 0.98391544 0.98414522 0.98414522 0.984375   0.984375   0.98460478\n",
      " 0.98460478 0.98483456 0.98483456 0.98506434 0.98506434 0.9855239\n",
      " 0.9855239  0.98575368 0.98575368 0.98598346 0.98598346 0.98621324\n",
      " 0.98621324 0.98644301 0.98644301 0.98667279 0.98667279 0.98690257\n",
      " 0.98690257 0.98713235 0.98713235 0.98736213 0.98736213 0.98759191\n",
      " 0.98759191 0.98782169 0.98782169 0.98805147 0.98805147 0.98828125\n",
      " 0.98828125 0.98851103 0.98851103 0.98874081 0.98874081 0.98897059\n",
      " 0.98897059 0.98920037 0.98920037 0.98943015 0.98943015 0.98965993\n",
      " 0.98965993 0.98988971 0.98988971 0.99011949 0.99011949 0.99034926\n",
      " 0.99034926 0.99057904 0.99057904 0.99080882 0.99080882 0.9910386\n",
      " 0.9910386  0.9910386  0.9910386  0.99126838 0.99126838 0.99149816\n",
      " 0.99149816 0.99172794 0.99172794 0.99195772 0.99195772 0.9921875\n",
      " 0.9921875  0.99241728 0.99241728 0.99264706 0.99264706 0.99287684\n",
      " 0.99287684 0.99310662 0.99310662 0.9933364  0.9933364  0.99356618\n",
      " 0.99356618 0.99379596 0.99379596 0.99402574 0.99402574 0.99425551\n",
      " 0.99425551 0.99448529 0.99448529 0.99471507 0.99471507 0.99517463\n",
      " 0.99517463 0.99540441 0.99540441 0.99563419 0.99563419 0.99609375\n",
      " 0.99609375 0.99632353 0.99632353 0.99655331 0.99655331 0.99678309\n",
      " 0.99678309 0.99701287 0.99701287 0.99724265 0.99724265 0.99747243\n",
      " 0.99747243 0.99770221 0.99770221 0.99793199 0.99793199 0.99816176\n",
      " 0.99816176 0.99839154 0.99839154 0.99862132 0.99862132 0.9988511\n",
      " 0.9988511  0.99908088 0.99908088 0.99931066 0.99931066 0.99954044\n",
      " 0.99954044 0.99977022 0.99977022 1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 1.94099379e-04 1.94099379e-04\n",
      " 1.94099379e-04 1.94099379e-04 3.88198758e-04 3.88198758e-04\n",
      " 3.88198758e-04 3.88198758e-04 3.88198758e-04 3.88198758e-04\n",
      " 5.82298137e-04 5.82298137e-04 5.82298137e-04 5.82298137e-04\n",
      " 5.82298137e-04 5.82298137e-04 5.82298137e-04 5.82298137e-04\n",
      " 5.82298137e-04 5.82298137e-04 5.82298137e-04 5.82298137e-04\n",
      " 5.82298137e-04 5.82298137e-04 5.82298137e-04 5.82298137e-04\n",
      " 5.82298137e-04 5.82298137e-04 5.82298137e-04 5.82298137e-04\n",
      " 7.76397516e-04 7.76397516e-04 7.76397516e-04 7.76397516e-04\n",
      " 7.76397516e-04 7.76397516e-04 7.76397516e-04 7.76397516e-04\n",
      " 7.76397516e-04 7.76397516e-04 9.70496894e-04 9.70496894e-04\n",
      " 1.16459627e-03 1.16459627e-03 1.16459627e-03 1.16459627e-03\n",
      " 1.35869565e-03 1.35869565e-03 1.55279503e-03 1.55279503e-03\n",
      " 1.74689441e-03 1.74689441e-03 1.94099379e-03 1.94099379e-03\n",
      " 2.13509317e-03 2.13509317e-03 2.32919255e-03 2.32919255e-03\n",
      " 2.52329193e-03 2.52329193e-03 2.71739130e-03 2.71739130e-03\n",
      " 2.91149068e-03 2.91149068e-03 3.10559006e-03 3.10559006e-03\n",
      " 3.29968944e-03 3.29968944e-03 3.49378882e-03 3.49378882e-03\n",
      " 3.68788820e-03 3.68788820e-03 3.88198758e-03 3.88198758e-03\n",
      " 4.07608696e-03 4.07608696e-03 4.27018634e-03 4.27018634e-03\n",
      " 4.46428571e-03 4.46428571e-03 4.85248447e-03 4.85248447e-03\n",
      " 5.04658385e-03 5.04658385e-03 5.24068323e-03 5.24068323e-03\n",
      " 5.43478261e-03 5.43478261e-03 5.62888199e-03 5.62888199e-03\n",
      " 5.82298137e-03 5.82298137e-03 6.01708075e-03 6.01708075e-03\n",
      " 6.21118012e-03 6.21118012e-03 6.40527950e-03 6.40527950e-03\n",
      " 6.59937888e-03 6.59937888e-03 6.79347826e-03 6.79347826e-03\n",
      " 6.98757764e-03 6.98757764e-03 7.18167702e-03 7.18167702e-03\n",
      " 7.37577640e-03 7.37577640e-03 7.56987578e-03 7.56987578e-03\n",
      " 7.76397516e-03 7.76397516e-03 8.15217391e-03 8.15217391e-03\n",
      " 8.34627329e-03 8.34627329e-03 8.54037267e-03 8.54037267e-03\n",
      " 8.73447205e-03 8.73447205e-03 9.31677019e-03 9.31677019e-03\n",
      " 9.51086957e-03 9.51086957e-03 9.70496894e-03 9.70496894e-03\n",
      " 9.89906832e-03 9.89906832e-03 1.00931677e-02 1.00931677e-02\n",
      " 1.02872671e-02 1.02872671e-02 1.04813665e-02 1.04813665e-02\n",
      " 1.06754658e-02 1.06754658e-02 1.08695652e-02 1.08695652e-02\n",
      " 1.10636646e-02 1.10636646e-02 1.16459627e-02 1.16459627e-02\n",
      " 1.22282609e-02 1.22282609e-02 1.24223602e-02 1.24223602e-02\n",
      " 1.28105590e-02 1.28105590e-02 1.30046584e-02 1.30046584e-02\n",
      " 1.31987578e-02 1.31987578e-02 1.35869565e-02 1.35869565e-02\n",
      " 1.37810559e-02 1.37810559e-02 1.39751553e-02 1.39751553e-02\n",
      " 1.57220497e-02 1.57220497e-02 1.64984472e-02 1.64984472e-02\n",
      " 1.68866460e-02 1.68866460e-02 1.72748447e-02 1.72748447e-02\n",
      " 1.74689441e-02 1.74689441e-02 1.78571429e-02 1.78571429e-02\n",
      " 1.80512422e-02 1.80512422e-02 1.82453416e-02 1.82453416e-02\n",
      " 1.84394410e-02 1.84394410e-02 1.88276398e-02 1.88276398e-02\n",
      " 1.90217391e-02 1.90217391e-02 1.92158385e-02 1.92158385e-02\n",
      " 1.94099379e-02 1.94099379e-02 1.97981366e-02 1.97981366e-02\n",
      " 2.03804348e-02 2.03804348e-02 2.05745342e-02 2.05745342e-02\n",
      " 2.07686335e-02 2.07686335e-02 2.09627329e-02 2.09627329e-02\n",
      " 2.13509317e-02 2.13509317e-02 2.17391304e-02 2.17391304e-02\n",
      " 2.19332298e-02 2.19332298e-02 2.21273292e-02 2.21273292e-02\n",
      " 2.25155280e-02 2.25155280e-02 2.27096273e-02 2.27096273e-02\n",
      " 2.29037267e-02 2.29037267e-02 2.32919255e-02 2.32919255e-02\n",
      " 2.34860248e-02 2.34860248e-02 2.40683230e-02 2.40683230e-02\n",
      " 2.42624224e-02 2.42624224e-02 2.48447205e-02 2.48447205e-02\n",
      " 2.50388199e-02 2.50388199e-02 2.52329193e-02 2.52329193e-02\n",
      " 2.56211180e-02 2.56211180e-02 2.60093168e-02 2.60093168e-02\n",
      " 2.62034161e-02 2.62034161e-02 2.65916149e-02 2.65916149e-02\n",
      " 2.81444099e-02 2.81444099e-02 2.83385093e-02 2.83385093e-02\n",
      " 2.85326087e-02 2.85326087e-02 2.87267081e-02 2.87267081e-02\n",
      " 2.95031056e-02 2.95031056e-02 2.96972050e-02 2.96972050e-02\n",
      " 3.00854037e-02 3.00854037e-02 3.06677019e-02 3.06677019e-02\n",
      " 3.08618012e-02 3.08618012e-02 3.16381988e-02 3.16381988e-02\n",
      " 3.20263975e-02 3.20263975e-02 3.24145963e-02 3.24145963e-02\n",
      " 3.26086957e-02 3.26086957e-02 3.39673913e-02 3.39673913e-02\n",
      " 3.41614907e-02 3.41614907e-02 3.43555901e-02 3.43555901e-02\n",
      " 3.47437888e-02 3.47437888e-02 3.61024845e-02 3.61024845e-02\n",
      " 3.68788820e-02 3.68788820e-02 3.74611801e-02 3.74611801e-02\n",
      " 3.80434783e-02 3.80434783e-02 3.88198758e-02 3.88198758e-02\n",
      " 3.92080745e-02 3.92080745e-02 3.94021739e-02 3.94021739e-02\n",
      " 3.95962733e-02 3.95962733e-02 3.99844720e-02 3.99844720e-02\n",
      " 4.01785714e-02 4.01785714e-02 4.03726708e-02 4.03726708e-02\n",
      " 4.05667702e-02 4.05667702e-02 4.09549689e-02 4.09549689e-02\n",
      " 4.13431677e-02 4.13431677e-02 4.21195652e-02 4.21195652e-02\n",
      " 4.23136646e-02 4.23136646e-02 4.30900621e-02 4.30900621e-02\n",
      " 4.52251553e-02 4.52251553e-02 4.56133540e-02 4.56133540e-02\n",
      " 4.58074534e-02 4.58074534e-02 4.61956522e-02 4.61956522e-02\n",
      " 4.67779503e-02 4.67779503e-02 4.94953416e-02 4.94953416e-02\n",
      " 5.00776398e-02 5.00776398e-02 5.16304348e-02 5.16304348e-02\n",
      " 5.24068323e-02 5.24068323e-02 5.37655280e-02 5.37655280e-02\n",
      " 5.41537267e-02 5.41537267e-02 5.76475155e-02 5.76475155e-02\n",
      " 5.80357143e-02 5.80357143e-02 5.82298137e-02 5.82298137e-02\n",
      " 5.93944099e-02 5.93944099e-02 5.95885093e-02 5.95885093e-02\n",
      " 5.97826087e-02 5.97826087e-02 6.30822981e-02 6.30822981e-02\n",
      " 6.85170807e-02 6.85170807e-02 6.94875776e-02 6.94875776e-02\n",
      " 7.23990683e-02 7.23990683e-02 7.27872671e-02 7.27872671e-02\n",
      " 7.43400621e-02 7.43400621e-02 7.58928571e-02 7.58928571e-02\n",
      " 7.80279503e-02 7.80279503e-02 7.86102484e-02 7.86102484e-02\n",
      " 7.99689441e-02 7.99689441e-02 8.17158385e-02 8.17158385e-02\n",
      " 8.22981366e-02 8.22981366e-02 8.46273292e-02 8.46273292e-02\n",
      " 8.71506211e-02 8.71506211e-02 8.79270186e-02 8.79270186e-02\n",
      " 8.88975155e-02 8.88975155e-02 9.45263975e-02 9.45263975e-02\n",
      " 1.02678571e-01 1.02678571e-01 1.03066770e-01 1.03066770e-01\n",
      " 1.05395963e-01 1.05395963e-01 1.07919255e-01 1.07919255e-01\n",
      " 1.12383540e-01 1.12383540e-01 1.14518634e-01 1.14518634e-01\n",
      " 1.14712733e-01 1.14712733e-01 1.17818323e-01 1.17818323e-01\n",
      " 1.21894410e-01 1.21894410e-01 1.23059006e-01 1.23059006e-01\n",
      " 1.25582298e-01 1.25582298e-01 1.26746894e-01 1.26746894e-01\n",
      " 1.28493789e-01 1.28493789e-01 1.30822981e-01 1.30822981e-01\n",
      " 1.31599379e-01 1.31599379e-01 1.34316770e-01 1.34316770e-01\n",
      " 1.43051242e-01 1.43051242e-01 1.48097826e-01 1.48097826e-01\n",
      " 1.48291925e-01 1.48291925e-01 1.49262422e-01 1.49262422e-01\n",
      " 1.54114907e-01 1.54114907e-01 1.54891304e-01 1.54891304e-01\n",
      " 1.55279503e-01 1.55279503e-01 1.55667702e-01 1.55667702e-01\n",
      " 1.65566770e-01 1.65566770e-01 1.66925466e-01 1.66925466e-01\n",
      " 1.67895963e-01 1.67895963e-01 1.75465839e-01 1.75465839e-01\n",
      " 1.81094720e-01 1.81094720e-01 1.84976708e-01 1.85753106e-01\n",
      " 1.87500000e-01 1.87500000e-01 1.90799689e-01 1.90799689e-01\n",
      " 2.10015528e-01 2.10015528e-01 2.14868012e-01 2.14868012e-01\n",
      " 2.28649068e-01 2.28649068e-01 2.41265528e-01 2.41265528e-01\n",
      " 3.61024845e-01 3.61024845e-01 4.55357143e-01 4.55357143e-01\n",
      " 4.93982919e-01 4.93982919e-01 5.06405280e-01 5.06405280e-01\n",
      " 5.35908385e-01 5.35908385e-01 5.40954969e-01 5.40954969e-01\n",
      " 5.59394410e-01 5.59394410e-01 5.59588509e-01 5.59588509e-01\n",
      " 5.60559006e-01 5.60559006e-01 5.87538820e-01 5.87538820e-01\n",
      " 5.96273292e-01 5.96273292e-01 5.99572981e-01 5.99572981e-01\n",
      " 6.00543478e-01 6.00543478e-01 6.23641304e-01 6.23641304e-01\n",
      " 6.37034161e-01 6.37034161e-01 6.44021739e-01 6.44021739e-01\n",
      " 6.44215839e-01 6.44215839e-01 6.51785714e-01 6.51785714e-01\n",
      " 6.64596273e-01 6.64596273e-01 6.65760870e-01 6.65760870e-01\n",
      " 6.70419255e-01 6.70419255e-01 6.70613354e-01 6.70613354e-01\n",
      " 6.77795031e-01 6.77795031e-01 7.16226708e-01 7.16226708e-01\n",
      " 7.17779503e-01 7.17779503e-01 7.18750000e-01 7.18750000e-01\n",
      " 7.19720497e-01 7.19720497e-01 7.34666149e-01 7.34666149e-01\n",
      " 7.41071429e-01 7.41071429e-01 7.84549689e-01 7.84549689e-01\n",
      " 8.19875776e-01 8.19875776e-01 9.01009317e-01 9.01397516e-01\n",
      " 9.23718944e-01 9.24107143e-01 1.00000000e+00]\n",
      "831\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6ffe21a890>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABgmklEQVR4nO2dd3hUxfeH30khIZRQEmqoSpEWSkB6ESsoqKCCgGIBxYJdsXw1tp/Yu6jYqVYQBAHpCEjvvQUInQAhIQSS7Pn9MdsSUnaT3ewmmfd57rO7d++dOTfZ3c+dM2fOUSKCwWAwGAz+RoCvDTAYDAaDITuMQBkMBoPBLzECZTAYDAa/xAiUwWAwGPwSI1AGg8Fg8EuCfG2Au0REREjdunV9bYbBYDAYCsiaNWtOikhkTu8XOYGqW7cuq1ev9rUZBoPBYCggSqn9ub1vXHwGg8Fg8EuMQBkMBoPBLzECZTAYDAa/xAiUwWAwGPwSI1AGg8Fg8EuMQBkMBoPBLzECZTAYDAa/xAiUwWAwGPySIrdQ12AwGABEhITzCexM2Mnp86e5mHGRCxkX9GP6hUyvnfcppXi03aPUCq/l60vwKCLC3tN7WXJgCUv2L+G/Q//RMaojn/X6jJCgEF+bly+MQBmKNDN2zuDhmQ8zpMUQXu3xKgHKOAWKG6npqew+tZudCTvZcXIHOxKs28kdnE49na82lxxYwr/3/EtgQKCHrS08MiwZbDy2UV/LgX/598C/HEk+kumYrSe2svfMXv64/Q/CQ8M92n+6JZ2gAO9KiCpqFXVjYmLEpDoyACzZv4Rrx19LanoqALc0voVxt4yjTKkyPrbMkB8yLBlsP7mdlYdWsuHYBrsI7U/cj0Us2Z5TtlRZGlVuRJUyVSgVWIqQoBD9GJjl0Wn/xys+5lDSId6++m2e7fRsIV9l/knLSGN5/HKW7F/CkgNLWHZwGUkXkzIdExEWQZfaXehcuzP1KtTjoZkPcTT5KC2qtmDmnTOpWb5mge1It6Qz+t/RTN0+laX3Li3Q6EwptUZEYnJ83wiUoSiy4egGuv3QjcQLifRp1IdFcYtIvJBIq2qtmD5wuke+iADxZ+MJCw6jUulKHmmvsDiSdIRPVnzCqfOnyJAMMiSDdEs6GRb9PMNifW19niEZiMglP+bZ/cDbXlcuXZk6FepQJ7wOUeWjCA4MdsvG+LPxrDy00r6tPrz6kh9cgAAVQP2K9WlYuSGNKjfSW4R+rFa2Gkopt/qdtXsWN0y4gVKBpVj3wDqaRDZx63xfccvPtzB1+9RM++pVqEeXOl3sotSocqNMf4+4M3HcMOEGtp/cTq3ytfh70N80rdI03zbsObWHIVOGsDx+OQB/DviTPo365Ls9I1CGYsfe03vp9F0njiYfpd8V/fi5/8/sOrWLGyfeyJ7Te6hetjrTBk4jpkaOn/s8OXvhLC8veJlPV35K1TJVWXH/iiIzZ7H95HauH389+xNzzcPpURSKGuVq2AWrdnht6oTXoU4F/TwyLJLNxzdrMTqsBelw0uFL2qkdXpt2NdvRpnobGkc0plHlRlxW6TJKBZbyqL3Dpg3jm3XfEFMjhuX3Lfe6q6qgpGWkUX50eVLTU3ko5iG7KLlyI3bq/Cn6TOrD0oNLqRBagT8H/EnXOl3d6l9E+GH9D4ycNZLki8nUKFeDH2/+kavrX53fSwKMQBmKGUeTj9Lpu07sPb2Xq+pdxcw7Z9pdDAkpCfT7pR+L9i+idFBpfrrlJ/o36e9W+yLC5M2TeXLOkxxNPmrf36paK5bcs8Sj7sONxzay7OAyhrYcSmhQqEfaXHZwGTdNuolT509xZc0rGdpyKIEqkKCAIAIDAglUgQQGWF9bn9veB3INNLiQfsH+PDU9lePnjrM/cT8HEg9w6OwhBPd+S8JDwmlXs12mrVrZah75O+TF2QtnaT6mOQcSD/B6j9d5qetLhdJvfll/dD2tvmpF/Yr12TNyj9vnn087z6A/BjFl+xRKBZZi/C3jua3pbS6dezLlJA/89QB/bPsDgP5N+vPVjV95xKtgBMpQbEhMTaTbD93YcGwDbaq3YcHdCygXUi7TMRczLvLQjIf4dt23ALzR4w1e6PKCS26gbSe28cjfjzB/33wArqx5Jf/X8/8YPn04e07voX+T/vzc/2ePBGKsPLSSnj/1JPliMs2rNGdiv4k0q9KsQG1O3T6Vgb8PJDU9lZsa3sTk/pMJCw4rsK2ukJaRRvzZeLtg7T+zn/2J++2vjyUfo1FEI9rVcIhRg8oNfBrUMm/vPK4edzXBAcGsGraK6GrRhWuAxQKbN0PTphCYe7DG2DVjGf7XcO5oegeT+0/OV3cZlgwem/UYn6/6HIXiw+s+5LH2j+V6zuzdsxn651COJh+lXKlyfNbrM4a0GOK2WzUn8hIoRKRIbW3atBGD54lPjJd1R9bJ+bTzHmkv5WKKLNm/RN759x259edb5dpx18rfu/4uUHtdv+8qxCINP20ox5OP53isxWKR95a+JypWCbHIoN8H5XpdyReSZdQ/oyT4tWAhFqn0diUZu2asZFgyRERk6/GtUv6t8kIs8vL8l/N9DTY2Ht0oFUdXFGKRsDfDhFgk5PUQ+XTFp2KxWPLV5phVYyTg1QAhFhk2bZikZaQV2M6SwEN/PSTEItFjouVC+oXC7XzsWBEQ+eyzPA8dNm2YEIu8v+z9AnVpsVhk9JLRQixCLPL07Kftn3NnUi6myCMzHrEf1/m7zrLv9L4C9Z0dwGrJ5ffe54Lj7mYEyvMkX0iWSm9XEmKRgFcDpNGnjaT/L/0ldkGs/L71d9lxcoekZ6TneL7FYpG9p/bKxI0T5dGZj0rM1zES9FqQ/cPtvF0//nrZfGyzW/alZaRJn0l9hFikxvs1JO50nEvn/bn9TynzZhkhFun4bUc5lnzsErunbJsitT+sbbfv/j/vlxPnTlzS1sydM+0CMHnTZLfsd2bnyZ1S9d2qQixy08Sb5FTKKbl36r32/ntP6H2JnblhsVjkxXkv2s9/beFr+Ra5kkjShSSp/3F9j918uMVDD+mf4EcfzfPQll+2FGKRxXGLPdL1uA3j7N/RAb8NkNS0VPt7aw+vlSs+u0KIRYJeC5L/W/x/uX7/C0JeAmVcfAZm757N9ROuJyQwhDRLWrYhvaWDStMksgnNqjSjeZXmXF7pcnYk7GB5/HKWH1zOsXPHMh0foAJoVqUZHaI60D6qPcfPHefNJW9y9sJZAlQAw1sP59Uer1KlTJVcbRMR7pt2H9+v/56KoRVZcs8St6KQNhzdwE2TbuLg2YPUCa/DX3f+RbMqzdh7ei8j/x7JjF0zAD3H9EXvL2gf1T7Htj5c/iFPznmS0KBQltyzxO0gjAOJB+jyfRcOJB6gZ72e/HXnX/a5p9+2/saw6cM4k3qGqmWq8sPNP3D95dfn2l5aRhrD/xrOD+t/IFAF8tWNX3Ff6/vcsskAi/cvpvsP3QlQAay4fwVtarQpnI779IHp02HwYBg3LsfDUtJSKP9WeQTh7KizHpsHnbt3Lrf+fCtJF5PoUbcHv93+G2PXjOV/C/5HmiWNxhGNGX/LeK/+PcwclCFPRs0dxdtL3+bZjs/yao9X2X5yO5uObWLz8c1sOr6JTcc3EX82Ptc2KpeuTPuo9nZBalez3SXzQyfOneDVRa/y5eovyZAMypUqx4tdXuSx9o/lGCTw3D/P8c6ydwgLDmPukLl0qNXB7es7mnyUvpP7svLQSsqWKstdLe7iu/XfkZqeSvmQ8rx51ZuMiBmR56JNEWHY9GF8u+5bapSrwaphq6hRroZLNhxLPkaX77uw69QuOkR1YM6QOZQtVTbTMQcTD3LX1LtYGLcQgMeufIzRV4/O9m+TfDGZ2369jVm7ZxEWHMYv/X+hd8Perv1BDJfwxKwn+GjFRzSNbMqa4WsKJ/NCy5awYQP07g1//ZXjYcsOLqPTd51oVqUZm0Zs8qgJ64+up9eEXhxJPkJYcBgpaSkAPNz2Yd655h2vz2GaOShDnrQb206IJdc5otPnT8uS/UtkzKox8tBfD8m1466VB6c/KD+u/1F2ntzplltp6/Gt0ntCb7tbqs6HdWTypsmXtPHu0nftboaZO2fm+/pEtE99wG8DMrkbB/8xWI4kHXGrnQvpF6TLd12EWKTt120l5WJKnuckpCRI8y+aC7FIyy9byunzp3M8Nj0jXd5a8pbd/dJiTItLXKJHk45Km6/aCLFIxDsRsiJ+hVvXYLiUcxfPSYNPGgixyKh/RhVOp5UqaRdfp065HvbR8o+EWOTeqfd6xYy403HS+LPGQixS9d2qMmPnDK/0kx2YOShDbiSmJkrgq4ES9FqQJF1IKtS+5+yeY//hJhZp/017WX5wuYiIfL/ue/v+8RvGe6Q/2wRxzx97yoJ9C/LdzvHk41L3o7p2/31u4nw29az9BqDxZ41dnl9aGb9SLv/kciEWCX0jVD5b8ZlYLBbZeXKnfc6k/sf1ZVfCrnxfhyEzyw4sk4BXAyTg1QD759BrJCfrn18QadIk10MH/T5IiEXGrBrjNXNOpZyS79d9n2vwkTcwAmXIlb92/CXEIh2+6eCT/tMz0mXsmrH2wAFikRvG3yCBrwYKscjH/33sE7vyYtOxTVL2/8oKscjri17P9piUiynS/YfuQixS96O6cjDxoFt9JF1IyhRAce24ayXinQghFon5OkaOJh31xKUYnHhmzjNCLNLo00YujY7zzbZtDoGqXj3XQ20ju9WHVnvPHh+Rl0CZzJolnAVxCwDoUbeHT/oPDAjk/tb3s+vRXbzY5UVCg0L5e/ffZEgGL3V5iZFXjvSJXXnRrEozJt46EYXifwv+Z1/EaONixkX6/9qfhXELqV62OnOHzCWqfJRbfZQtVZZv+37Lr7f9SoXQCszZM4eTKSe5/vLrWXD3AqqWrerJSzIAr/V4jSaRTdiRsIOX5ntx8e6BA47np3NOeHsm9Qy7Tu2iVGApmldt7j17/BQjUCUcu0DV841A2SgXUo43rnqDHY/sYETMCN7o8Qav9XjNpzblxU2NbmL01aMBGDJlCOuOrAP0gsjBfwxm5q6ZVC5dmbl3zeWySpflu5/+Tfqz8cGN3N70dp7q8BTTBky7JMDC4BlCg0L5oa+Oivzwvw/598C/3uno4EHH89RUvWXD6sM6IKxVtVYeT/dUFDACVYI5ff40646sIzggmI61OvraHEDnYvui9xe82PVFj61W9ybPdHyGu6LvIiUthb6T+3Ik6QjDpg/j162/Uj6kPLMHz/ZIMtJa4bX4uf/PvHfte24nZTW4R9uabRnVeRSCMHTqUM5dPOf5TpxHUABnzmR72KpDq7RNNdp63oYigBGoEszi/YsRhCujriy0lDjFDaUUX9/4NR2iOnDw7EGajWnG9+u/p3RQaWbcOaPw1tQYPMrL3V6mRdUW7Dm9h1FzR3m+A+cRFOTo5lt12CpQNY1AGUoYvp5/Ki6EBIUw5Y4p1A6vzanzpygVWIo/B/xJ59qdfW2aIZ+UCizFjzf/SFBAEJ+t+oy1R9Z6toOsI6gcBGrloZWAGUEZSiBGoDxH1bJVmXHnDG5ufDNT75jKNZdd42uTDAWkZbWWPNruUQDe+vctzzZuG0HVspZwyUagjiQd4VDSIcqVKkejiEae7b+IYASqhHIy5SQbj20kJDAkX9kZDJfSrEozptwxhRsa3OBrUwwe4qkOTxEcEMzvW39nx8kdnmlUxDGCatFCP2YjUDb3XkyNGJ9mffclJfOqDSyKWwRAh1odPFaLyGAobtQsX5O7o+9GEN5d9q5nGk1I0FF74eFQp47el02QREkPkAAjUCUW494zGFzj2U7PolD8tOGnPHNSuoRt9FSrFlSsqJ/nMoIqqQESYASqxGIEymBwjQaVG9C/SX/SLGl8uPzDgjdom3+qXRsqVNDPswiUiNgFql3NdgXvs4hiBKoEciz5GFtPbKV0UOkS/eE3GFzl+c7PA/DVmq9ISEkoWGMujKD2nt7LqfOnqFKmCrXK1ypYf0UYI1AlEFs5h061OxVOWQGDoYjTqnorrrvsOs6lneOzlZ8VrDHnEVQOAmV379VoWyQWrHsLI1AlEOPeMxjcZ1RnvWD3k5WfFCy7RHYjqCxBEiZAQmMEypOkp+sIHT/HCJTB4D7d6nSjfVR7Tp0/xdi1Y/PfkAsjqJWH9QLdku6CNwLlSZ5+GqpWhU2erXrpSQ4nHWZnwk7KBJdxu2S5wVCSUUrZ56LeX/4+FzMu5q+hPOag0i3p9swVJTmCD4xAeY6MDBg/Xj8uWuRra3LENv/UpU4Xk3TUYHCTGxveSJPIJsSfjWfCxgnuN5CeDocPg1JQs2a2UXzbTmwjJS2FuhXqEhEW4RnDiyhGoDzF2rUO997Onb61JRcW7DPuPYMhvwSoAEZ10nNRby99mwxLhnsNHD4MFov2tISEQLlyEBAAycmQlgZkDpAo6RiB8hSzZjme+7NAmfkng6FADGg2gDrhddiRsIM/d/zp3snO80+gxck2irIGStgCJEr6/BMYgfIcRUCgDiYeZM/pPZQPKU+r6q18bY7BUCQJDgzm6Y5PAzqJrK5c7iLO8082skTy2QIkzAjKCJRnOH0a/vsPgoL0HVFcXI4VMn2JbfTUtU5XggKCfGyNwVB0ubfVvUSGRbL68Grm7Zvn+olZR1CQKVAiNT2Vjcc2olC0rt7acwYXUbwqUEqp65VSO5RSu5VSl1T9UkrVVkotUEqtU0ptVEr18qY9XmPePO1X7tQJ6tXT2Yr37PG1VZdg3HsGg2cICw7j8faPAzD639Gun5i1zAZkCpTYcHQD6ZZ0roi8gnIh5Txia1HGawKllAoEPgduAJoAA5VSWWtfvwT8IiKtgAHAF96yx6vY3HvXXw+NrHVb/NDNZwIkDAbP8VDbhyhXqhzz9s2zzxvlic3Fl8MIyuTfy4w3R1DtgN0isldELgKTgb5ZjhGgvPV5OHDYi/Z4BxGYPVs/v+46aNhQP/czgdp3eh/7E/dTMbQi0dWifW2OwVDkqRBagRExIwAYvdTFUVR2IygngSrpFXSz4k2BqgkcdHodb93nTCwwWCkVD8wEHs2uIaXUcKXUaqXU6hMnTnjD1vyzdSvEx+uw0ehoh0Dt8FBxMw9hc+91q9utxBY/Mxg8zePtHyckMIQp26aw/eT2vE/II0jChJhnxte/VAOBH0QkCugFjFPq0l9PEflaRGJEJCYyMrLQjcwVm3vvuut0gISfjqDM/JPB4Hmql6vO0JZDEYS3l76d+8EpKXqtZHCwvqG1YRWos6ePsuPkDoIDgmlRtYUXrS46eFOgDgHOeeKjrPucuQ/4BUBElgOhQNFaOu3s3gO/nIMSETP/ZDB4iWc6PkOACmD8xvEcTDyY84E2915UlL6ZtWENkliTshtBiK4WbaoMWPGmQK0CGiil6imlSqGDIKZlOeYA0BNAKXUFWqD8zIeXC+fO6bRGSsE11+h9NWpAWBicOJFtlUxfsPvUbg4lHSIiLIKmVZr62hyDoVhxWaXLuKPpHaRb0nl/+fs5H5hdiDnYR1Cr0rX7r10NEyBhw2sCJSLpwCPAbGAbOlpvi1LqNaVUH+thTwHDlFIbgEnAUHFr1ZuPWbQILl6EmBiwuR4DAqBBA/3cT0ZRNvde97rdzfyTweAFnuv0HABj147lZMrJ7A/Kbv4J7AK1MugYYBLEOuPVXysRmSkiDUXkMhF507rvZRGZZn2+VUQ6iUi0iLQUkTnetMfjZHXv2XBxHmr6junM3DXTC4Zlxsw/GQzeJbpaNL0a9CIlLYVPVnyS/UF5jaDKJAImQMIZcztdEJzXPznjwjzUyZST3PLzLdw48UambJviJQPN/JPBUFg4l+LYmZDNdz+XEdTxMnAg7CJlgsvQOKKxly0tOhiByi/79mkBCg+HK6/M/J4LI6gl+5eQIRkIwuApg+31XzzN9pPbOXbuGNXKVjMffIPBi3Su3ZlBzQeRkpbCoD8GkZaRlvmAnEZQFSqwqoZ+GlMjhsCAQO8bW0QwApVfbO69q6/WOficcUGgFu9fDEDl0pVJSUvhpkk3cehs1iDHguM8/6SU8nj7BoPBwee9PqdOeB1WH15N7MLYzG/mNIKqUIFV1hWibU0R0UwYgcovObn3ILNAWSzZnr74gBaocbeMo3PtzhxOOkyfyX04d/GcR800808GQ+ERHhrOuFvGEaACeOvft1iyf4l+QyTnEVRgICvr6JvctuFZs8GVbIxA5YeLF3WCWLg0QAL0pGdkpF6Yd/jS7E2JqYmsP7qe4IBgutXtxpQ7plC/Yn3WHlnLXVPvwiLZi5q7WMRir6BrBMpgKBy61OnCqE6jEIQhU4aQmJoIp07p34Ny5fS0gBMiwqrq+jvftvTlvjDZbzEClR+WL9cVMJs0uXS4biMXN9+yg8uwiIW2NdsSFhxGRFgEfw38i/CQcP7Y9gcvzX/JI2ZuOb6FkyknqVmuJpdXMh98g6GwiO0eS0yNGPYn7ufhmQ/nPHoC9ifu52SohYhzUDetTCFb6t8YgcoPubn3bOQiULb5p661u9r3XRF5Bb/c9guBKpC3/n2LH9f/WGAz7e69ej3M/JPBUIgEBwYz4dYJhAWHMWHTBCauH6ffyOaG1pYJve1hUNaihQaNEaj84I5AZZM0dtH+RYAuHOjMtZddy6c3fArAsOnDHP7rfGLmnwwG39GwckM+uu4jAEYc+IL94WQ7grJnMD+E32Sf8ReMQLnL0aOwfj2ULg1duuR8XA5roVLSUlh1eBUBKoCOtTpectqItiMY2W4kaZY0bvn5Fvacyl/hQ4tYWBSnhdAIlMHgG+5vfT99G/XlrKQy5FbIiMpa0AFHBvPDGIHKghEod5ljTXbRvTuEhuZ8XA4uvv/i/yPdkk7Lai0JDw3P5kR4/7r3uf7y60k4n8BNk27iTOoZt83ccHQDp1NPUye8DvUq1nP7fIPBUHCUUnzT5xuqpYeypA68E74p0/sZlgzWHFkDWEdQxsWXCSNQ7uKKew/gsst0Etl9+3TUnxXb/FO3Ot1yPDUoIIjJ/SbTNLIp205u4/Zfbyfdku6yiRaxMH3ndEDPPxkMBt8RERbBDxvrA/DymSmsPrza/t6OhB0kX0ymNuFUPYcZQWXBCJQ7ZGQ4RlDZhZc7ExoKderoc/bute+2B0hkmX/KSnhoONMHTicyLJJ/9v7DyL9HklMe3TOpZ5i9ezaxC2O5dty1VHy7Iq8sfAUw7j2DwR+4bn0yI/+DdMlg0B+D7Osd7QESpaxeDiNQmQjK+xCDnbVrdcGxunUdLrzcaNQI4uK0m69xYy6kX2B5/HJAp0XJi3oV6zF1wFR6/NiDMavHcEXEFTzS7hF2JOxg+cHlLDu4jOXxy9l6YitCZvGqHV6bnvV60u+Kfvm4UIPB4DEyMuDQIUYfhnk3NmHLya08NecpvrzxS0eARLnGwHojUFkwAuUOzu49V8K2GzbUKZGs81CrD68mNT2VppFNiQhzrS5jx1od+a7PdwyeMpjHZz9O7KJYTp0/lemYUoGlaF29NR2jOtKhVgc6RHWgZvlLJ2MNBoMPOHIEMjIoXbUqE/tPou3Ytny15it6NehlD5BoFxkNTDYClQUjUO6QU3mNnMgSKOGqey8rg1oMYkfCDl5f/Dqnzp+ietnqdKzVkQ5RHehYqyOtqrciNCiXgA2DweA7nHLwtajagtE9R/PknCe5b9p9nL1wFoWija0GlAmSyIQRKFc5fVpnkAgKgquucu2crAJ1IH8CBfBq91fp1aAX1ctWp3Z4bbPw1mAoKmTJIvFY+8eYuXsmc/fOBaBxRGPKR0bpY8wIKhMmSMJV5s3TiV87dYLy5V07x7YWascO0i3pLD2wFMifQCmlaB/VnjoV6hhxMhiKEjaBsmaRCFAB/Hjzj1QqXQmwFiisUEEfYwQqEyVPoF59Fb77zv3z3HXvgf5AhoTA0aNs2LOUpItJXF7pcmqUq+F+/waDoWhic/E5ZZGoUa4G428ZT4NKDbg7+m57VV1On9aZzw1ASXPxbdgAsbEAXJi/lJCxn+mMEHkh4vr6J2cCAqBBA9i8mUXrpwKZ8+8ZDIYSQJYRlI0bGtzADQ1ucOwIC9MZz5OTddZzQ8kaQaU1ieb+gO84TyghE75jU/mODGy3h+HD4YMPYOZM2LNHR4VmYutWiI+HqlUhOtq9Tq3zUIutefXy494zGAxFmGxGUNliG0WZQAk7JWoElZwM526/h3vWteLNnf1pnr6eMavacPeqHxlLX/txpUrpgU/jxrqixjNBsykHcO21elTkDo0aYVGwJHkrKCNQBkOJI4cR1CVUrAiHDmk3X17HlhBK1AiqYkWYNAkmb29JvYQ1pFx3MxVI5E9uZk6r57imRzo1a+rMRFu2wO+/w+uvw+b38uHes9GwIVsj4ZQ6T1T5KOpWqOvRazIYDH7M+fNw4gQEB0O1arkfawIlLqFECZQzARXDCfv7D3j3XQgM5Jp17zDHcjXxq49y9iysXg0TJkDDqBRaJS1GlIJrrnG/o4YNWVxHP+1Wp5uJwDMYShLx8fqxZs28vS/OgRIGoAQLFKCzQTz9NMyfr+9uFi2CVq0ot34JbdrAnXfC+GGLCOUCa2nDvuRI9/twEqiutXMpz2EwGIofTot088QI1CWUbIGy0bUrrFunH48ehR494L33QIS2Cdq9N1Ou58EH3Y8AlcqVWVRPj5q6lrnC05YbDAZ/JpdS75dggiQuwQiUjWrV9GLcZ5/VYXzPPAO33gozZgCwrNx1zJmj3X7usPvUbo6WESLPQaNjFi8YbjAY/BYzgioQRqCcCQqCt9+GqVMhPFw/7tkD4eHc8UF7AJ54Ak6edL1Je/69/aB27fK8zQaDwX/JzwjKCJQdI1DZ0bcvrFnjWPN03XXcfV8QV12lxenJJ11vypZ/r1scl1TXNRgMxRx3RlAmiu8SjEDlxGWX6eSwP/wAH32EUvDVV7oO4bhx8M8/rjXjPIJixw6vmWswGPwQM4IqEEagciFRXWR4paUsT48D4PLL4RVdqJYHH9RZSXLjQOIB4s7EUSG4HM2OY0ZQBkNJQiR/c1AmSMKOEahc+HHDj4xdO5Zbf7mVM6lnAHjqKWjRQldxt6b1yxHb6Klz7c4ECno+Kz3dqzYbDAY/4cwZOHcOypZ1uO9yw4ygLsEIVC78e+BfAI4mH+WZOc8AekH42LF6CdUHH+jo9Jywu/fq9dB3UOnpugS8wWAo/jiPnlxZoG8E6hJcEiil1PtKqabeNsafEBGWHtT1mwJUAN+s+4YF+xYA0K4djBypo9GHDct5UJSpgq6tNpRx8xkMJQN35p/ABElkg6sjqG3A10qpFUqpB5VS4d40yh+IOxPH4aTDVC5dmZe7vgzA8L+Gcz7tPABvvKE/d2vWwCefXHr+seRj7EjYQZngMrSu3tpRXdfbgRIWi86+/t13MGaMfm0wGAofd+afQJf+KVUKLlzQOfwMrgmUiHwjIp2Au4C6wEal1ESlVA9vGudLbKOnTrU78XyX52ka2ZTdp3bz2qLXAO1WHjNGH/u//8G+fZnPX3JAl9foWKsjwYHBl5R/9xhnzuhiiq++qpPZVq4MTZvCfffBQw/B3Lme7c9gMLiGuyMopYybLwsuz0EppQKBxtbtJLABeFIpNdlLtvkU2/xTp1qdKBVYim/6fINC8e6yd1l3RE889eoFd9yho/lGjMicBmlR3CLAqbyGJwTKYtFp1r/9Fu6/XwtRpUpamGJjtVCdOaMTU9ru2nbvzn9/BoMh/7g7ggITyZcFV+egPgS2A72A/xORNiLytojcBLTypoG+wjaC6ly7MwDto9rzaLtHyZAM7p9+P+kWPfH08cf6MzV7Nkyc6DjftkDXLlAFnYPatg3q1IFmzbQ4ffutduUFB0P79jrFxc8/6y9FfLyeHAPHXZzBYChc3B1BgRlBZcHVgoUbgZdE5Fw277XzoD1+wenzp9l8fDMhgSG0qd7Gvv+Nq95g6o6prD2ylo/++4inOz5N1ao6r+x998Hjj+vBjAo7xaZjmwgJDKFdTeufp04dLSbx8Tr0tEwZ94yKjdXnVqsGXbpAhw5amFq3hpCQS4+PitKPRqAMBt+QnxGUCZTIhKsuvjM4iZlSqoJS6mYAEUnM6SSl1PVKqR1Kqd1KqVE5HHO7UmqrUmqLUmpidscUNssOLgOgbc22hAQ5fvzLhZTjy95fAvDygpfZc2oPAPfcA9276zRITz0FSw8sRRCujLqS0KBQfXJgoF7pC+BuTr6DB3X1xMBAWLkSfvlFj5g6dMhenMDxpbDVozEYDIVHRoaujguOm0VXMCOoTLgqUK84C5GInAFeye0E65zV58ANQBNgoFKqSZZjGgDPA51EpCnwuMuWexF7gEStTpe8d0ODGxjUfBDn08/zwF8PICIoBV9/rbXixx/hlxVW917tLOXd8zsP9cUX+gPfv7/rd2O248wIymAofI4e1etPIiN1dJ6rGIHKhKsCld1xebkH2wG7RWSviFwEJgN9sxwzDPhcRE4DiMhxF+3xKrYACdv8U1Y+vO5DKpeuzLx98/hh/Q8ANGigp4YA5u/NEiBhIz/zUCkpOgkgwGOPuX6e8wjKhJobDIVLfuafwARJZMHVOajVSqkP0CMigIeBNXmcUxNwvn2PB67MckxDAKXUUiAQiBWRWS7a5BUupF9g1eFVgA4Rz47IMpF8dP1HDJkyhKfmPMUNDW6gWtlqXHMNfD42icOylsCAQDrU6pD5xPyshRo/Xt9NtW2r55xcJSxMR/idOgUnTkDVqq6f6yPS0tKIj48nNTXV16YY/ITQ0FCioqIIDg72tSnuYRMod+afwIygsuCqQD0K/A/42fr6H7RIeaL/BkB3IApYrJRqbnUh2lFKDQeGA9R2947ETdYeWUtqeipNIptQqXSlHI8b1HwQ4zeOZ/ae2Tw26zF+7v8zXbsCtZZDQAatqrWjbKmymU9y18Un4lgF/PjjrqVLcSYqSgvUwYNFQqDi4+MpV64cdevWRbl7rYZih4iQkJBAfHw89erV87U57mELkHD398oESWTC1YW650RklIjEWLfnc4joc+YQ4Hz7EGXd50w8ME1E0kRkH7ATLVhZ+//a1ndkZKQrJueb3OafnFFK8eWNX1ImuAy/bPmFaTumUbEiVLtSzz/VVV0vPclZoFypHT9vnl73VL26nn9ylyIWKJGamkrlypWNOBkA/R2rXLly0RxRmxGUR3B1HVSkUupdpdRMpdR825bHaauABkqpekqpUsAAYFqWY6aiR08opSLQLr+97lyAp8lr/smZuhXq8uZVbwLw0IyHOHvhLEGXaYFif7dLT6hSRVfqPXPGtbK8H32kHx96SKdAcZciGChhxMngTJH9POR3BGUEKhOuBklMQC/UrQe8CsShBShHRCQdeASYjc7l94uIbFFKvaaU6mM9bDaQoJTaCiwAnhGRBLevwkM4J4jNawRl45F2j9CuZjsOJR3i8VmPczRoBYgiblE25yvluptv1y6YMUOHBj7wgDuX4aAICpTBUCwo6AjKBEkArgtUZRH5FkgTkUUici9wVV4nichMEWkoIpeJyJvWfS+LyDTrcxGRJ0WkiYg0FxGfpk3ambCTkyknqVa2GvUr1nfpnMCAQL656RuCAoL4fv33pMtFONaCdcsrkpSUzQmuBkp8+ql+HDRIh6rmByNQbpGQkEDLli1p2bIl1apVo2bNmvbXFy9ezPXc1atXM3LkyDz76Ngx+8Abd1m4cCE33nijR9oyeAEzgvIIrgZJpFkfjyilegOHgZwjCIoozumN3HEtNK/anFGdRvHGkjcAqHahK0czYMkSna8vE66MoBIT4fvv9XN3QsuzYrJJuEXlypVZv349ALGxsZQtW5ann37a/n56ejpBQdl/ZWJiYoiJicmzj2XLlnnEVoMfk5oKx49DUJDO/OIOJkgiE66OoN6wlth4Cnga+AZ4wmtW+QjnBLHu8lLXl2gc0RiAzjV6AjA/u1k6V9ZCffcdJCfr9BQtWrhti50iFiThjwwdOpQHH3yQK6+8kmeffZaVK1fSoUMHWrVqRceOHdlhHQk7j2hiY2O599576d69O/Xr1+cTp3osZcuWtR/fvXt3+vfvT+PGjRk0aBBiDZyZOXMmjRs3pk2bNowcOdKtkdKkSZNo3rw5zZo147nnngMgIyODoUOH0qxZM5o3b86HH34IwCeffEKTJk1o0aIFAwYMKPgfy6Cxfd9q1tTZX9yhXDl9zrlzkJaW9/HFnDxHUNaMEA1E5C8gESj2JTZcCZDISkhQCP8M+YeFcQupeqwPv70JCxZkc2BeI6iMDId7ryCjJ3CMoA4d0u26+2XxId6aG3cleDIr8fHxLFu2jMDAQM6ePcuSJUsICgpi7ty5vPDCC/z++++XnLN9+3YWLFhAUlISjRo1YsSIEZes5Vm3bh1btmyhRo0adOrUiaVLlxITE8MDDzzA4sWLqVevHgMHDnTZzsOHD/Pcc8+xZs0aKlasyLXXXsvUqVOpVasWhw4dYvPmzQCcsc5vjB49mn379hESEmLfZ/AA+Z1/Av3Br1ABEhL0KKpKFY+aVtTIcwQlIhmA69+SIsrxc8fZmbCTsOAwoqtG56uNqPJRDG4xmE6dFMHBuhz8JSP1BtYo+t27tWhk5a+/dHGpevXgppvyZYed0FA9f5WeDseOFaytEsxtt91GoFXcExMTue2222jWrBlPPPEEW7Zsyfac3r17ExISQkREBFWqVOFYNn//du3aERUVRUBAAC1btiQuLo7t27dTv359+7ofdwRq1apVdO/encjISIKCghg0aBCLFy+mfv367N27l0cffZRZs2ZRvnx5AFq0aMGgQYMYP358jq5LQz7I7/yTDRMoYcdVF99SpdRnSqkuSqnWts2rlhUytgSx7aPa6wKDBSAsTOdxFYFFi7K8WbYs1Kihq2baPsjO2ELLH33UMyOeIhooIeKdLT+Ucco8/7///Y8ePXqwefNmpk+fnuManRCnJL6BgYGkp6fn6xhPULFiRTZs2ED37t358ssvud+ak2vGjBk8/PDDrF27lrZt23qt/xJHQUZQYAIlnHBVoFoCTYHXgPet23tessknFGT+KTt6WB2h2br5cpqH2rgRFi7UInbvvR6xo6gKlL+SmJhIzZo1Afjhhx883n6jRo3Yu3cvcXFxAPz888+5n+BEu3btWLRoESdPniQjI4NJkybRrVs3Tp48icVioV+/frzxxhusXbsWi8XCwYMH6dGjB2+//TaJiYkkJyd7/HpKJPkps+GMCZSw49K4XkSK7byTjYLMP2VHjx66CnuO81ALFmiBuu46x/6PP9aP99yjF/R6AhPJ51GeffZZ7r77bt544w169+7t8fZLly7NF198wfXXX0+ZMmVo27ZtjsfOmzePKKdSDr/++iujR4+mR48eiAi9e/emb9++bNiwgXvuuQeLNWnwW2+9RUZGBoMHDyYxMRERYeTIkVSw/TAaCkZ+E8XaMCMoByKS5wa8nN3myrme3tq0aSOeJuViigS/FiwBrwZIYmqiR9pMTRUJDdWOpePHs7z5/vv6jYcfduw7flwkJEREKZGdOz1ig4iIjB6t+3rySc+16SW2bt3qaxP8gqSkJBERsVgsMmLECPnggw98bJFvKXKfiyZN9Hdu3br8nf/AA/r8zz/3qFn+CLBacvm9d9XFd85py0DXeKrrYa30GasOryLNkkaLqi0oH1LeI22GhEAnq7dw4cIsb2YXyffVV3peqlcvRyCFJzAuviLH2LFjadmyJU2bNiUxMZEH8ptJxFD4iJggCQ/iqovvfefXSqn30GmKigWenn+ycdVVOt/r/Plw221Ob2QVqIsXdVFCKHhoeVaMQBU5nnjiCZ54otgtMywZJCbqNYxhYQ6hcRfj4rOT39jSMHR28mKBp+efbOQYKFGvnl5lfuAAnD8PU6bAkSPQpAlcfbVHbTACZTAUIs7zT/ldzGeCJOy4JFBKqU2ALUg3EIhER/QVeSxiYekB9xLEukpMDJQpo9PuHT6so8sBCA6G+vX1CGr3bkdo+WOPeX6Fao0aus0jR/R6KLPexWDwHgWN4AMzgnLC1TmoG4GbrNu1QA0R+cxrVhUiW45vIfFCIrXDa1MrvAAfqmwIDkYXMSSbUZTNzffjj7Bqla5+O3iwR/sHdJmOqlV12fcjRzzfvsFgcFDQCD4wAuWEqwJVHTglIvtF5BBQWimVtXx7kcTd8hrukqObzyZQttDyYcO039obGDefwVA4eHIEZYIkXBaoMYDzKr5z1n1FHncKFOaHHAXKtlg3PV1njHj4Ya/0DxiBcpEePXowe3bm2J+PPvqIESNG5HhO9+7dWb16NQC9evXKNqddbGws772X+7r2qVOnsnXrVvvrl19+mblz57phffaYshyFjBlBeRRXBUpZY9YBEBEL+Q+w8Cu8FSBho1UrveZ2717Yv9/pDdsICqBfv4LdceWFESiXGDhwIJMnZy5JNnnyZJfz4c2cOTPfi12zCtRrr73G1Z4OmDF4H0+MoEyQhB1XBWqvUmqkUirYuj2Gj0uze4JDZw8RdyaO8iHlaRrZ1Ct9BAZCN2v190yjKGeB8nRoeVZMNgmX6N+/PzNmzLAXJ4yLi+Pw4cN06dKFESNGEBMTQ9OmTXnllVeyPb9u3bqcPHkSgDfffJOGDRvSuXNne0kO0Guc2rZtS3R0NP369SMlJYVly5Yxbdo0nnnmGVq2bMmePXsYOnQov/32G6AzRrRq1YrmzZtz7733cuHCBXt/r7zyCq1bt6Z58+Zs377d5Ws1ZTm8hCdGULYsMomJ2SeULkG4KlAPAh2BQ0A8cCUw3FtGFRa20VPHWh0JDPBeKYqrrLWHM9WHql5dzzs99JDOLOtNimJdKKW8s+VCpUqVaNeuHX///TegR0+33347SinefPNNVq9ezcaNG1m0aBEbN27MsZ01a9YwefJk1q9fz8yZM1m1apX9vVtvvZVVq1axYcMGrrjiCr799ls6duxInz59ePfdd1m/fj2XXXaZ/fjU1FSGDh3Kzz//zKZNm0hPT2fMGId3PSIigrVr1zJixIg83Yg2bGU55s+fz/r161m1ahVTp05l/fr19rIcmzZt4p577gF0WY5169axceNGvvzyS5f6KJFYLI7vWFQBVuEEBmYWqRKMSwIlIsdFZICIVBGRqiJyp4gc97Zx3sZbC3Sz4jwPZXeUKgVffw2ff+694kc2jIvPZZzdfM7uvV9++YXWrVvTqlUrtmzZkskdl5UlS5Zwyy23EBYWRvny5enTp4/9vc2bN9OlSxeaN2/OhAkTcizXYWPHjh3Uq1ePhtYR9913383ixYvt7996660AtGnTxp5gNi9MWQ4vcfSoLjIYEVHwgCcTKAG4KFBKqR+VUhWcXldUSn3nNasKCW/PP9lo1gwqV9Y3V3v2eLWr7CmKAuWjeht9+/Zl3rx5rF27lpSUFNq0acO+fft47733mDdvHhs3bqR37945ltnIi6FDh/LZZ5+xadMmXnnllXy3Y8NWssMT5TpMWY4CsmKFfmzSpOBtmUAJwHUXXwsROWN7ISKngVZesaiQSLqQxPqj6wkKCKJdzXZe7SsgwDGKyrYMvLepXl0bceyYTqtkyJGyZcvSo0cP7r33Xvvo6ezZs5QpU4bw8HCOHTtmdwHmRNeuXZk6dSrnz58nKSmJ6dOn299LSkqievXqpKWlMWHCBPv+cuXKkZSUdElbjRo1Ii4ujt27dwMwbtw4utkmNfOJKcvhJebN0489exa8LSNQgOuReAFKqYpWYUIpVcmNc/2SFYdWYBELMTViCAv20vojJ3r0gN9+026+4YU9excUpDNKxMfr8u/Waq2G7Bk4cCC33HKL3dUXHR1Nq1ataNy4MbVq1aJTp9xdwq1bt+aOO+4gOjqaKlWqZCqZ8frrr3PllVcSGRnJlVdeaRelAQMGMGzYMD755BN7cARAaGgo33//Pbfddhvp6em0bduWBx980K3rMWU5CglPCpSJ5NPklurctgF3AduB14E3rM/vcuVcT2+eKrfxyoJXhFjkiVlPeKS9vNi2TfuYqlYVsVgKpcvMtG+vDVi0yAedu0aRK6tgKBSKxOciPl5/v8qUEbl4seDt3Xefbu+rrwrelh+DJ8ptiMhPwK3AMeAocKt1X5GlsOafbDRqBNWqaS/btm2F0mVmimIkn8FQVLD57rt21TnOCooJkgBcn4NCRLaKzr/3N9BPKZV7+JEfk25JZ/nB5YD3I/hsKJVHGXhvUxQDJQyGooIn3Xtg5qCsuBrFV0Mp9YRSahWwxXpekV2xt/HYRs6lnePySpdTtWzVQus32/VQhYURKIPBO4gYgfISuQqUUmq4UmoBsBCoDNwHHBGRV0VkUyHY5xUKa/1TVmwjqIUL9Zq+QsUIlMHgHXbt0q7ziAho0cIzbZogCSDvEdRn1mPuFJGXRGQjjrpQRZbCnn+yUb++1olTp2BTYcu7SXdkMHgHm0ukRw+9nMMTmBEUkLdAVQcmAe8rpXYopV4HPDAD6DtExGcjKKV86OYzQRIGg3fwtHsPTJCElVwFSkQSRORLEekG9ATOAMeUUtuUUv9XGAZ6mv2J+zmcdJjKpSvTOKJxoffvs0CJqlX1eqgTJ6CA2QuKK8Wx3IaNxx9/nJo1a9rXOBk8hMXi+DJ7Q6DMCCpnlFK2IuWISLyIvC8iMUBfoEj+ytlHT7U7obydAy8bbAK1aJEuBVVoBAZCzZr6uRlFZUtxLbdhsViYMmUKtWrVYtGiRR5pMztKZAqkDRsgIUFnL3dK8ltgjEABebv4vlFK/aeUGq2U6q6UCgIQkZ0i8loh2OdxfOXes2H7HJ89C+vWFXLnJlAiV4pruY2FCxfStGlTRowYwaRJk+z7jx07xi233EJ0dDTR0dEsW7YMgJ9++okWLVoQHR3NkCFDADLZAzollK3tLl260KdPH5pYc9DdfPPNtGnThqZNm/L111/bz5k1axatW7cmOjqanj17YrFYaNCgASdOnAC0kF5++eX210UCZ/eeJ294bTc6Z864lEOyuJJruiIR6aWUCgW6A7cA7ymlDgCzgFkicsD7JnoWXwVIONOjh04au2ABOGXB8T5FKFBCveqd0a28kvOX3bncRt++fS8pt1GpUiUyMjLo2bMnGzdupEUOEVvO5TbS09Np3bo1bdq0AXT28WHDhgHw0ksv8e233/Loo4/Sp08fbrzxRvr375+pLVu5jXnz5tGwYUPuuusuxowZw+OPPw44ym188cUXvPfee3zzzTeX2DNp0iQGDhxI3759eeGFF0hLSyM4OJiRI0fSrVs3pkyZQkZGBsnJyWzZsoU33niDZcuWERERwalTp/L8m65du5bNmzdTz5pC67vvvqNSpUqcP3+etm3b0q9fPywWC8OGDWPx4sXUq1ePU6dOERAQwODBg5kwYQKPP/44c+fOJTo6msjIyDz79Bu8Mf8EerFvmTJw7hwkJYE1s3xJI8+QExFJFZFZIvKY1b33FFrYPlNKrfS6hR7k9PnTbD6+mZDAENpUb+MzO0yghP9S3MptXLx4kZkzZ3LzzTdTvnx5rrzySvs82/z58+3za4GBgYSHhzN//nxuu+02IiIiAC3aedGuXTu7OIEucBgdHU379u05ePAgu3bt4r///qNr167242zt3nvvvfz0k05K891339lrUBUJLl4E2//C9qX2JMbN51rCV6VUGeC86FLvweiihf2Awp/EKQClAksx/pbxHE46TEhQiM/s6N5dP/77ry4f44nMKC5RhFx8uY10vEnfvn154oknsi23sWrVKipWrMjQoUMLVG5j6tSpREdH88MPP7Bw4cIC2ZtXuY3Zs2dz5swZmjdvDkBKSgqlS5fmxhtvdKufoKAge4CFxWKxu0EBypQpY3++cOFC5s6dy/LlywkLC6N79+65/q1q1apF1apVmT9/PitXrsyU4d3vWbECUlJ0eY3q1T3ffsWK+mbyzBmoU8fz7RcBXA3aXwyEKqVqAnOAIcD3IlKkajeUKVWGQS0G8UynZ3xqR/Xq0LixHr07FVv1PkVIoHxFcSu3MWnSJL755hvi4uKIi4tj3759/PPPP6SkpNCzZ097dd6MjAwSExO56qqr+PXXX0lISACwu/jq1q3LmjVrAJg2bRppaWnZ9peYmEjFihUJCwtj+/bt/PfffwC0b9+exYsXs2/fvkztAtx///0MHjyY2267jcBA71W29jjecu/ZMCMolwVKiUgKOmHsFyJyG9Dce2YVf3zi5jMC5RIDBw5kw4YNdoFyLrdx5513ulVu44Ybbsi23EanTp1o3NixzGHAgAG8++67tGrVij1OVS2dy200b96cgIAAl8ttpKSkMGvWLHr37m3fV6ZMGTp37sz06dP5+OOPWbBgAc2bN6dNmzZs3bqVpk2b8uKLL9KtWzeio6N58sknARg2bBiLFi0iOjqa5cuXZxo1OXP99deTnp7OFVdcwahRo2jfvj0AkZGRfP3119x6661ER0dzxx132M/p06cPycnJRcu9Bw6B8oZ7D0w2CXC53MY6oAPwH9DUum+TK+d6evNUuQ1f8+uvOpv+VVcVYqfHjulOK1YsxE5dp0iUVTB4nFWrVknnzp1zfN8vPxdJSSJBQSIBASKnT3unj7vv1t/Xb7/1Tvt+AJ4otwE8DjwPTBGRLUqp+oAvcnIXG7p311Gp//4LR44UUqcREVCqlL4jO3eukDo1GHJm9OjR9OvXj7feesvXprjHkiV6IWObNo6RjqcxLj6X60EtEpE+IvK2UioAOCkiI/M6Tyl1vTVF0m6l1KhcjuunlBKlVIwbthdpIiLg5pt1INBHHxVSpwEBjlBzE8ln8ANGjRrF/v376dzZd8s+8oW355/ApDvC9XIbE5VS5a3RfJuBrUqpXCMNlFKBwOfADUATYKBSqkk2x5UDHgNWuGt8Uef55/XjF18U4k2Sn89DSQlelGi4FL/9PBSmQJkRVJ40EZGzwM3ogoX10JF8udEO2C0ie0VH+01Gp0jKyuvA2xTR1EkFoW1b/flOTobPPy+kTv1YoEJDQ0lISPDfHyVDoSIiJCQkEBoa6mtTMnPyJKxfDyEhkEfATIEwQRKurYMCgpVSwWiB+kxE0pRSef2K1AScfwXjgSudD1BKtQZqiciM3EZkSqnhwHCA2rVru2hy0eD55/XN2Mcfw5NPQliYlzv0Y4GKiooiPj6+aKW6MXiV0NBQomxuaX/BtnatY0coXdp7/ZgRlMsC9RUQB2wAFiul6gBnC9KxdS7rA2BoXseKyNfA1wAxMTHF6vb6qqugXTtYuRK++QZG5jmzV0D8ON1RcHBwpowEBoNfUhjuPTAChetBEp+ISE0R6WWNDtwP9MjjtENALafXUdZ9NsoBzYCFSqk4oD0wrSQFSoCO5LPNRb33ng6a8Com3ZHBUDAKW6BMkETuKKXClVIfKKVWW7f3gexX6jlYBTRQStVTSpUCBgDTbG+KSKKIRIhIXRGpi15j1UdEVufvUoouffrobCkHD8LEiV7uzI9dfAaD33PwoC7xXr48xHj5XtqMoFwOkvgOSAJut25nge9zO0FE0oFHgNnANuAX6xqq15RSfXI7t6QREADPPaefjx4NGRle7MwIlMGQf2yjp27ddAFQb+IcJFFCA4dcFajLROQVa0TeXhF5Faif10kiMlNEGorIZSLypnXfyyIyLZtju5fE0ZONgQN1PsgdO2DqVC92VKmSntg9e1ZvBoPBdQrLvQf6exoSov3+5897vz8/xFWBOq+Usq+kU0p1AkrmX8xLBAfDM9Y4xrfe8uINk1J+HShhMPgtIt7Pv5eVEu7mc1WgHgQ+V0rFWQMaPgMe8JpVJZR774UqVWDNGpg714sdmUAJg8F9tm/XecmqVIFmzQqnzxIeKOFqFN8GEYkGWgAtRKQVUEi3ECWH0qXBWigVr6YmM/NQBoP7OI+ePFnePTfMCMp1ROSsNaMEwJNesKfE89BDOkBowQKwltLxPEagDAb3Kcz5JxslPJuEWwKVhSJVTbeoEB6uRQq8OIoyAmUwuEdGhiODRGEKlBlB5ZuSGfdYCDz+OISGwrRpsHmzFzowAmUwuMfatXoeqF49vRUWRqByRimVpJQ6m82WBNQoJBtLHFWrwn336edvv+2FDkwUn8HgHr5w74EJksjtTREpJyLls9nKiYiXV6mVbJ5+GgIDYdIk2LfPw407R/GV0AWABoNb+FqgzAjK4E/UrQt33qld3++95+HGw8OhbFldVbeE3pkZDC6TmqpLX0PhrX+yYYIkDP6KLf3Rt9/C0aMebFgpMw9lMLjKf/9pkWreXK+BKkzMCMrgrzRtqsvCX7jghbLwRqAMBtfwlXsPjED52gBD7jiXhfeoN84EShgMruEPAlVCXfFGoPycdu202zspSYuUxzDpjgyGvDl7VlcTDQyErl0Lv38zgjL4O7ZR1EcfQUqKhxo1Lj6DIW8WL9aRSm3b6hQvhY0RKIO/07Onro124gS88oqH6kUZgTIY8saX7j2AMmX06C0lpRDKbfsfRqCKAErBq6/q5++9B927w969BWzUCJTBkDsi8Pff+rmvBEqpEj2KMgJVROjVC2bMgGrV9JKM6Gj45psCrLO1BUmYxboGQ/asWaMriEZGQufOeR/vLUpwoIQRqCJEr146N99tt0FyMgwbBjfdlM81UuXK6QW7qalw8qTHbTUYijzjxunHgQN1RVFfYUZQhqJC5crw888wYYJeZD5jhq6d9ttv+WjMRPIZDNmTlqbzjAEMGeJbW4xAGYoSSuk0SJs2wTXXQEKCHlUNHuzmZ9jMQxkM2TNnjo5KatwY2rTxrS0lON2REagiTFQUzJ4Nn3+uq/FOmKCzsbhcLt4IlGdJS9M1g0pgtFWxw+beGzKk8Krn5kRhjKD27YN77oE9e7zXRz4wAlXEUUoXONywAdq3h0OH9Khq5EgX1kwZgfIcFy5Av37Qo4eeHDQUXc6ehT//1M/vvNO3tkDhBEn873/www/w2GPe6yMfGIEqJjRoAEuWwJtvQlAQfPoptGoFW7bkcpJJd+QZUlPh1lth+nT9etw47X81FE1+/13/T7t21WUFfI23R1DJyTBlin4+YwZs3OidfvKBEahiRFAQvPCCzszStCns3AkdOzqWclyCCZIoOOfPwy23wMyZOoKlb18dtv/ii762zJBfnN17/oC3BeqPPzK7W955xzv95AMjUMWQVq20SN12m/ZW3HgjfPxxNsudjIuvYKSkaEGaNUuvlVmwAL7+Wq/+nz4dli3ztYUGdzl4UM8jhoRA//6+tkbj7SAJmyC/8ILOWjF5MsTFeacvNzECVUwJC9Ofs5dfBosFHn8cRozQ8/h2nBfrWiy+MDN7Vq3SCyT9mXPn9CK0f/6BqlW1ONnqBT3xhD7m+efNIuiixoQJ+n/Wp49DGHyNN0dQhw7pdE6lSuky3gMH6lxq77/v+b7ygRGoYkxAgE6RNHGiviH86iu4/no4dcp6QFiYdkulpcHx4z611c577+kU7jExcOCAr63JnuRk6N0b5s+H6tX1HXfTpo73n34aKlXSiUZnz/aZmQY3EfE/9x54N0hi4kR93TfdpPt59lm9/5tv/OI3wQhUCWDgQFi0SN/oz5+vo/127rS+6S+BEiL6y/HMM/p1cjI88IDnRyCnTuk/RqahpBskJcENN+g2atTQ4tS4ceZjwsNh1Cj9/IUX/Gt0asiZ9eth61aIiNB3cv6CN0dQWQW5eXM9J5CaqiOtfIwRqBLClVfqeanoaNi1S7+eNw//CJRIT4f77oN339WRHh99pL+Us2bB+PGe6yclBbp109l2o6Lgqad07ihXOXsWrrtOJ0OMitIi1bBh9sc+8ogWsHXr8pnmIxtOntSuRYN3sP1YDxjg29RGWfGWQG3YoKNNK1fWN102nntOP37+ub4h8yUiUqS2Nm3aiCH/JCWJ9OkjAiKBgSKbu47QLz7+2DcGpaQ4DCpdWmTmTL3/hx/0vkqVRI4e9Uxfw4frNkuV0o+2rW1bkTFjRE6fzvnc06dF2rXTx9euLbJnT979ffmlPr5hQ5G0tILZvny5/vtcfrn+Jxo8S1qaSNWq+v/133++tiYzGRkiSmnb0tM91+5TT+k2H3ro0vc6ddLvvf++5/rLBmC15PJ773PBcXczAlVwMjJEnn1W//dH8X8iIBlPPl34hpw+LdKlizakYkWRZcsc71ksItddp9+77baC9/Xzz7qtkBCR9etFVq4UefBBkfBwh1CFhooMHCjyzz/6j2QjIUGkTRt9TN26Ivv2udbnxYtaUEBk7Nj8275/v+PHE0Qeeyz/bRmy5++/9d+2QQP92fM3KlTQ9p086Zn20tNFqlfXbTp/72xMn67fq1lT5MIFz/SZDUagDDny/fcidweOEwFZWO0OOXOmEDs/fFikRQvHl2Dz5kuPiYsTKVNGH/PHH/nva+9ekfLldTuff575vZQUkQkTRHr2lEyjqtq1RV5+WWTNGpFWrfS++vW1WLjDxIn63KgokfPn3bc9KUkkOlq3EROjh71K+d9dflHnzjv13/i113xtSfbUq6ft27XLM+3NmaPbu/zy7AU5I0OkWTN9zHffeabPbDACZciVDR8vEAH5l44SECBSrZr+PbzuOpG779YjrQ8+0L+z8+aJbNmiBxQFusncvVv/2NvcX3FxOR/76af6uGrVRE6dcr+vixcdrrlbbsnd8Lg4kVdf1aMkZ7GyfZEPHnS//4wMh8C46y7JyBC5+Wax39mfOuUY+jZvrq/NUHDOntXuU9A3M/5I69bavlWrPNPekCG6vdjYnI/56Sd9TKNGmT0KHsQIlCF3du8WATlSqtYlv8nZbxYZzpdykCjZX62tpL/wP5F//3V9jmXdOoe7KiZG5Pjx3I/PyHD4w++91/3rs/2g167tusBlZIjMny8yeLD+4WrSROTQIff7tjFjhrahcmWRxETXz3v+eX1ehQoi27frfefOiVx2md7/5pv5t8ng4Mcf9d+zc2dfW5IzthH+nDkFbys52eGZ2L075+MuXtTfm4J6MHLBCJQhd1JTxRYxcSElXeLjRVavFvnrL5Fvv9W/gY8+KnL77SLXdDonU8rflb1yhYeL9O+v51oOHMi+r4ULHa62nj31nasrbN+u547c/YLOmmW/Nvn3X9fPc+b8+YKPVCwW/eMHIq+84to548Y5bP/nn8zvzZ0r9vm0HTsKZptB5Oqr9d/zq698bUnO9Ounbfz554K3ZftsdeyY97GffKKPbdfOK3NzRqAMeVOliv4oxMfnfMzu3Y45o9KlZddLP8jQKjPkYx6VnarhpYLVtKmOEpozR//IT5niEJnbbtPC6A7/p4M5pG5d16LYDh8WiYwUvxlpLFmibSlbNu9R47JljkjDrHNmNoYO1e936+Y194vXsFj0/3DPHh2dOG2ayDff6P/xE0+IDBqkH90ZbeaX+Hg9p1eqVP5cyIXF/ffr//eXXxa8rWuv1W2NGZP3sefOiURE6OMXLCh431kwAmXIG1uE2vLl2b8/bZoj2u3yy0U2bhQRHYRnu7Grxx4Z1/ELSevdx+E+sG2lS4sEBOjnI0bkL1T24kVHsEJeUWwZGQ6XSM+eng3NLQi9emmbnngi52Pi4hw3DA8/nPNxJ086jvv6a8/b6iksFh0R1revdunWrq2jJV3xJ195Ze6h/57gnXd0X/36ebefgvLMM9rOt94qWDuHD+vvYqlSejLZFV57Tfd93XUF6zsbjEAZ8sY2Ef/LL5n3p6eLvPii4wfj5psla6ifxaJvxGyDoyZNRDavvaDvtp57zhEgYHNvFcRNsHatI4pt6dKcj7ONtiIj9RfSX1i3TuyuuezcoElJjlHq1VfnPa83aZLY3av+dJ0i+v/8zz9aZLITn9KlRerU0WvQevfWI8JnnxV5913tW7YFqrRu7bnQ6uxo3lz3M3Wq9/rwBLbP9HPPFayd994Te8CQqyQkOG46164tWP9Z8KlAAdcDO4DdwKhs3n8S2ApsBOYBdfJq0wiUF3jkEbkkyuz4cYdvPiBAZPToXMVlwwaRxo314aGh+qbefvjhw/oAT2ALHGjcOPuw7aVLtYiBnoPyNwYM0Lbdd1/m/RkZjgXLDRu65m6yWByjsv79vWNvfliyRLsebWIUGal/GFes0FFyycl5t7F/vyMYpEWLvN2i+WH9et1+pUpeXevjEcaM0bYOH16wdmw3jO4GPTzxhD5vwICC9Z8FnwkUEAjsAeoDpYANQJMsx/QAwqzPRwA/59WuESgv8Pbbksn1tGKFSK1ajh+XefNcaiY5WeSeexy/S3fcccmAq+CcP6/DXkGP7pw5dcoRdfTssx7u2EPs3KkFNCDAEZknou+MbRF77gQ+7N/vuLv19Shg5UrH4mrQi6/feiv/mS/i4x3/6yZNRI4c8ay9Tz8tdrezv2MbLRdk0frGjY7/i7tzwAcPigQH689tbpF/buJLgeoAzHZ6/TzwfC7HtwKW5tWuESgvYFtM2r+/vlMLDtav27fP19qf8eN1LADo5U4rV3rY3n//1W6+oCDtNhPRo4lbbxX73IU/rxGypVyy/djYwpwDA3WEnrt8/LE+v2bNwgksyMqGDXqOySZM5cppd64n7k6OHNHiZBtZ5hbI4w7p6SI1auh2s8uk4G/YIlKvvjr/bdjmsR58MH/n2+4+83t+NvhSoPoD3zi9HgJ8lsvxnwEv5fDecGA1sLp27doe++MYrNgizGzCBNrtVwC3x86djrWFQUF6asGjXhSbW7J1az1X8/nn+nX58v672NJGfLwjUODTTx0Re198kb/20tMdcz3Z5VXzFtu26WGy7TMTFqZHgp6eMzp+3OGauuwy97N5ZEdemRT8jRUrtL35vUF3FuT8LrnYulXsc6geyo9ZJAQKGAz8B4Tk1a4ZQXmBuLjMPzLjx3uk2dRUHXBna7pmTT0V4ZGb/KQkhzvv3nsdURpZAz38FZt7yfmGoCBs3KjvBAryA+Qqa9fqRcy2yMyQEJHHH/dcUt/syJoPsaA3Ia5kUvAndu50CHR++Ocfsbs0CiLItoCq55/PfxtO+L2LD7ga2AZUcaVdI1BeID1d591q0kRk0yaPNz99ul4WZfstLl9eTxEVJDmDiIjMnp35R76gE8iFycmTjkXL11xT8GznIo6IyyuucH+OIS/S0kR+/dWx4Ng2NH7wwfylgMoPp087RopRUfpHOz+4mknBnzhxQuwBHfnhLusC+5dfLpgdy5frdsLDPXKn6UuBCgL2AvWcgiSaZjmmlTWQooGr7RqB8hLp6V51dWRk6OwUzsFdwcHarb1lSwEati1YbdpULyosSvz2mx79eWqB6Pnzep7GFtLvCRISdBCNbbRqu8N44gnfuFITEx0iWb26djO6izuZFPyFixfFHlHr7sJsZ0HOr6g70727buuddwrclK/DzHsBO60i9KJ132tAH+vzucAxYL11m5ZXm0agij4rV+r4AJuHCPRSmIUL86GRSUn6i+KJeYniwMKFDvUviPJv2SLywAOOJKqgE9Z++qnrKaq8RVKSSI8e2qYqVdwf9dsiDV3JpOBP2CKP3A0+GT9e7EFPnsBWmqRatfxl6HciL4FS+piiQ0xMjKxevdrXZhg8wJ498MEH8P33cP683teuna76ftVVuoDtmTPZb4mJjudJSVCpki5gW7OmfnTeypXzzfX5jOHDYexY6NgRliyBABcLZ1ss8Pff8PHH8M8/jv3XXQcjR+oy6K625W1SUuDmm7WdlSvrD1KZMto+pXJ+TE2FW2+FwEA4ckSfW1SoXRsOHtSVcFu0cP28G27Q1ak//xweeqjgdohAq1bajhkzoFevfDellFojIjE5vm8EyuBrTpzQ353PPoOEBM+3X7ZsZsGqW1cLYKdOEBrq+f58zpkzcMUVcPSovvjQUAgJ0VupUo7nWbeNG2H3bt1GWBjcfTc8+qhuyx9JTYV+/WDmTPfPvflmmDLF4yZ5lY4dYflyKF0aHnkEnn0WIiJyP+foUX3X5mlBXrZM3/k1b16gZoxAGYoMKSl6NPXpp/q7VKFC7lt4uH4sW1YL2+HDl26HDjlGZ1kpXRq6ddMDhGuv1b/DShXKpXqf6dP1j3damnvn1amjf/zuuw8qVvSObZ7kwgV44w3YulXf2VssmR+z2xcSAv/3f+6NQvyB3bvhuefgjz/067Jl4Ykn4Mkn9RchOz78UL/fty9MnVpYlrqMEShDiUZEuwqdBWvTJpgzRw8YnKlZUwvVtdfC1VfnfXPq96SladW/cEFvFy86nme3hYdDjx4QFORryw25sWYN/O9/2h0L+kbimWf0aLds2czHtm4N69bBb7/pGxY/wwiUwZADR47A3LlarObMgePHHe8ppb/b116rf7NjYorGgMJQgli6FF56CRYu1K+rVIHnn4cHH9Ru3S1boFkzPbo6elSPHP0MI1AGgwtYLI6R1Zw5OrbgwoXMxzRoAG3b6kCOtm31PHHp0r6x12AAtItg/nx48UVYsULvq1lTC9euXTp4ZPhw+Oor39qZA0agDIZ8kJKiRWrOHD0vvXbtpYIVGKjniG2C1a4dNGliPGQGHyCig0VeegnWr8/83pIl0LmzT8zKCyNQBoMHSEuDzZth1SpYuVI/bt6sR17OhIXBnXfquezLL/eNrYYSjMWigyhefhm2bdPD/u3b/Wd5QBaMQBkMXuLcOT3/7Cxae/bo9wIC4I47YNSoohcsZigGZGTAvHlaoOrV87U1OWIEymAoRHbuhHfegZ9+ckR433QTvPACtG/vW9sMBn8jL4Hyz3GfwVBEadgQvvlGj6Qee0wHUUyfDh066MXBc+fq6QKDwZA3ZgRlMHiREyd05qDPPtPpmUAHVLzwAvTpk/PUQEaGPvfIEcdmSwzRrJneqlQpRguLDSUS4+IzGPyAxEQYM0ZH/Z44ofc1aQJDh0JycmYhOnxYr8nKyMi9zYgIh1g1bep4NOu1DEUFI1AGgx+RkgLffgvvvqvzfuZGRARUr+7YqlWD06d19ODmzTpDRnbUrOkQq0aNdDRhgwZ6v58GcxlKKEagDAY/5OJFmDhRr62MjMwsRDYxKlUq5/NFID7eIVZbtujHrVtzzj0YGgqXXeYQLOfHqKiiK16bNzuy2RuKFkagDIYSREYG7NvnEK1du3SO0V27MqdyykpIiBarFi0gOtqxVatWeLa7y4ULOrPPhx/q9Wdvv62rSRQVod28WQfQDBmibxBKIkagDAYDoF2Cu3c7BMsV8apSJbNgRUdD48YQHFy4tmdl2zYYOFCXJFLKERnZtSt8950eKfory5bBW2/BX3/p19Wr6yQQLVv61CyfYATKYDDkydmzOuHAhg2ObePG7Oe5SpXSAR6NG+vaWs5b7drezU8oAl9/ratMnD+vhWjiRJ2lfsQIOHZMj6beektXDfGX0ZSIrhn41ls68xBol2u9elpsy5bVCcevu863dhY2RqAMBkO+EIG4OIdY2YTLli0jJ6pV02WlnIWrfn2dDi4sLP/2JCTAsGGOOoN3361rh9kqJick6MK/Eyfq11266NGUL1NOZWTAr7/C6NH6bwe6qskjj2hbw8N1JOfkyTq349ixcM89vrO3sMlLoHKsBe+vW5s2bdyoeG8wGDzN2bMiS5eK/PSTyGuvidx7r8hVV4lcdplIcLCtSuClW7lyIvfdJ7J4sYjF4l6f8+aJ1Kyp2ylfXmTixJyPnTJFpGpVfWzp0iIffiiSkVGQK3af8+dFvvpK/01s11+tmsg774gkJmY+NiND5LnnHMe98or7f5+iCrBacvm997nguLsZgTIY/Jf0dJGDB0WWLBEZN07k9de1KMXEZBar+vVFYmNF9u7Nvb2LF0VGjRJRSp/XsaPIvn1525GQIDJ4sKO/zp1Fdu70yCXmytmzWoSqV3f0fdllWqzOn8/93M8/FwkI0Ofcc4++9uKOESiDweAXbNsm8vzzIlFRmcWqa1eRb7/VP+7O7Nol0ratPiYgQAtaWpp7ff75px65gEhoqMgHH2gR9SQWi8iKFSLDh+tRou26oqNFJk1yz+Y//9SjPhC59tpLR1vFDSNQBoPBr0hPF5kzR2TQIMePMYiEhelRzz//iHz/vUiZMnp/nToi//6b//4SEkSGDHH007GjyM8/ixw7VrDrOHFCC16zZpcK7syZ+XfTrVghEhnpELlDhwpmpz+Tl0CZIAmDweAzzp7V0Ws//giLF1/6/oABOkVUhQoF72v6dHjgAZ1Oykbz5jqJ71VX6RD1vPrJyIB//tHZQP7805GxPiIC7roL7r1XZ/AoKHv2wA036CUAtWrB3397pl1/w0TxGQyGIsHevTBunBarhAQdoTdkiGcT4p4+raufz5sH//4LqamO9wICoE0bh2B16gRlyjhs+/57+OEHncHDdvz112tRuumm3DN/5IeTJ3VC4eXLdbTflCnQo4dn+/A1RqAMBkORQgTS072/GPjCBfjvP5g/X2///af7tREcrGt4BQXBggWO/fXra1G6+27vZ4A4fx4GD9ZFcoODdVb8m2/WC6iLA0agDAaDwQWSk2HpUodgrVnjyFARGgr9+2th6tatcBcAZ2TA00/DRx859lWpot2TzZrpx+bNtQvQNuIrKhiBMhgMhnxw+jQsWgRJSdqF54l5sIIwdqx2M27erG3KilI6M4VNsJo31+mTLr/cfzJqZMUIlMFgMBQjRODAAdi0ybFt3qxTVdmCNpwpX17PrcXEOB7r1/ePYpdGoAwGg6EEcPEi7NypxWrTJp2eat06nacwKxUrOsTKJlx16uj3EhN1gIZtO3Ei82vnfQsW6Dpj+cUIlMFgMJRgjhzR82mrVzu2Y8cuPa5cOR2U4Rwokhdr10KrVvm3LS+BCsp/0waDwWDwd6pXhxtv1BtoF+GhQ5eK1smT+v1y5fS6rshI/Wjbsr6OiNBzXt7ECJTBYDCUIJTS4fFRUdC3r94nAqdO6bIfISG+tc8ZI1AGg8FQwlEKKlf2tRWX4qfBhwaDwWAo6RiBMhgMBoNfYgTKYDAYDH6JESiDwWAw+CVGoAwGg8HglxiBMhgMBoNfYgTKYDAYDH6JESiDwWAw+CVFLhefUuoEsL+AzUQAJz1gjr9TUq4TSs61mussfpSUa83uOuuISGROJxQ5gfIESqnVuSUoLC6UlOuEknOt5jqLHyXlWvNzncbFZzAYDAa/xAiUwWAwGPySkipQX/vagEKipFwnlJxrNddZ/Cgp1+r2dZbIOSiDwWAw+D8ldQRlMBgMBj/HCJTBYDAY/JISJVBKqeuVUjuUUruVUqN8bY83UUrFKaU2KaXWK6VW+9oeT6GU+k4pdVwptdlpXyWl1D9KqV3Wx4q+tNFT5HCtsUqpQ9b/63qlVC9f2ugJlFK1lFILlFJblVJblFKPWfcXq/9rLtdZrP6nSqlQpdRKpdQG63W+at1fTym1wvr7+7NSqlSebZWUOSilVCCwE7gGiAdWAQNFZKtPDfMSSqk4IEZEitUCQKVUVyAZ+ElEmln3vQOcEpHR1huPiiLynC/t9AQ5XGsskCwi7/nSNk+ilKoOVBeRtUqpcsAa4GZgKMXo/5rLdd5OMfqfKqUUUEZEkpVSwcC/wGPAk8AfIjJZKfUlsEFExuTWVkkaQbUDdovIXhG5CEwG+vrYJoObiMhi4FSW3X2BH63Pf0R/6Ys8OVxrsUNEjojIWuvzJGAbUJNi9n/N5TqLFaJJtr4Mtm4CXAX8Zt3v0v+zJAlUTeCg0+t4iuGHwwkB5iil1iilhvvaGC9TVUSOWJ8fBar60phC4BGl1EarC7BIu72yopSqC7QCVlCM/69ZrhOK2f9UKRWolFoPHAf+AfYAZ0Qk3XqIS7+/JUmgShqdRaQ1cAPwsNVdVOwR7bMuzn7rMcBlQEvgCPC+T63xIEqpssDvwOMictb5veL0f83mOovd/1REMkSkJRCF9l41zk87JUmgDgG1nF5HWfcVS0TkkPXxODAF/SEprhyz+vdtfv7jPrbHa4jIMeuX3wKMpZj8X61zFb8DE0TkD+vuYvd/ze46i+v/FEBEzgALgA5ABaVUkPUtl35/S5JArQIaWCNJSgEDgGk+tskrKKXKWCdhUUqVAa4FNud+VpFmGnC39fndwJ8+tMWr2H6wrdxCMfi/WifVvwW2icgHTm8Vq/9rTtdZ3P6nSqlIpVQF6/PS6MC0bWih6m89zKX/Z4mJ4gOwhm9+BAQC34nIm761yDsopeqjR00AQcDE4nKtSqlJQHd06v5jwCvAVOAXoDa6FMvtIlLkgwtyuNbuaFeQAHHAA07zNEUSpVRnYAmwCbBYd7+Anp8pNv/XXK5zIMXof6qUaoEOgghED4J+EZHXrL9Lk4FKwDpgsIhcyLWtkiRQBoPBYCg6lCQXn8FgMBiKEEagDAaDweCXGIEyGAwGg19iBMpgMBgMfokRKIPBYDD4JUagDAYPo5TKcMpMvd6TmfOVUnWds5sbDMWZoLwPMRgMbnLemubFYDAUADOCMhgKCWuNrnesdbpWKqUut+6vq5Sab00WOk8pVdu6v6pSaoq1rs4GpVRHa1OBSqmx1lo7c6yr9VFKjbTWGtqolJrso8s0GDyGESiDwfOUzuLiu8PpvUQRaQ58hs5qAvAp8KOItAAmAJ9Y938CLBKRaKA1sMW6vwHwuYg0Bc4A/az7RwGtrO086J1LMxgKD5NJwmDwMEqpZBEpm83+OOAqEdlrTRp6VEQqK6VOogvZpVn3HxGRCKXUCSDKOR2MtUzDPyLSwPr6OSBYRN5QSs1CFzicCkx1qsljMBRJzAjKYChcJIfn7uCcvywDx1xyb+Bz9GhrlVPmaIOhSGIEymAoXO5welxufb4MnV0fYBA6oSjAPGAE2AvAhefUqFIqAKglIguA54Bw4JJRnMFQlDB3WAaD5yltrSZqY5aI2ELNKyqlNqJHQQOt+x4FvldKPQOcAO6x7n8M+FopdR96pDQCXdAuOwKB8VYRU8An1lo8BkORxcxBGQyFhHUOKkZETvraFoOhKGBcfAaDwWDwS8wIymAwGAx+iRlBGQwGg8EvMQJlMBgMBr/ECJTBYDAY/BIjUAaDwWDwS4xAGQwGg8Ev+X+k+sAPET14WAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f118576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

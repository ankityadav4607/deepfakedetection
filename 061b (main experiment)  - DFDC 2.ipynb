{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import json\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '061b (main experiment)  - DFDC 2'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFDCClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, root, names, metapath, allImageTensorPath, transform = None):\n",
    "        \n",
    "        self.root = root\n",
    "        \n",
    "        print('Loading all image tensors')\n",
    "        self.allImages = torch.load(allImageTensorPath)\n",
    "        print('Loading complete')\n",
    "               \n",
    "        self.allNames = torch.load(names)\n",
    "        \n",
    "        self.allIndices = list(self.allNames.keys())\n",
    "        \n",
    "        f = open(metapath)\n",
    "        \n",
    "        self.meta = json.load(f)\n",
    "        \n",
    "        self.transform = transform             \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.allNames)\n",
    "    \n",
    "#     def getName(self, allnames, idx):\n",
    "        \n",
    "#         for i in range(len(allnames)):\n",
    "            \n",
    "#             if(allnames[i][0] == idx):\n",
    "#                 n = allnames[i][1]\n",
    "                \n",
    "#         return n\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        actualIndex = self.allIndices[index]\n",
    "        \n",
    "        vidTensor = self.allImages[actualIndex]\n",
    "        \n",
    "        video = self.allNames[actualIndex]\n",
    "        \n",
    "#         videoPath = self.root + str(actualIndex) + '/'\n",
    "        \n",
    "#         ofPath = self.ofpath + str(folderValue) + '/' + videoName[0:-4] + '.pt'\n",
    "        \n",
    "#         vidTensor = torch.load(videoPath)[0]\n",
    "    \n",
    "#         vidTensor = getFaceTensor3(videoPath, 32)\n",
    "#         ofTensor = getOFTensor(ofPath, 0)\n",
    "        \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "#             ofTensor = self.transform(ofTensor)\n",
    "#             print('Transformation successful')\n",
    "        \n",
    "        label_string = self.meta[video]['label']\n",
    "        \n",
    "        if(label_string == 'fake'):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "#         print('labels : ', label)\n",
    "        \n",
    "        return (vidTensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5220ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = '/home/ankit/datasets/DFDC preview/extracted faces/'\n",
    "\n",
    "metaPath = '/home/biometricgpu09/datasets/DFDCPreview/dataset.json'\n",
    "\n",
    "namesPath = '/home/biometricgpu09/datasets/DFDCPreview/DFDC preview all videos list FINAL.pt'\n",
    "\n",
    "allImageTensorFile = '/home/biometricgpu09/datasets/DFDCPreview/allImages.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 3500\n",
    "num_samples_validation = 700\n",
    "num_samples_test = 857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all image tensors\n",
      "Loading complete\n"
     ]
    }
   ],
   "source": [
    "dataset = DFDCClassification(rootPath, namesPath, metaPath, allImageTensorFile, transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5057\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "30\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.69263837 \n",
      "Epoch 1, Batch 20, Loss 0.67174193 \n",
      "Epoch 1, Batch 30, Loss 0.65287145 \n",
      "Epoch 1, Batch 40, Loss 0.64521146 \n",
      "Epoch 1, Batch 50, Loss 0.61801587 \n",
      "Epoch 1, Batch 60, Loss 0.58716432 \n",
      "Epoch 1, Batch 70, Loss 0.54320338 \n",
      "Epoch 1, Batch 80, Loss 0.49723240 \n",
      "Epoch 1, Batch 90, Loss 0.46190580 \n",
      "Epoch 1, Batch 100, Loss 0.46983435 \n",
      "Epoch 1, Batch 110, Loss 0.48816297 \n",
      "Epoch 1, Batch 120, Loss 0.43851437 \n",
      "Epoch 1, Batch 130, Loss 0.44585142 \n",
      "Epoch 1, Batch 140, Loss 0.44083224 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.39038605988025665\n",
      "Validation loss :  0.37890521734952926\n",
      "Validation loss :  0.3060991384088993\n",
      "---------\n",
      "Correct :  17984\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.8028571428571428\n",
      "---------\n",
      "Epoch time :  87.227224\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.5e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.43080457 \n",
      "Epoch 2, Batch 20, Loss 0.43502907 \n",
      "Epoch 2, Batch 30, Loss 0.38505771 \n",
      "Epoch 2, Batch 40, Loss 0.33420623 \n",
      "Epoch 2, Batch 50, Loss 0.39054984 \n",
      "Epoch 2, Batch 60, Loss 0.37161805 \n",
      "Epoch 2, Batch 70, Loss 0.33525420 \n",
      "Epoch 2, Batch 80, Loss 0.38862710 \n",
      "Epoch 2, Batch 90, Loss 0.35567202 \n",
      "Epoch 2, Batch 100, Loss 0.38278016 \n",
      "Epoch 2, Batch 110, Loss 0.32014717 \n",
      "Epoch 2, Batch 120, Loss 0.39271820 \n",
      "Epoch 2, Batch 130, Loss 0.34138273 \n",
      "Epoch 2, Batch 140, Loss 0.33227927 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.3198956996202469\n",
      "Validation loss :  0.32691340148448944\n",
      "Validation loss :  0.2719837695360184\n",
      "---------\n",
      "Correct :  19510\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.8709821428571428\n",
      "---------\n",
      "Epoch time :  70.287001\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.025e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.30577701 \n",
      "Epoch 3, Batch 20, Loss 0.31519403 \n",
      "Epoch 3, Batch 30, Loss 0.26060606 \n",
      "Epoch 3, Batch 40, Loss 0.28336713 \n",
      "Epoch 3, Batch 50, Loss 0.30188536 \n",
      "Epoch 3, Batch 60, Loss 0.31598443 \n",
      "Epoch 3, Batch 70, Loss 0.27903996 \n",
      "Epoch 3, Batch 80, Loss 0.28082908 \n",
      "Epoch 3, Batch 90, Loss 0.26999981 \n",
      "Epoch 3, Batch 100, Loss 0.29313791 \n",
      "Epoch 3, Batch 110, Loss 0.25054760 \n",
      "Epoch 3, Batch 120, Loss 0.23550717 \n",
      "Epoch 3, Batch 130, Loss 0.28671741 \n",
      "Epoch 3, Batch 140, Loss 0.20722298 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.21757067516446113\n",
      "Validation loss :  0.24680753648281098\n",
      "Validation loss :  0.20899500027298928\n",
      "---------\n",
      "Correct :  20765\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9270089285714286\n",
      "---------\n",
      "Epoch time :  70.738804\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.573749999999999e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.27846842 \n",
      "Epoch 4, Batch 20, Loss 0.25270677 \n",
      "Epoch 4, Batch 30, Loss 0.26864557 \n",
      "Epoch 4, Batch 40, Loss 0.21196174 \n",
      "Epoch 4, Batch 50, Loss 0.22832670 \n",
      "Epoch 4, Batch 60, Loss 0.25083940 \n",
      "Epoch 4, Batch 70, Loss 0.22634881 \n",
      "Epoch 4, Batch 80, Loss 0.25715839 \n",
      "Epoch 4, Batch 90, Loss 0.23903750 \n",
      "Epoch 4, Batch 100, Loss 0.18930087 \n",
      "Epoch 4, Batch 110, Loss 0.17906106 \n",
      "Epoch 4, Batch 120, Loss 0.22121641 \n",
      "Epoch 4, Batch 130, Loss 0.22589948 \n",
      "Epoch 4, Batch 140, Loss 0.19962762 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.23505087792873383\n",
      "Validation loss :  0.2381916455924511\n",
      "Validation loss :  0.17199950031936168\n",
      "---------\n",
      "Correct :  20501\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9152232142857143\n",
      "---------\n",
      "Epoch time :  69.183768\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.145062499999998e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.18370289 \n",
      "Epoch 5, Batch 20, Loss 0.19455932 \n",
      "Epoch 5, Batch 30, Loss 0.19090252 \n",
      "Epoch 5, Batch 40, Loss 0.14741085 \n",
      "Epoch 5, Batch 50, Loss 0.21288781 \n",
      "Epoch 5, Batch 60, Loss 0.27638612 \n",
      "Epoch 5, Batch 70, Loss 0.19991351 \n",
      "Epoch 5, Batch 80, Loss 0.22497425 \n",
      "Epoch 5, Batch 90, Loss 0.16874391 \n",
      "Epoch 5, Batch 100, Loss 0.17885672 \n",
      "Epoch 5, Batch 110, Loss 0.21235285 \n",
      "Epoch 5, Batch 120, Loss 0.22695257 \n",
      "Epoch 5, Batch 130, Loss 0.17815203 \n",
      "Epoch 5, Batch 140, Loss 0.15819665 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.14767430871725082\n",
      "Validation loss :  0.13581402003765106\n",
      "Validation loss :  0.23816513866186143\n",
      "---------\n",
      "Correct :  21051\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9397767857142857\n",
      "---------\n",
      "Epoch time :  69.055105\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.737809374999998e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.20569344 \n",
      "Epoch 6, Batch 20, Loss 0.16731505 \n",
      "Epoch 6, Batch 30, Loss 0.21186342 \n",
      "Epoch 6, Batch 40, Loss 0.25048637 \n",
      "Epoch 6, Batch 50, Loss 0.19480926 \n",
      "Epoch 6, Batch 60, Loss 0.18628775 \n",
      "Epoch 6, Batch 70, Loss 0.16229730 \n",
      "Epoch 6, Batch 80, Loss 0.16975753 \n",
      "Epoch 6, Batch 90, Loss 0.18876502 \n",
      "Epoch 6, Batch 100, Loss 0.16858705 \n",
      "Epoch 6, Batch 110, Loss 0.16964811 \n",
      "Epoch 6, Batch 120, Loss 0.15073545 \n",
      "Epoch 6, Batch 130, Loss 0.20730329 \n",
      "Epoch 6, Batch 140, Loss 0.16740650 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.15991807784885168\n",
      "Validation loss :  0.16024229303002357\n",
      "Validation loss :  0.12285048216581344\n",
      "---------\n",
      "Correct :  21200\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9464285714285714\n",
      "---------\n",
      "Epoch time :  69.331909\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.350918906249998e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.15300402 \n",
      "Epoch 7, Batch 20, Loss 0.13627135 \n",
      "Epoch 7, Batch 30, Loss 0.15382164 \n",
      "Epoch 7, Batch 40, Loss 0.16603106 \n",
      "Epoch 7, Batch 50, Loss 0.10630906 \n",
      "Epoch 7, Batch 60, Loss 0.15695684 \n",
      "Epoch 7, Batch 70, Loss 0.15084758 \n",
      "Epoch 7, Batch 80, Loss 0.17350275 \n",
      "Epoch 7, Batch 90, Loss 0.19008264 \n",
      "Epoch 7, Batch 100, Loss 0.17444444 \n",
      "Epoch 7, Batch 110, Loss 0.12082394 \n",
      "Epoch 7, Batch 120, Loss 0.21281746 \n",
      "Epoch 7, Batch 130, Loss 0.15015768 \n",
      "Epoch 7, Batch 140, Loss 0.15453521 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.18789325207471846\n",
      "Validation loss :  0.16511915773153304\n",
      "Validation loss :  0.1359157834202051\n",
      "---------\n",
      "Correct :  20969\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9361160714285715\n",
      "---------\n",
      "Epoch time :  69.812357\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.983372960937497e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.14994657 \n",
      "Epoch 8, Batch 20, Loss 0.10160026 \n",
      "Epoch 8, Batch 30, Loss 0.14935339 \n",
      "Epoch 8, Batch 40, Loss 0.17013263 \n",
      "Epoch 8, Batch 50, Loss 0.16461437 \n",
      "Epoch 8, Batch 60, Loss 0.17288896 \n",
      "Epoch 8, Batch 70, Loss 0.12320348 \n",
      "Epoch 8, Batch 80, Loss 0.14063256 \n",
      "Epoch 8, Batch 90, Loss 0.10606230 \n",
      "Epoch 8, Batch 100, Loss 0.13886994 \n",
      "Epoch 8, Batch 110, Loss 0.19113947 \n",
      "Epoch 8, Batch 120, Loss 0.15284778 \n",
      "Epoch 8, Batch 130, Loss 0.17980773 \n",
      "Epoch 8, Batch 140, Loss 0.16153772 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.18814046494662762\n",
      "Validation loss :  0.11389753594994545\n",
      "Validation loss :  0.13411398082971573\n",
      "---------\n",
      "Correct :  21149\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9441517857142857\n",
      "---------\n",
      "Epoch time :  69.244746\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.634204312890622e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.15082459 \n",
      "Epoch 9, Batch 20, Loss 0.14201130 \n",
      "Epoch 9, Batch 30, Loss 0.13424496 \n",
      "Epoch 9, Batch 40, Loss 0.16075839 \n",
      "Epoch 9, Batch 50, Loss 0.13088479 \n",
      "Epoch 9, Batch 60, Loss 0.14513932 \n",
      "Epoch 9, Batch 70, Loss 0.15931846 \n",
      "Epoch 9, Batch 80, Loss 0.15480032 \n",
      "Epoch 9, Batch 90, Loss 0.11814470 \n",
      "Epoch 9, Batch 100, Loss 0.11789342 \n",
      "Epoch 9, Batch 110, Loss 0.11096894 \n",
      "Epoch 9, Batch 120, Loss 0.13160007 \n",
      "Epoch 9, Batch 130, Loss 0.12503808 \n",
      "Epoch 9, Batch 140, Loss 0.11200439 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.12874215096235275\n",
      "Validation loss :  0.14530897475779056\n",
      "Validation loss :  0.11951050944626332\n",
      "---------\n",
      "Correct :  21262\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9491964285714286\n",
      "---------\n",
      "Epoch time :  69.150119\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [6.30249409724609e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.10078110 \n",
      "Epoch 10, Batch 20, Loss 0.13500681 \n",
      "Epoch 10, Batch 30, Loss 0.09568993 \n",
      "Epoch 10, Batch 40, Loss 0.11742357 \n",
      "Epoch 10, Batch 50, Loss 0.09426143 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 60, Loss 0.10838977 \n",
      "Epoch 10, Batch 70, Loss 0.13204738 \n",
      "Epoch 10, Batch 80, Loss 0.12626972 \n",
      "Epoch 10, Batch 90, Loss 0.11135635 \n",
      "Epoch 10, Batch 100, Loss 0.15021813 \n",
      "Epoch 10, Batch 110, Loss 0.15150940 \n",
      "Epoch 10, Batch 120, Loss 0.13528860 \n",
      "Epoch 10, Batch 130, Loss 0.10966737 \n",
      "Epoch 10, Batch 140, Loss 0.11598136 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.14565199762582778\n",
      "Validation loss :  0.10062361396849155\n",
      "Validation loss :  0.13525897413492202\n",
      "---------\n",
      "Correct :  21222\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9474107142857143\n",
      "---------\n",
      "Epoch time :  69.464436\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.987369392383786e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.10004411 \n",
      "Epoch 11, Batch 20, Loss 0.14901531 \n",
      "Epoch 11, Batch 30, Loss 0.11740232 \n",
      "Epoch 11, Batch 40, Loss 0.12758088 \n",
      "Epoch 11, Batch 50, Loss 0.14362551 \n",
      "Epoch 11, Batch 60, Loss 0.10983687 \n",
      "Epoch 11, Batch 70, Loss 0.14589771 \n",
      "Epoch 11, Batch 80, Loss 0.14079232 \n",
      "Epoch 11, Batch 90, Loss 0.08126874 \n",
      "Epoch 11, Batch 100, Loss 0.13066628 \n",
      "Epoch 11, Batch 110, Loss 0.11215097 \n",
      "Epoch 11, Batch 120, Loss 0.12482912 \n",
      "Epoch 11, Batch 130, Loss 0.14586242 \n",
      "Epoch 11, Batch 140, Loss 0.13598290 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.308303128182888\n",
      "Validation loss :  0.32239277064800265\n",
      "Validation loss :  0.4281951516866684\n",
      "---------\n",
      "Correct :  18597\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.8302232142857143\n",
      "---------\n",
      "Epoch time :  69.068403\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.688000922764596e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.17207847 \n",
      "Epoch 12, Batch 20, Loss 0.10024131 \n",
      "Epoch 12, Batch 30, Loss 0.11043985 \n",
      "Epoch 12, Batch 40, Loss 0.15857512 \n",
      "Epoch 12, Batch 50, Loss 0.18659276 \n",
      "Epoch 12, Batch 60, Loss 0.09777462 \n",
      "Epoch 12, Batch 70, Loss 0.10116839 \n",
      "Epoch 12, Batch 80, Loss 0.11663451 \n",
      "Epoch 12, Batch 90, Loss 0.14159362 \n",
      "Epoch 12, Batch 100, Loss 0.08454215 \n",
      "Epoch 12, Batch 110, Loss 0.12079762 \n",
      "Epoch 12, Batch 120, Loss 0.10243410 \n",
      "Epoch 12, Batch 130, Loss 0.10698591 \n",
      "Epoch 12, Batch 140, Loss 0.12292350 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.14616993255913258\n",
      "Validation loss :  0.20304508302360774\n",
      "Validation loss :  0.12345136161893606\n",
      "---------\n",
      "Correct :  21210\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.946875\n",
      "---------\n",
      "Epoch time :  69.336951\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.4036008766263664e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.10767889 \n",
      "Epoch 13, Batch 20, Loss 0.13919023 \n",
      "Epoch 13, Batch 30, Loss 0.11578358 \n",
      "Epoch 13, Batch 40, Loss 0.14320897 \n",
      "Epoch 13, Batch 50, Loss 0.10712627 \n",
      "Epoch 13, Batch 60, Loss 0.15428729 \n",
      "Epoch 13, Batch 70, Loss 0.12987503 \n",
      "Epoch 13, Batch 80, Loss 0.13015258 \n",
      "Epoch 13, Batch 90, Loss 0.09485318 \n",
      "Epoch 13, Batch 100, Loss 0.09692863 \n",
      "Epoch 13, Batch 110, Loss 0.10944389 \n",
      "Epoch 13, Batch 120, Loss 0.10898913 \n",
      "Epoch 13, Batch 130, Loss 0.10609132 \n",
      "Epoch 13, Batch 140, Loss 0.09174766 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.16160054407082497\n",
      "Validation loss :  0.11990951858460903\n",
      "Validation loss :  0.09981382237747312\n",
      "---------\n",
      "Correct :  21404\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9555357142857143\n",
      "---------\n",
      "Epoch time :  69.318397\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [5.133420832795048e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.09793954 \n",
      "Epoch 14, Batch 20, Loss 0.07889759 \n",
      "Epoch 14, Batch 30, Loss 0.12075747 \n",
      "Epoch 14, Batch 40, Loss 0.08849682 \n",
      "Epoch 14, Batch 50, Loss 0.07372491 \n",
      "Epoch 14, Batch 60, Loss 0.07312872 \n",
      "Epoch 14, Batch 70, Loss 0.08707073 \n",
      "Epoch 14, Batch 80, Loss 0.13410278 \n",
      "Epoch 14, Batch 90, Loss 0.09659017 \n",
      "Epoch 14, Batch 100, Loss 0.18984062 \n",
      "Epoch 14, Batch 110, Loss 0.09957365 \n",
      "Epoch 14, Batch 120, Loss 0.12093744 \n",
      "Epoch 14, Batch 130, Loss 0.12036379 \n",
      "Epoch 14, Batch 140, Loss 0.11352391 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.19083231389522554\n",
      "Validation loss :  0.14460023082792758\n",
      "Validation loss :  0.16066478826105596\n",
      "---------\n",
      "Correct :  20780\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9276785714285715\n",
      "---------\n",
      "Epoch time :  69.242724\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.876749791155295e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.08937468 \n",
      "Epoch 15, Batch 20, Loss 0.08031926 \n",
      "Epoch 15, Batch 30, Loss 0.11773919 \n",
      "Epoch 15, Batch 40, Loss 0.09597477 \n",
      "Epoch 15, Batch 50, Loss 0.11914949 \n",
      "Epoch 15, Batch 60, Loss 0.08768105 \n",
      "Epoch 15, Batch 70, Loss 0.11294030 \n",
      "Epoch 15, Batch 80, Loss 0.10455192 \n",
      "Epoch 15, Batch 90, Loss 0.10137387 \n",
      "Epoch 15, Batch 100, Loss 0.11751877 \n",
      "Epoch 15, Batch 110, Loss 0.10560673 \n",
      "Epoch 15, Batch 120, Loss 0.09762112 \n",
      "Epoch 15, Batch 130, Loss 0.09662934 \n",
      "Epoch 15, Batch 140, Loss 0.09701221 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11577176079154014\n",
      "Validation loss :  0.14069645553827287\n",
      "Validation loss :  0.1041424646275118\n",
      "---------\n",
      "Correct :  21344\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9528571428571428\n",
      "---------\n",
      "Epoch time :  69.372183\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.6329123015975305e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.09124828 \n",
      "Epoch 16, Batch 20, Loss 0.06853299 \n",
      "Epoch 16, Batch 30, Loss 0.08349413 \n",
      "Epoch 16, Batch 40, Loss 0.09641447 \n",
      "Epoch 16, Batch 50, Loss 0.09001615 \n",
      "Epoch 16, Batch 60, Loss 0.07075164 \n",
      "Epoch 16, Batch 70, Loss 0.10408703 \n",
      "Epoch 16, Batch 80, Loss 0.10135792 \n",
      "Epoch 16, Batch 90, Loss 0.08435428 \n",
      "Epoch 16, Batch 100, Loss 0.09505215 \n",
      "Epoch 16, Batch 110, Loss 0.11605229 \n",
      "Epoch 16, Batch 120, Loss 0.10345505 \n",
      "Epoch 16, Batch 130, Loss 0.10518509 \n",
      "Epoch 16, Batch 140, Loss 0.07809937 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.13892777934670447\n",
      "Validation loss :  0.10434479974210262\n",
      "Validation loss :  0.11890049539506435\n",
      "---------\n",
      "Correct :  21322\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.951875\n",
      "---------\n",
      "Epoch time :  69.319874\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.4012666865176535e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.08379556 \n",
      "Epoch 17, Batch 20, Loss 0.10331120 \n",
      "Epoch 17, Batch 30, Loss 0.09465747 \n",
      "Epoch 17, Batch 40, Loss 0.07596329 \n",
      "Epoch 17, Batch 50, Loss 0.10893948 \n",
      "Epoch 17, Batch 60, Loss 0.11658686 \n",
      "Epoch 17, Batch 70, Loss 0.10918789 \n",
      "Epoch 17, Batch 80, Loss 0.11001467 \n",
      "Epoch 17, Batch 90, Loss 0.09243375 \n",
      "Epoch 17, Batch 100, Loss 0.06354717 \n",
      "Epoch 17, Batch 110, Loss 0.08412162 \n",
      "Epoch 17, Batch 120, Loss 0.07455701 \n",
      "Epoch 17, Batch 130, Loss 0.08316201 \n",
      "Epoch 17, Batch 140, Loss 0.08639028 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.08454517833888531\n",
      "Validation loss :  0.10844891257584095\n",
      "Validation loss :  0.2339310166426003\n",
      "---------\n",
      "Correct :  21504\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.96\n",
      "---------\n",
      "Epoch time :  68.771612\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [4.181203352191771e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.06255722 \n",
      "Epoch 18, Batch 20, Loss 0.07658269 \n",
      "Epoch 18, Batch 30, Loss 0.05269152 \n",
      "Epoch 18, Batch 40, Loss 0.10933572 \n",
      "Epoch 18, Batch 50, Loss 0.13090833 \n",
      "Epoch 18, Batch 60, Loss 0.08156487 \n",
      "Epoch 18, Batch 70, Loss 0.11696492 \n",
      "Epoch 18, Batch 80, Loss 0.09068102 \n",
      "Epoch 18, Batch 90, Loss 0.07359599 \n",
      "Epoch 18, Batch 100, Loss 0.05641100 \n",
      "Epoch 18, Batch 110, Loss 0.09512055 \n",
      "Epoch 18, Batch 120, Loss 0.05662998 \n",
      "Epoch 18, Batch 130, Loss 0.09298142 \n",
      "Epoch 18, Batch 140, Loss 0.07647320 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.10975818708539009\n",
      "Validation loss :  0.13446367327123881\n",
      "Validation loss :  0.16480637900531292\n",
      "---------\n",
      "Correct :  21140\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.94375\n",
      "---------\n",
      "Epoch time :  70.106548\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.972143184582182e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.07264075 \n",
      "Epoch 19, Batch 20, Loss 0.09598789 \n",
      "Epoch 19, Batch 30, Loss 0.06916572 \n",
      "Epoch 19, Batch 40, Loss 0.08840066 \n",
      "Epoch 19, Batch 50, Loss 0.07205706 \n",
      "Epoch 19, Batch 60, Loss 0.06988703 \n",
      "Epoch 19, Batch 70, Loss 0.08214345 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Batch 80, Loss 0.08495234 \n",
      "Epoch 19, Batch 90, Loss 0.10966144 \n",
      "Epoch 19, Batch 100, Loss 0.07426575 \n",
      "Epoch 19, Batch 110, Loss 0.07470972 \n",
      "Epoch 19, Batch 120, Loss 0.07916802 \n",
      "Epoch 19, Batch 130, Loss 0.10489446 \n",
      "Epoch 19, Batch 140, Loss 0.09386643 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.12362121418118477\n",
      "Validation loss :  0.09327737400308252\n",
      "Validation loss :  0.15032500429078938\n",
      "---------\n",
      "Correct :  21288\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9503571428571429\n",
      "---------\n",
      "Epoch time :  69.353435\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.7735360253530726e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.08731053 \n",
      "Epoch 20, Batch 20, Loss 0.05292558 \n",
      "Epoch 20, Batch 30, Loss 0.09764514 \n",
      "Epoch 20, Batch 40, Loss 0.06224435 \n",
      "Epoch 20, Batch 50, Loss 0.04851022 \n",
      "Epoch 20, Batch 60, Loss 0.06751641 \n",
      "Epoch 20, Batch 70, Loss 0.09910491 \n",
      "Epoch 20, Batch 80, Loss 0.06346695 \n",
      "Epoch 20, Batch 90, Loss 0.11909744 \n",
      "Epoch 20, Batch 100, Loss 0.08281044 \n",
      "Epoch 20, Batch 110, Loss 0.09475934 \n",
      "Epoch 20, Batch 120, Loss 0.08495416 \n",
      "Epoch 20, Batch 130, Loss 0.13635823 \n",
      "Epoch 20, Batch 140, Loss 0.10207915 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.19436229318380355\n",
      "Validation loss :  0.1275600578635931\n",
      "Validation loss :  0.11155607346445322\n",
      "---------\n",
      "Correct :  21097\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9418303571428571\n",
      "---------\n",
      "Epoch time :  70.210204\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.584859224085419e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.09386531 \n",
      "Epoch 21, Batch 20, Loss 0.07344429 \n",
      "Epoch 21, Batch 30, Loss 0.07426620 \n",
      "Epoch 21, Batch 40, Loss 0.07053876 \n",
      "Epoch 21, Batch 50, Loss 0.06692874 \n",
      "Epoch 21, Batch 60, Loss 0.05088629 \n",
      "Epoch 21, Batch 70, Loss 0.08193145 \n",
      "Epoch 21, Batch 80, Loss 0.05482741 \n",
      "Epoch 21, Batch 90, Loss 0.08313477 \n",
      "Epoch 21, Batch 100, Loss 0.05785424 \n",
      "Epoch 21, Batch 110, Loss 0.06285535 \n",
      "Epoch 21, Batch 120, Loss 0.06791914 \n",
      "Epoch 21, Batch 130, Loss 0.12489887 \n",
      "Epoch 21, Batch 140, Loss 0.08908319 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11716025657951831\n",
      "Validation loss :  0.1208376320078969\n",
      "Validation loss :  0.10705255325883627\n",
      "---------\n",
      "Correct :  21255\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9488839285714286\n",
      "---------\n",
      "Epoch time :  69.538927\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.405616262881148e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.07860090 \n",
      "Epoch 22, Batch 20, Loss 0.05502442 \n",
      "Epoch 22, Batch 30, Loss 0.08123872 \n",
      "Epoch 22, Batch 40, Loss 0.05360327 \n",
      "Epoch 22, Batch 50, Loss 0.07927700 \n",
      "Epoch 22, Batch 60, Loss 0.06814815 \n",
      "Epoch 22, Batch 70, Loss 0.07764196 \n",
      "Epoch 22, Batch 80, Loss 0.06994277 \n",
      "Epoch 22, Batch 90, Loss 0.10404942 \n",
      "Epoch 22, Batch 100, Loss 0.08463635 \n",
      "Epoch 22, Batch 110, Loss 0.05952938 \n",
      "Epoch 22, Batch 120, Loss 0.06246377 \n",
      "Epoch 22, Batch 130, Loss 0.05880160 \n",
      "Epoch 22, Batch 140, Loss 0.04261310 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11764013934880495\n",
      "Validation loss :  0.09290973842144012\n",
      "Validation loss :  0.16767266280949117\n",
      "---------\n",
      "Correct :  21478\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9588392857142857\n",
      "---------\n",
      "Epoch time :  69.462029\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.2353354497370904e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.06308376 \n",
      "Epoch 23, Batch 20, Loss 0.04809740 \n",
      "Epoch 23, Batch 30, Loss 0.06017331 \n",
      "Epoch 23, Batch 40, Loss 0.05455291 \n",
      "Epoch 23, Batch 50, Loss 0.04876740 \n",
      "Epoch 23, Batch 60, Loss 0.05321424 \n",
      "Epoch 23, Batch 70, Loss 0.09310747 \n",
      "Epoch 23, Batch 80, Loss 0.08786355 \n",
      "Epoch 23, Batch 90, Loss 0.07835605 \n",
      "Epoch 23, Batch 100, Loss 0.07303453 \n",
      "Epoch 23, Batch 110, Loss 0.06953090 \n",
      "Epoch 23, Batch 120, Loss 0.06807205 \n",
      "Epoch 23, Batch 130, Loss 0.04870029 \n",
      "Epoch 23, Batch 140, Loss 0.04540980 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.09529010150581599\n",
      "Validation loss :  0.12612771349959076\n",
      "Validation loss :  0.08295702636241913\n",
      "---------\n",
      "Correct :  21592\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9639285714285715\n",
      "---------\n",
      "Epoch time :  69.477806\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [3.0735686772502355e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.05312743 \n",
      "Epoch 24, Batch 20, Loss 0.04700784 \n",
      "Epoch 24, Batch 30, Loss 0.10049618 \n",
      "Epoch 24, Batch 40, Loss 0.04993154 \n",
      "Epoch 24, Batch 50, Loss 0.05902724 \n",
      "Epoch 24, Batch 60, Loss 0.04852424 \n",
      "Epoch 24, Batch 70, Loss 0.07119598 \n",
      "Epoch 24, Batch 80, Loss 0.07489146 \n",
      "Epoch 24, Batch 90, Loss 0.05891296 \n",
      "Epoch 24, Batch 100, Loss 0.06072001 \n",
      "Epoch 24, Batch 110, Loss 0.05998487 \n",
      "Epoch 24, Batch 120, Loss 0.05603486 \n",
      "Epoch 24, Batch 130, Loss 0.06175268 \n",
      "Epoch 24, Batch 140, Loss 0.05469463 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.07907046768814326\n",
      "Validation loss :  0.08834244832396507\n",
      "Validation loss :  0.11032894123345613\n",
      "---------\n",
      "Correct :  21588\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.96375\n",
      "---------\n",
      "Epoch time :  69.743512\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.9198902433877236e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.09068417 \n",
      "Epoch 25, Batch 20, Loss 0.04937211 \n",
      "Epoch 25, Batch 30, Loss 0.06827251 \n",
      "Epoch 25, Batch 40, Loss 0.05194898 \n",
      "Epoch 25, Batch 50, Loss 0.05059774 \n",
      "Epoch 25, Batch 60, Loss 0.04911484 \n",
      "Epoch 25, Batch 70, Loss 0.03827837 \n",
      "Epoch 25, Batch 80, Loss 0.06460557 \n",
      "Epoch 25, Batch 90, Loss 0.05048058 \n",
      "Epoch 25, Batch 100, Loss 0.04209698 \n",
      "Epoch 25, Batch 110, Loss 0.05157120 \n",
      "Epoch 25, Batch 120, Loss 0.09041911 \n",
      "Epoch 25, Batch 130, Loss 0.05057172 \n",
      "Epoch 25, Batch 140, Loss 0.04994300 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.12234933860599995\n",
      "Validation loss :  0.08350556828081608\n",
      "Validation loss :  0.10377108119428158\n",
      "---------\n",
      "Correct :  21473\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9586160714285714\n",
      "---------\n",
      "Epoch time :  69.411227\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.7738957312183373e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.05639209 \n",
      "Epoch 26, Batch 20, Loss 0.06001835 \n",
      "Epoch 26, Batch 30, Loss 0.03414419 \n",
      "Epoch 26, Batch 40, Loss 0.05820296 \n",
      "Epoch 26, Batch 50, Loss 0.03760307 \n",
      "Epoch 26, Batch 60, Loss 0.05062857 \n",
      "Epoch 26, Batch 70, Loss 0.03275381 \n",
      "Epoch 26, Batch 80, Loss 0.06219311 \n",
      "Epoch 26, Batch 90, Loss 0.06148997 \n",
      "Epoch 26, Batch 100, Loss 0.06824390 \n",
      "Epoch 26, Batch 110, Loss 0.06344596 \n",
      "Epoch 26, Batch 120, Loss 0.05357253 \n",
      "Epoch 26, Batch 130, Loss 0.07666898 \n",
      "Epoch 26, Batch 140, Loss 0.07355201 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.17229862539097668\n",
      "Validation loss :  0.09232823457568884\n",
      "Validation loss :  0.11816894179210066\n",
      "---------\n",
      "Correct :  21494\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9595535714285715\n",
      "---------\n",
      "Epoch time :  69.506107\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.6352009446574204e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.05789357 \n",
      "Epoch 27, Batch 20, Loss 0.05776119 \n",
      "Epoch 27, Batch 30, Loss 0.06319852 \n",
      "Epoch 27, Batch 40, Loss 0.04864416 \n",
      "Epoch 27, Batch 50, Loss 0.04906348 \n",
      "Epoch 27, Batch 60, Loss 0.04885264 \n",
      "Epoch 27, Batch 70, Loss 0.04916829 \n",
      "Epoch 27, Batch 80, Loss 0.02688877 \n",
      "Epoch 27, Batch 90, Loss 0.04271850 \n",
      "Epoch 27, Batch 100, Loss 0.05575486 \n",
      "Epoch 27, Batch 110, Loss 0.05259517 \n",
      "Epoch 27, Batch 120, Loss 0.06870675 \n",
      "Epoch 27, Batch 130, Loss 0.06165503 \n",
      "Epoch 27, Batch 140, Loss 0.03848619 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11922156848013402\n",
      "Validation loss :  0.12102980185300112\n",
      "Validation loss :  0.08510025516152382\n",
      "---------\n",
      "Correct :  21579\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9633482142857143\n",
      "---------\n",
      "Epoch time :  69.625143\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.5034408974245492e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.05825338 \n",
      "Epoch 28, Batch 20, Loss 0.04886191 \n",
      "Epoch 28, Batch 30, Loss 0.06415995 \n",
      "Epoch 28, Batch 40, Loss 0.05441269 \n",
      "Epoch 28, Batch 50, Loss 0.07794833 \n",
      "Epoch 28, Batch 60, Loss 0.09237849 \n",
      "Epoch 28, Batch 70, Loss 0.06301576 \n",
      "Epoch 28, Batch 80, Loss 0.06251943 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Batch 90, Loss 0.04561548 \n",
      "Epoch 28, Batch 100, Loss 0.05787275 \n",
      "Epoch 28, Batch 110, Loss 0.04440872 \n",
      "Epoch 28, Batch 120, Loss 0.03867029 \n",
      "Epoch 28, Batch 130, Loss 0.04987626 \n",
      "Epoch 28, Batch 140, Loss 0.06305778 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.05997323552146554\n",
      "Validation loss :  0.1583076471462846\n",
      "Validation loss :  0.09793814206495881\n",
      "---------\n",
      "Correct :  21579\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9633482142857143\n",
      "---------\n",
      "Epoch time :  69.367731\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.3782688525533216e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.07198135 \n",
      "Epoch 29, Batch 20, Loss 0.05707827 \n",
      "Epoch 29, Batch 30, Loss 0.03050915 \n",
      "Epoch 29, Batch 40, Loss 0.04888673 \n",
      "Epoch 29, Batch 50, Loss 0.03239568 \n",
      "Epoch 29, Batch 60, Loss 0.05537895 \n",
      "Epoch 29, Batch 70, Loss 0.05785966 \n",
      "Epoch 29, Batch 80, Loss 0.06802028 \n",
      "Epoch 29, Batch 90, Loss 0.06340536 \n",
      "Epoch 29, Batch 100, Loss 0.04212159 \n",
      "Epoch 29, Batch 110, Loss 0.04214389 \n",
      "Epoch 29, Batch 120, Loss 0.04389786 \n",
      "Epoch 29, Batch 130, Loss 0.07224309 \n",
      "Epoch 29, Batch 140, Loss 0.06377960 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.13601964963600038\n",
      "Validation loss :  0.10658294167369604\n",
      "Validation loss :  0.06100816000252962\n",
      "---------\n",
      "Correct :  21520\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9607142857142857\n",
      "---------\n",
      "Epoch time :  69.330023\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.2593554099256555e-05]\n",
      "------------------------\n",
      "Epoch 30, Batch 10, Loss 0.03469963 \n",
      "Epoch 30, Batch 20, Loss 0.04329479 \n",
      "Epoch 30, Batch 30, Loss 0.04710017 \n",
      "Epoch 30, Batch 40, Loss 0.02524975 \n",
      "Epoch 30, Batch 50, Loss 0.04217411 \n",
      "Epoch 30, Batch 60, Loss 0.05392602 \n",
      "Epoch 30, Batch 70, Loss 0.05069178 \n",
      "Epoch 30, Batch 80, Loss 0.05640004 \n",
      "Epoch 30, Batch 90, Loss 0.05575786 \n",
      "Epoch 30, Batch 100, Loss 0.04015091 \n",
      "Epoch 30, Batch 110, Loss 0.05341095 \n",
      "Epoch 30, Batch 120, Loss 0.04648340 \n",
      "Epoch 30, Batch 130, Loss 0.03823497 \n",
      "Epoch 30, Batch 140, Loss 0.05082126 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.1125939273275435\n",
      "Validation loss :  0.12714302798267454\n",
      "Validation loss :  0.11746096488204785\n",
      "---------\n",
      "Correct :  21459\n",
      "Total :  22400\n",
      "Final Validation accuracy :  0.9579910714285714\n",
      "---------\n",
      "Epoch time :  69.468521\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [2.1463876394293726e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  26390\n",
      "Total :  27424\n",
      "Test accuracy is  0.9622957992998833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5202   462]\n",
      " [  572 21188]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8858483633401544\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9786605080831409, 0.9737132352941177, 0.9761806035475696)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916073394400132\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9622957992998833,\n",
       " 'precision': 0.9786605080831409,\n",
       " 'recall': 0.9737132352941177,\n",
       " 'f1': 0.9761806035475696,\n",
       " 'auc': 0.9916073394400132,\n",
       " 'mcc': 0.8858483633401544}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.04034926 0.05813419 ... 1.         1.         1.        ]\n",
      "[0.         0.         0.         ... 0.94456215 0.94491525 1.        ]\n",
      "4136\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0335960250>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f118576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

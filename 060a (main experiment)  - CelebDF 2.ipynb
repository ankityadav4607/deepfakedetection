{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '060a (main experiment)  - CelebDF 2'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebDFClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, root, names, transform = None):\n",
    "        \n",
    "        print('Loading all images...')\n",
    "        self.allImages = torch.load(root)\n",
    "        print('Loading complete')\n",
    "        \n",
    "        self.allNames = torch.load(names)\n",
    "        \n",
    "        self.transform = transform             \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "#         return 500\n",
    "\n",
    "        return (len(self.allNames))\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        name = self.allNames[index]\n",
    "\n",
    "        vidTensor = self.allImages[index]    \n",
    "    \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "        \n",
    "        c = countUnderScore(name)\n",
    "        \n",
    "        if(c == 2):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0          \n",
    "        \n",
    "        return (vidTensor,  label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a8acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation_types = ['real-deepfake' , 'real-f2f', 'real-faceshifter', 'real-faceswap', 'real-neuraltextures']\n",
    "\n",
    "# manipulation = manipulation_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d14981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alldatapath = '/home/biometricgpu09/datasets/FF++/allData.pt'\n",
    "\n",
    "# allimagespath = '/home/biometricgpu09/datasets/FF++/allImages.pt'\n",
    "\n",
    "# allindexpath = '/home/biometricgpu09/datasets/FF++/allIndexes.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5220ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = '/home/biometricgpu09/datasets/celebDFv2/allImages.pt'\n",
    "\n",
    "allNamesPath = '/home/biometricgpu09/datasets/celebDFv2/celebDFAllNames.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 5000\n",
    "num_samples_validation = 826\n",
    "num_samples_test = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all images...\n",
      "Loading complete\n"
     ]
    }
   ],
   "source": [
    "dataset = CelebDFClassification(rootPath, allNamesPath, transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6526\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n",
      "35\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.66848609 \n",
      "Epoch 1, Batch 20, Loss 0.64400987 \n",
      "Epoch 1, Batch 30, Loss 0.61697591 \n",
      "Epoch 1, Batch 40, Loss 0.58297018 \n",
      "Epoch 1, Batch 50, Loss 0.57164938 \n",
      "Epoch 1, Batch 60, Loss 0.53946023 \n",
      "Epoch 1, Batch 70, Loss 0.52746271 \n",
      "Epoch 1, Batch 80, Loss 0.47327343 \n",
      "Epoch 1, Batch 90, Loss 0.45204760 \n",
      "Epoch 1, Batch 100, Loss 0.43679545 \n",
      "Epoch 1, Batch 110, Loss 0.40519088 \n",
      "Epoch 1, Batch 120, Loss 0.37284563 \n",
      "Epoch 1, Batch 130, Loss 0.41114185 \n",
      "Epoch 1, Batch 140, Loss 0.44756781 \n",
      "Epoch 1, Batch 150, Loss 0.40642799 \n",
      "Epoch 1, Batch 160, Loss 0.41521251 \n",
      "Epoch 1, Batch 170, Loss 0.38694618 \n",
      "Epoch 1, Batch 180, Loss 0.33519273 \n",
      "Epoch 1, Batch 190, Loss 0.32523353 \n",
      "Epoch 1, Batch 200, Loss 0.31151534 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.3771909102797508\n",
      "Validation loss :  0.35906710028648375\n",
      "Validation loss :  0.34945948570966723\n",
      "---------\n",
      "Correct :  22784\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.8619854721549637\n",
      "---------\n",
      "Epoch time :  112.379064\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.900000000000001e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.42992232 \n",
      "Epoch 2, Batch 20, Loss 0.33380944 \n",
      "Epoch 2, Batch 30, Loss 0.35949655 \n",
      "Epoch 2, Batch 40, Loss 0.37892254 \n",
      "Epoch 2, Batch 50, Loss 0.32578447 \n",
      "Epoch 2, Batch 60, Loss 0.36619776 \n",
      "Epoch 2, Batch 70, Loss 0.40019774 \n",
      "Epoch 2, Batch 80, Loss 0.30067892 \n",
      "Epoch 2, Batch 90, Loss 0.35158325 \n",
      "Epoch 2, Batch 100, Loss 0.32084408 \n",
      "Epoch 2, Batch 110, Loss 0.30018649 \n",
      "Epoch 2, Batch 120, Loss 0.24159873 \n",
      "Epoch 2, Batch 130, Loss 0.34457860 \n",
      "Epoch 2, Batch 140, Loss 0.25685466 \n",
      "Epoch 2, Batch 150, Loss 0.28418529 \n",
      "Epoch 2, Batch 160, Loss 0.24512362 \n",
      "Epoch 2, Batch 170, Loss 0.21303749 \n",
      "Epoch 2, Batch 180, Loss 0.25146052 \n",
      "Epoch 2, Batch 190, Loss 0.36880362 \n",
      "Epoch 2, Batch 200, Loss 0.26129483 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.41664978489279747\n",
      "Validation loss :  0.3183628128841519\n",
      "Validation loss :  0.3161484718322754\n",
      "---------\n",
      "Correct :  22784\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.8619854721549637\n",
      "---------\n",
      "Epoch time :  104.817391\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.801e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.32089866 \n",
      "Epoch 3, Batch 20, Loss 0.30018772 \n",
      "Epoch 3, Batch 30, Loss 0.30095057 \n",
      "Epoch 3, Batch 40, Loss 0.35024499 \n",
      "Epoch 3, Batch 50, Loss 0.26739141 \n",
      "Epoch 3, Batch 60, Loss 0.24733597 \n",
      "Epoch 3, Batch 70, Loss 0.27658841 \n",
      "Epoch 3, Batch 80, Loss 0.30224247 \n",
      "Epoch 3, Batch 90, Loss 0.26884322 \n",
      "Epoch 3, Batch 100, Loss 0.28148776 \n",
      "Epoch 3, Batch 110, Loss 0.23839211 \n",
      "Epoch 3, Batch 120, Loss 0.27523476 \n",
      "Epoch 3, Batch 130, Loss 0.28918390 \n",
      "Epoch 3, Batch 140, Loss 0.25497896 \n",
      "Epoch 3, Batch 150, Loss 0.27672387 \n",
      "Epoch 3, Batch 160, Loss 0.23551411 \n",
      "Epoch 3, Batch 170, Loss 0.20910122 \n",
      "Epoch 3, Batch 180, Loss 0.24856512 \n",
      "Epoch 3, Batch 190, Loss 0.22381210 \n",
      "Epoch 3, Batch 200, Loss 0.23254389 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.20524988397955896\n",
      "Validation loss :  0.358550089597702\n",
      "Validation loss :  0.2180356837809086\n",
      "---------\n",
      "Correct :  23858\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9026180387409201\n",
      "---------\n",
      "Epoch time :  103.314887\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.70299e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.19157770 \n",
      "Epoch 4, Batch 20, Loss 0.24595247 \n",
      "Epoch 4, Batch 30, Loss 0.25203417 \n",
      "Epoch 4, Batch 40, Loss 0.23597160 \n",
      "Epoch 4, Batch 50, Loss 0.25281961 \n",
      "Epoch 4, Batch 60, Loss 0.26036991 \n",
      "Epoch 4, Batch 70, Loss 0.23811130 \n",
      "Epoch 4, Batch 80, Loss 0.22530695 \n",
      "Epoch 4, Batch 90, Loss 0.22361804 \n",
      "Epoch 4, Batch 100, Loss 0.22011491 \n",
      "Epoch 4, Batch 110, Loss 0.21283433 \n",
      "Epoch 4, Batch 120, Loss 0.19200937 \n",
      "Epoch 4, Batch 130, Loss 0.20064136 \n",
      "Epoch 4, Batch 140, Loss 0.20123867 \n",
      "Epoch 4, Batch 150, Loss 0.23884339 \n",
      "Epoch 4, Batch 160, Loss 0.21947080 \n",
      "Epoch 4, Batch 170, Loss 0.21475222 \n",
      "Epoch 4, Batch 180, Loss 0.19809552 \n",
      "Epoch 4, Batch 190, Loss 0.21334830 \n",
      "Epoch 4, Batch 200, Loss 0.20097702 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.23747702687978745\n",
      "Validation loss :  0.28157691061496737\n",
      "Validation loss :  0.28764469623565675\n",
      "---------\n",
      "Correct :  23801\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9004615617433414\n",
      "---------\n",
      "Epoch time :  105.377972\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.605960100000001e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.16016509 \n",
      "Epoch 5, Batch 20, Loss 0.22193025 \n",
      "Epoch 5, Batch 30, Loss 0.16998270 \n",
      "Epoch 5, Batch 40, Loss 0.17485692 \n",
      "Epoch 5, Batch 50, Loss 0.20828481 \n",
      "Epoch 5, Batch 60, Loss 0.16344989 \n",
      "Epoch 5, Batch 70, Loss 0.15187881 \n",
      "Epoch 5, Batch 80, Loss 0.21684541 \n",
      "Epoch 5, Batch 90, Loss 0.14610634 \n",
      "Epoch 5, Batch 100, Loss 0.21766857 \n",
      "Epoch 5, Batch 110, Loss 0.26633762 \n",
      "Epoch 5, Batch 120, Loss 0.15678060 \n",
      "Epoch 5, Batch 130, Loss 0.18845662 \n",
      "Epoch 5, Batch 140, Loss 0.21604184 \n",
      "Epoch 5, Batch 150, Loss 0.23977219 \n",
      "Epoch 5, Batch 160, Loss 0.20129835 \n",
      "Epoch 5, Batch 170, Loss 0.20227424 \n",
      "Epoch 5, Batch 180, Loss 0.16868454 \n",
      "Epoch 5, Batch 190, Loss 0.16250448 \n",
      "Epoch 5, Batch 200, Loss 0.20408372 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.3741611629724503\n",
      "Validation loss :  0.3404988139867783\n",
      "Validation loss :  0.34371536821126936\n",
      "---------\n",
      "Correct :  21943\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.8301679782082324\n",
      "---------\n",
      "Epoch time :  104.857608\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.509900499000001e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.21575830 \n",
      "Epoch 6, Batch 20, Loss 0.17905875 \n",
      "Epoch 6, Batch 30, Loss 0.14798676 \n",
      "Epoch 6, Batch 40, Loss 0.14127828 \n",
      "Epoch 6, Batch 50, Loss 0.15130991 \n",
      "Epoch 6, Batch 60, Loss 0.15434936 \n",
      "Epoch 6, Batch 70, Loss 0.19281094 \n",
      "Epoch 6, Batch 80, Loss 0.18449022 \n",
      "Epoch 6, Batch 90, Loss 0.19287809 \n",
      "Epoch 6, Batch 100, Loss 0.17701052 \n",
      "Epoch 6, Batch 110, Loss 0.19050730 \n",
      "Epoch 6, Batch 120, Loss 0.15720298 \n",
      "Epoch 6, Batch 130, Loss 0.19734252 \n",
      "Epoch 6, Batch 140, Loss 0.11956882 \n",
      "Epoch 6, Batch 150, Loss 0.13825961 \n",
      "Epoch 6, Batch 160, Loss 0.12506605 \n",
      "Epoch 6, Batch 170, Loss 0.16059813 \n",
      "Epoch 6, Batch 180, Loss 0.15839156 \n",
      "Epoch 6, Batch 190, Loss 0.16711551 \n",
      "Epoch 6, Batch 200, Loss 0.16974941 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.2418007433414459\n",
      "Validation loss :  0.20995887964963914\n",
      "Validation loss :  0.22347401678562165\n",
      "---------\n",
      "Correct :  23838\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9018613801452785\n",
      "---------\n",
      "Epoch time :  103.145316\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.414801494010001e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.15311336 \n",
      "Epoch 7, Batch 20, Loss 0.16266673 \n",
      "Epoch 7, Batch 30, Loss 0.15421377 \n",
      "Epoch 7, Batch 40, Loss 0.14868241 \n",
      "Epoch 7, Batch 50, Loss 0.14666674 \n",
      "Epoch 7, Batch 60, Loss 0.15391596 \n",
      "Epoch 7, Batch 70, Loss 0.16824304 \n",
      "Epoch 7, Batch 80, Loss 0.14064286 \n",
      "Epoch 7, Batch 90, Loss 0.14048797 \n",
      "Epoch 7, Batch 100, Loss 0.15641335 \n",
      "Epoch 7, Batch 110, Loss 0.26297075 \n",
      "Epoch 7, Batch 120, Loss 0.15434319 \n",
      "Epoch 7, Batch 130, Loss 0.12785850 \n",
      "Epoch 7, Batch 140, Loss 0.16678185 \n",
      "Epoch 7, Batch 150, Loss 0.16445451 \n",
      "Epoch 7, Batch 160, Loss 0.11200672 \n",
      "Epoch 7, Batch 170, Loss 0.10280220 \n",
      "Epoch 7, Batch 180, Loss 0.13489134 \n",
      "Epoch 7, Batch 190, Loss 0.16338031 \n",
      "Epoch 7, Batch 200, Loss 0.13283535 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.24825893789529802\n",
      "Validation loss :  0.20789239071309568\n",
      "Validation loss :  0.224911680072546\n",
      "---------\n",
      "Correct :  24497\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9267932808716707\n",
      "---------\n",
      "Epoch time :  104.448731\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.320653479069902e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.09818972 \n",
      "Epoch 8, Batch 20, Loss 0.11889087 \n",
      "Epoch 8, Batch 30, Loss 0.07340417 \n",
      "Epoch 8, Batch 40, Loss 0.13992942 \n",
      "Epoch 8, Batch 50, Loss 0.13233582 \n",
      "Epoch 8, Batch 60, Loss 0.11771495 \n",
      "Epoch 8, Batch 70, Loss 0.15449043 \n",
      "Epoch 8, Batch 80, Loss 0.16965728 \n",
      "Epoch 8, Batch 90, Loss 0.13803156 \n",
      "Epoch 8, Batch 100, Loss 0.18363932 \n",
      "Epoch 8, Batch 110, Loss 0.11829278 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 120, Loss 0.11881653 \n",
      "Epoch 8, Batch 130, Loss 0.17711362 \n",
      "Epoch 8, Batch 140, Loss 0.16922651 \n",
      "Epoch 8, Batch 150, Loss 0.12478809 \n",
      "Epoch 8, Batch 160, Loss 0.10187004 \n",
      "Epoch 8, Batch 170, Loss 0.11330631 \n",
      "Epoch 8, Batch 180, Loss 0.11356213 \n",
      "Epoch 8, Batch 190, Loss 0.13407707 \n",
      "Epoch 8, Batch 200, Loss 0.09337017 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.14567211787216366\n",
      "Validation loss :  0.16470463555306197\n",
      "Validation loss :  0.2010214166715741\n",
      "---------\n",
      "Correct :  24913\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.942531779661017\n",
      "---------\n",
      "Epoch time :  103.816086\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.227446944279203e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.07833322 \n",
      "Epoch 9, Batch 20, Loss 0.12283306 \n",
      "Epoch 9, Batch 30, Loss 0.18418272 \n",
      "Epoch 9, Batch 40, Loss 0.12871261 \n",
      "Epoch 9, Batch 50, Loss 0.09886198 \n",
      "Epoch 9, Batch 60, Loss 0.14121117 \n",
      "Epoch 9, Batch 70, Loss 0.12605214 \n",
      "Epoch 9, Batch 80, Loss 0.12429344 \n",
      "Epoch 9, Batch 90, Loss 0.09524433 \n",
      "Epoch 9, Batch 100, Loss 0.11810384 \n",
      "Epoch 9, Batch 110, Loss 0.14869357 \n",
      "Epoch 9, Batch 120, Loss 0.14120761 \n",
      "Epoch 9, Batch 130, Loss 0.09673621 \n",
      "Epoch 9, Batch 140, Loss 0.11355168 \n",
      "Epoch 9, Batch 150, Loss 0.10130394 \n",
      "Epoch 9, Batch 160, Loss 0.13844134 \n",
      "Epoch 9, Batch 170, Loss 0.10552683 \n",
      "Epoch 9, Batch 180, Loss 0.10981252 \n",
      "Epoch 9, Batch 190, Loss 0.10641141 \n",
      "Epoch 9, Batch 200, Loss 0.10675672 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.8047719210386276\n",
      "Validation loss :  0.769135594367981\n",
      "Validation loss :  0.8941092014312744\n",
      "---------\n",
      "Correct :  16619\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.6287454600484261\n",
      "---------\n",
      "Epoch time :  103.719407\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.13517247483641e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.10440858 \n",
      "Epoch 10, Batch 20, Loss 0.12901500 \n",
      "Epoch 10, Batch 30, Loss 0.11163860 \n",
      "Epoch 10, Batch 40, Loss 0.11367704 \n",
      "Epoch 10, Batch 50, Loss 0.10562440 \n",
      "Epoch 10, Batch 60, Loss 0.14087344 \n",
      "Epoch 10, Batch 70, Loss 0.10581614 \n",
      "Epoch 10, Batch 80, Loss 0.11562987 \n",
      "Epoch 10, Batch 90, Loss 0.10154012 \n",
      "Epoch 10, Batch 100, Loss 0.11316197 \n",
      "Epoch 10, Batch 110, Loss 0.07202085 \n",
      "Epoch 10, Batch 120, Loss 0.08432666 \n",
      "Epoch 10, Batch 130, Loss 0.06976468 \n",
      "Epoch 10, Batch 140, Loss 0.08234717 \n",
      "Epoch 10, Batch 150, Loss 0.14892203 \n",
      "Epoch 10, Batch 160, Loss 0.10311959 \n",
      "Epoch 10, Batch 170, Loss 0.07891786 \n",
      "Epoch 10, Batch 180, Loss 0.14147109 \n",
      "Epoch 10, Batch 190, Loss 0.15621602 \n",
      "Epoch 10, Batch 200, Loss 0.12215880 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.296461845934391\n",
      "Validation loss :  0.32089473456144335\n",
      "Validation loss :  0.28678818196058276\n",
      "---------\n",
      "Correct :  22867\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.8651256053268765\n",
      "---------\n",
      "Epoch time :  104.012076\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.043820750088047e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.12360333 \n",
      "Epoch 11, Batch 20, Loss 0.12387409 \n",
      "Epoch 11, Batch 30, Loss 0.08895132 \n",
      "Epoch 11, Batch 40, Loss 0.12235681 \n",
      "Epoch 11, Batch 50, Loss 0.06194603 \n",
      "Epoch 11, Batch 60, Loss 0.08314448 \n",
      "Epoch 11, Batch 70, Loss 0.10907340 \n",
      "Epoch 11, Batch 80, Loss 0.14537837 \n",
      "Epoch 11, Batch 90, Loss 0.14941827 \n",
      "Epoch 11, Batch 100, Loss 0.11493352 \n",
      "Epoch 11, Batch 110, Loss 0.11148520 \n",
      "Epoch 11, Batch 120, Loss 0.10621994 \n",
      "Epoch 11, Batch 130, Loss 0.05530265 \n",
      "Epoch 11, Batch 140, Loss 0.11000317 \n",
      "Epoch 11, Batch 150, Loss 0.08437148 \n",
      "Epoch 11, Batch 160, Loss 0.10227820 \n",
      "Epoch 11, Batch 170, Loss 0.06210688 \n",
      "Epoch 11, Batch 180, Loss 0.10282744 \n",
      "Epoch 11, Batch 190, Loss 0.09345591 \n",
      "Epoch 11, Batch 200, Loss 0.10292527 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.1597414530813694\n",
      "Validation loss :  0.15206024162471293\n",
      "Validation loss :  0.16597750782966614\n",
      "---------\n",
      "Correct :  24832\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9394673123486683\n",
      "---------\n",
      "Epoch time :  106.207574\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.953382542587167e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.11983985 \n",
      "Epoch 12, Batch 20, Loss 0.09104461 \n",
      "Epoch 12, Batch 30, Loss 0.13272789 \n",
      "Epoch 12, Batch 40, Loss 0.08676418 \n",
      "Epoch 12, Batch 50, Loss 0.10056100 \n",
      "Epoch 12, Batch 60, Loss 0.07720728 \n",
      "Epoch 12, Batch 70, Loss 0.11642016 \n",
      "Epoch 12, Batch 80, Loss 0.07043765 \n",
      "Epoch 12, Batch 90, Loss 0.08144104 \n",
      "Epoch 12, Batch 100, Loss 0.08708186 \n",
      "Epoch 12, Batch 110, Loss 0.08827595 \n",
      "Epoch 12, Batch 120, Loss 0.05533967 \n",
      "Epoch 12, Batch 130, Loss 0.09527792 \n",
      "Epoch 12, Batch 140, Loss 0.07147734 \n",
      "Epoch 12, Batch 150, Loss 0.08294908 \n",
      "Epoch 12, Batch 160, Loss 0.09961649 \n",
      "Epoch 12, Batch 170, Loss 0.09540936 \n",
      "Epoch 12, Batch 180, Loss 0.10956797 \n",
      "Epoch 12, Batch 190, Loss 0.09061137 \n",
      "Epoch 12, Batch 200, Loss 0.09351412 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.3023687206208706\n",
      "Validation loss :  0.15983034493401646\n",
      "Validation loss :  0.19522057976573706\n",
      "---------\n",
      "Correct :  24787\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9377648305084746\n",
      "---------\n",
      "Epoch time :  103.416623\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.863848717161295e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.11572730 \n",
      "Epoch 13, Batch 20, Loss 0.06983641 \n",
      "Epoch 13, Batch 30, Loss 0.07228587 \n",
      "Epoch 13, Batch 40, Loss 0.07256016 \n",
      "Epoch 13, Batch 50, Loss 0.08518919 \n",
      "Epoch 13, Batch 60, Loss 0.10238615 \n",
      "Epoch 13, Batch 70, Loss 0.06843398 \n",
      "Epoch 13, Batch 80, Loss 0.07450103 \n",
      "Epoch 13, Batch 90, Loss 0.07091499 \n",
      "Epoch 13, Batch 100, Loss 0.06367596 \n",
      "Epoch 13, Batch 110, Loss 0.11494502 \n",
      "Epoch 13, Batch 120, Loss 0.06878624 \n",
      "Epoch 13, Batch 130, Loss 0.09028141 \n",
      "Epoch 13, Batch 140, Loss 0.05644822 \n",
      "Epoch 13, Batch 150, Loss 0.13148464 \n",
      "Epoch 13, Batch 160, Loss 0.08008185 \n",
      "Epoch 13, Batch 170, Loss 0.07639451 \n",
      "Epoch 13, Batch 180, Loss 0.12644906 \n",
      "Epoch 13, Batch 190, Loss 0.09782636 \n",
      "Epoch 13, Batch 200, Loss 0.08759739 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.1192323226481676\n",
      "Validation loss :  0.13013516776263714\n",
      "Validation loss :  0.11119590438902378\n",
      "---------\n",
      "Correct :  25271\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9560759685230025\n",
      "---------\n",
      "Epoch time :  105.978708\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.775210229989682e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.08774854 \n",
      "Epoch 14, Batch 20, Loss 0.09346051 \n",
      "Epoch 14, Batch 30, Loss 0.08056003 \n",
      "Epoch 14, Batch 40, Loss 0.09119012 \n",
      "Epoch 14, Batch 50, Loss 0.09992556 \n",
      "Epoch 14, Batch 60, Loss 0.07219810 \n",
      "Epoch 14, Batch 70, Loss 0.05605179 \n",
      "Epoch 14, Batch 80, Loss 0.04587847 \n",
      "Epoch 14, Batch 90, Loss 0.04575104 \n",
      "Epoch 14, Batch 100, Loss 0.07137172 \n",
      "Epoch 14, Batch 110, Loss 0.07733954 \n",
      "Epoch 14, Batch 120, Loss 0.07944312 \n",
      "Epoch 14, Batch 130, Loss 0.07879657 \n",
      "Epoch 14, Batch 140, Loss 0.08400802 \n",
      "Epoch 14, Batch 150, Loss 0.05947393 \n",
      "Epoch 14, Batch 160, Loss 0.06602957 \n",
      "Epoch 14, Batch 170, Loss 0.06242464 \n",
      "Epoch 14, Batch 180, Loss 0.15410787 \n",
      "Epoch 14, Batch 190, Loss 0.07406828 \n",
      "Epoch 14, Batch 200, Loss 0.05193782 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.1658220786601305\n",
      "Validation loss :  0.1641175255179405\n",
      "Validation loss :  0.0982321172952652\n",
      "---------\n",
      "Correct :  25127\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9506280266343826\n",
      "---------\n",
      "Epoch time :  105.117522\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.687458127689785e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.11330135 \n",
      "Epoch 15, Batch 20, Loss 0.07388235 \n",
      "Epoch 15, Batch 30, Loss 0.08890568 \n",
      "Epoch 15, Batch 40, Loss 0.05932704 \n",
      "Epoch 15, Batch 50, Loss 0.06438740 \n",
      "Epoch 15, Batch 60, Loss 0.08281409 \n",
      "Epoch 15, Batch 70, Loss 0.06772038 \n",
      "Epoch 15, Batch 80, Loss 0.07245713 \n",
      "Epoch 15, Batch 90, Loss 0.07470962 \n",
      "Epoch 15, Batch 100, Loss 0.03311728 \n",
      "Epoch 15, Batch 110, Loss 0.07829035 \n",
      "Epoch 15, Batch 120, Loss 0.08423572 \n",
      "Epoch 15, Batch 130, Loss 0.08358706 \n",
      "Epoch 15, Batch 140, Loss 0.09908469 \n",
      "Epoch 15, Batch 150, Loss 0.08100606 \n",
      "Epoch 15, Batch 160, Loss 0.06741356 \n",
      "Epoch 15, Batch 170, Loss 0.06111536 \n",
      "Epoch 15, Batch 180, Loss 0.08424910 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch 190, Loss 0.08621635 \n",
      "Epoch 15, Batch 200, Loss 0.06352834 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.24784975117072464\n",
      "Validation loss :  0.19515391774475574\n",
      "Validation loss :  0.17965851020999252\n",
      "---------\n",
      "Correct :  24987\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.945331416464891\n",
      "---------\n",
      "Epoch time :  103.339816\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.600583546412887e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.04884664 \n",
      "Epoch 16, Batch 20, Loss 0.03995455 \n",
      "Epoch 16, Batch 30, Loss 0.04600311 \n",
      "Epoch 16, Batch 40, Loss 0.04915289 \n",
      "Epoch 16, Batch 50, Loss 0.06344491 \n",
      "Epoch 16, Batch 60, Loss 0.08347353 \n",
      "Epoch 16, Batch 70, Loss 0.04291214 \n",
      "Epoch 16, Batch 80, Loss 0.06795247 \n",
      "Epoch 16, Batch 90, Loss 0.06076708 \n",
      "Epoch 16, Batch 100, Loss 0.07003163 \n",
      "Epoch 16, Batch 110, Loss 0.06947809 \n",
      "Epoch 16, Batch 120, Loss 0.04548696 \n",
      "Epoch 16, Batch 130, Loss 0.04862689 \n",
      "Epoch 16, Batch 140, Loss 0.04703710 \n",
      "Epoch 16, Batch 150, Loss 0.04043837 \n",
      "Epoch 16, Batch 160, Loss 0.08834006 \n",
      "Epoch 16, Batch 170, Loss 0.07829172 \n",
      "Epoch 16, Batch 180, Loss 0.08902296 \n",
      "Epoch 16, Batch 190, Loss 0.09530728 \n",
      "Epoch 16, Batch 200, Loss 0.05541375 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.08948774598538875\n",
      "Validation loss :  0.11638973224908114\n",
      "Validation loss :  0.11198090324178338\n",
      "---------\n",
      "Correct :  25373\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9599349273607748\n",
      "---------\n",
      "Epoch time :  105.644235\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.514577710948758e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.06131263 \n",
      "Epoch 17, Batch 20, Loss 0.05282983 \n",
      "Epoch 17, Batch 30, Loss 0.09173123 \n",
      "Epoch 17, Batch 40, Loss 0.08315652 \n",
      "Epoch 17, Batch 50, Loss 0.07814718 \n",
      "Epoch 17, Batch 60, Loss 0.06973934 \n",
      "Epoch 17, Batch 70, Loss 0.06063552 \n",
      "Epoch 17, Batch 80, Loss 0.06958919 \n",
      "Epoch 17, Batch 90, Loss 0.04779977 \n",
      "Epoch 17, Batch 100, Loss 0.05703372 \n",
      "Epoch 17, Batch 110, Loss 0.08681038 \n",
      "Epoch 17, Batch 120, Loss 0.05605441 \n",
      "Epoch 17, Batch 130, Loss 0.03880455 \n",
      "Epoch 17, Batch 140, Loss 0.05711248 \n",
      "Epoch 17, Batch 150, Loss 0.05905138 \n",
      "Epoch 17, Batch 160, Loss 0.05344128 \n",
      "Epoch 17, Batch 170, Loss 0.04791335 \n",
      "Epoch 17, Batch 180, Loss 0.06735981 \n",
      "Epoch 17, Batch 190, Loss 0.09326695 \n",
      "Epoch 17, Batch 200, Loss 0.08883973 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.3103016674518585\n",
      "Validation loss :  0.37196102887392046\n",
      "Validation loss :  0.28721418008208277\n",
      "---------\n",
      "Correct :  22924\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.8672820823244553\n",
      "---------\n",
      "Epoch time :  105.138385\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.429431933839271e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.06612785 \n",
      "Epoch 18, Batch 20, Loss 0.08212975 \n",
      "Epoch 18, Batch 30, Loss 0.05669065 \n",
      "Epoch 18, Batch 40, Loss 0.10739732 \n",
      "Epoch 18, Batch 50, Loss 0.11202611 \n",
      "Epoch 18, Batch 60, Loss 0.03491221 \n",
      "Epoch 18, Batch 70, Loss 0.07508527 \n",
      "Epoch 18, Batch 80, Loss 0.04131133 \n",
      "Epoch 18, Batch 90, Loss 0.09189274 \n",
      "Epoch 18, Batch 100, Loss 0.07210948 \n",
      "Epoch 18, Batch 110, Loss 0.06260948 \n",
      "Epoch 18, Batch 120, Loss 0.08339310 \n",
      "Epoch 18, Batch 130, Loss 0.05259658 \n",
      "Epoch 18, Batch 140, Loss 0.07391503 \n",
      "Epoch 18, Batch 150, Loss 0.05341132 \n",
      "Epoch 18, Batch 160, Loss 0.03917243 \n",
      "Epoch 18, Batch 170, Loss 0.06566909 \n",
      "Epoch 18, Batch 180, Loss 0.06960321 \n",
      "Epoch 18, Batch 190, Loss 0.03890046 \n",
      "Epoch 18, Batch 200, Loss 0.04702166 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.0977591210976243\n",
      "Validation loss :  0.10105209704488516\n",
      "Validation loss :  0.08053732272237539\n",
      "---------\n",
      "Correct :  25498\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9646640435835351\n",
      "---------\n",
      "Epoch time :  104.472158\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.345137614500879e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.06480771 \n",
      "Epoch 19, Batch 20, Loss 0.07220830 \n",
      "Epoch 19, Batch 30, Loss 0.07468832 \n",
      "Epoch 19, Batch 40, Loss 0.04632392 \n",
      "Epoch 19, Batch 50, Loss 0.06053073 \n",
      "Epoch 19, Batch 60, Loss 0.08547346 \n",
      "Epoch 19, Batch 70, Loss 0.06399705 \n",
      "Epoch 19, Batch 80, Loss 0.05648210 \n",
      "Epoch 19, Batch 90, Loss 0.04497114 \n",
      "Epoch 19, Batch 100, Loss 0.06855947 \n",
      "Epoch 19, Batch 110, Loss 0.05899121 \n",
      "Epoch 19, Batch 120, Loss 0.03479783 \n",
      "Epoch 19, Batch 130, Loss 0.04375268 \n",
      "Epoch 19, Batch 140, Loss 0.05060623 \n",
      "Epoch 19, Batch 150, Loss 0.04380186 \n",
      "Epoch 19, Batch 160, Loss 0.04807657 \n",
      "Epoch 19, Batch 170, Loss 0.05094839 \n",
      "Epoch 19, Batch 180, Loss 0.04422698 \n",
      "Epoch 19, Batch 190, Loss 0.05934574 \n",
      "Epoch 19, Batch 200, Loss 0.06922150 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.10481684161350131\n",
      "Validation loss :  0.08810416013002395\n",
      "Validation loss :  0.11185332611203194\n",
      "---------\n",
      "Correct :  25346\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9589134382566586\n",
      "---------\n",
      "Epoch time :  105.484708\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.26168623835587e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.04307031 \n",
      "Epoch 20, Batch 20, Loss 0.05005574 \n",
      "Epoch 20, Batch 30, Loss 0.03325740 \n",
      "Epoch 20, Batch 40, Loss 0.04303994 \n",
      "Epoch 20, Batch 50, Loss 0.07613034 \n",
      "Epoch 20, Batch 60, Loss 0.03555563 \n",
      "Epoch 20, Batch 70, Loss 0.06249054 \n",
      "Epoch 20, Batch 80, Loss 0.02957948 \n",
      "Epoch 20, Batch 90, Loss 0.06009651 \n",
      "Epoch 20, Batch 100, Loss 0.03919569 \n",
      "Epoch 20, Batch 110, Loss 0.05861565 \n",
      "Epoch 20, Batch 120, Loss 0.04378798 \n",
      "Epoch 20, Batch 130, Loss 0.03404230 \n",
      "Epoch 20, Batch 140, Loss 0.05180398 \n",
      "Epoch 20, Batch 150, Loss 0.10347995 \n",
      "Epoch 20, Batch 160, Loss 0.05092464 \n",
      "Epoch 20, Batch 170, Loss 0.06078540 \n",
      "Epoch 20, Batch 180, Loss 0.04342062 \n",
      "Epoch 20, Batch 190, Loss 0.05586051 \n",
      "Epoch 20, Batch 200, Loss 0.04749591 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.110062275826931\n",
      "Validation loss :  0.11767110303044319\n",
      "Validation loss :  0.06235160436481237\n",
      "---------\n",
      "Correct :  25526\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9657233656174334\n",
      "---------\n",
      "Epoch time :  105.149541\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.17906937597231e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.07045231 \n",
      "Epoch 21, Batch 20, Loss 0.07517656 \n",
      "Epoch 21, Batch 30, Loss 0.03194682 \n",
      "Epoch 21, Batch 40, Loss 0.07079073 \n",
      "Epoch 21, Batch 50, Loss 0.04567018 \n",
      "Epoch 21, Batch 60, Loss 0.05086491 \n",
      "Epoch 21, Batch 70, Loss 0.05033186 \n",
      "Epoch 21, Batch 80, Loss 0.05731546 \n",
      "Epoch 21, Batch 90, Loss 0.09353945 \n",
      "Epoch 21, Batch 100, Loss 0.06483693 \n",
      "Epoch 21, Batch 110, Loss 0.05884079 \n",
      "Epoch 21, Batch 120, Loss 0.05217000 \n",
      "Epoch 21, Batch 130, Loss 0.09252340 \n",
      "Epoch 21, Batch 140, Loss 0.06505434 \n",
      "Epoch 21, Batch 150, Loss 0.05256497 \n",
      "Epoch 21, Batch 160, Loss 0.03439627 \n",
      "Epoch 21, Batch 170, Loss 0.07556647 \n",
      "Epoch 21, Batch 180, Loss 0.04775936 \n",
      "Epoch 21, Batch 190, Loss 0.05790654 \n",
      "Epoch 21, Batch 200, Loss 0.04656989 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11010080985724927\n",
      "Validation loss :  0.10736763961613179\n",
      "Validation loss :  0.10512588694691657\n",
      "---------\n",
      "Correct :  25303\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.957286622276029\n",
      "---------\n",
      "Epoch time :  103.740235\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.097278682212587e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.05154655 \n",
      "Epoch 22, Batch 20, Loss 0.03537606 \n",
      "Epoch 22, Batch 30, Loss 0.04773739 \n",
      "Epoch 22, Batch 40, Loss 0.06241248 \n",
      "Epoch 22, Batch 50, Loss 0.04142954 \n",
      "Epoch 22, Batch 60, Loss 0.06160735 \n",
      "Epoch 22, Batch 70, Loss 0.03155671 \n",
      "Epoch 22, Batch 80, Loss 0.03962656 \n",
      "Epoch 22, Batch 90, Loss 0.03058222 \n",
      "Epoch 22, Batch 100, Loss 0.04541402 \n",
      "Epoch 22, Batch 110, Loss 0.02463042 \n",
      "Epoch 22, Batch 120, Loss 0.02935885 \n",
      "Epoch 22, Batch 130, Loss 0.05891324 \n",
      "Epoch 22, Batch 140, Loss 0.03140656 \n",
      "Epoch 22, Batch 150, Loss 0.06774568 \n",
      "Epoch 22, Batch 160, Loss 0.03224712 \n",
      "Epoch 22, Batch 170, Loss 0.04052366 \n",
      "Epoch 22, Batch 180, Loss 0.03404829 \n",
      "Epoch 22, Batch 190, Loss 0.08242946 \n",
      "Epoch 22, Batch 200, Loss 0.05290329 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.08663009330630303\n",
      "Validation loss :  0.09124708231538534\n",
      "Validation loss :  0.11439526788890361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Correct :  25465\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9634155569007264\n",
      "---------\n",
      "Epoch time :  105.199482\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.016305895390461e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.07992176 \n",
      "Epoch 23, Batch 20, Loss 0.09563605 \n",
      "Epoch 23, Batch 30, Loss 0.07014580 \n",
      "Epoch 23, Batch 40, Loss 0.05040016 \n",
      "Epoch 23, Batch 50, Loss 0.05620024 \n",
      "Epoch 23, Batch 60, Loss 0.03802016 \n",
      "Epoch 23, Batch 70, Loss 0.02602759 \n",
      "Epoch 23, Batch 80, Loss 0.04901492 \n",
      "Epoch 23, Batch 90, Loss 0.07862109 \n",
      "Epoch 23, Batch 100, Loss 0.02795310 \n",
      "Epoch 23, Batch 110, Loss 0.04067275 \n",
      "Epoch 23, Batch 120, Loss 0.03895347 \n",
      "Epoch 23, Batch 130, Loss 0.04538203 \n",
      "Epoch 23, Batch 140, Loss 0.04459585 \n",
      "Epoch 23, Batch 150, Loss 0.03387546 \n",
      "Epoch 23, Batch 160, Loss 0.04218861 \n",
      "Epoch 23, Batch 170, Loss 0.07299843 \n",
      "Epoch 23, Batch 180, Loss 0.04661692 \n",
      "Epoch 23, Batch 190, Loss 0.03272053 \n",
      "Epoch 23, Batch 200, Loss 0.02860160 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.10766004155157134\n",
      "Validation loss :  0.13817370049655436\n",
      "Validation loss :  0.11875503454357386\n",
      "---------\n",
      "Correct :  25399\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.960918583535109\n",
      "---------\n",
      "Epoch time :  105.257242\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.936142836436556e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.06515401 \n",
      "Epoch 24, Batch 20, Loss 0.06807055 \n",
      "Epoch 24, Batch 30, Loss 0.05310376 \n",
      "Epoch 24, Batch 40, Loss 0.03856986 \n",
      "Epoch 24, Batch 50, Loss 0.03851124 \n",
      "Epoch 24, Batch 60, Loss 0.03316624 \n",
      "Epoch 24, Batch 70, Loss 0.03918354 \n",
      "Epoch 24, Batch 80, Loss 0.03711587 \n",
      "Epoch 24, Batch 90, Loss 0.03880074 \n",
      "Epoch 24, Batch 100, Loss 0.04883042 \n",
      "Epoch 24, Batch 110, Loss 0.06090759 \n",
      "Epoch 24, Batch 120, Loss 0.03818963 \n",
      "Epoch 24, Batch 130, Loss 0.06200397 \n",
      "Epoch 24, Batch 140, Loss 0.06880324 \n",
      "Epoch 24, Batch 150, Loss 0.06383472 \n",
      "Epoch 24, Batch 160, Loss 0.06152168 \n",
      "Epoch 24, Batch 170, Loss 0.03163348 \n",
      "Epoch 24, Batch 180, Loss 0.02952041 \n",
      "Epoch 24, Batch 190, Loss 0.02848866 \n",
      "Epoch 24, Batch 200, Loss 0.02716601 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.09716315865516663\n",
      "Validation loss :  0.09363470431417227\n",
      "Validation loss :  0.06388591453433037\n",
      "---------\n",
      "Correct :  25607\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9687878329297821\n",
      "---------\n",
      "Epoch time :  103.435518\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.856781408072191e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.03290664 \n",
      "Epoch 25, Batch 20, Loss 0.02931767 \n",
      "Epoch 25, Batch 30, Loss 0.02717577 \n",
      "Epoch 25, Batch 40, Loss 0.02302759 \n",
      "Epoch 25, Batch 50, Loss 0.07905898 \n",
      "Epoch 25, Batch 60, Loss 0.03857008 \n",
      "Epoch 25, Batch 70, Loss 0.07273663 \n",
      "Epoch 25, Batch 80, Loss 0.08020946 \n",
      "Epoch 25, Batch 90, Loss 0.03219028 \n",
      "Epoch 25, Batch 100, Loss 0.03857871 \n",
      "Epoch 25, Batch 110, Loss 0.03622706 \n",
      "Epoch 25, Batch 120, Loss 0.07561884 \n",
      "Epoch 25, Batch 130, Loss 0.06161203 \n",
      "Epoch 25, Batch 140, Loss 0.05100002 \n",
      "Epoch 25, Batch 150, Loss 0.04327409 \n",
      "Epoch 25, Batch 160, Loss 0.03703499 \n",
      "Epoch 25, Batch 170, Loss 0.03833073 \n",
      "Epoch 25, Batch 180, Loss 0.03015338 \n",
      "Epoch 25, Batch 190, Loss 0.02520330 \n",
      "Epoch 25, Batch 200, Loss 0.06474634 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.07611983260139824\n",
      "Validation loss :  0.13378603560850025\n",
      "Validation loss :  0.06139355222694576\n",
      "---------\n",
      "Correct :  25607\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9687878329297821\n",
      "---------\n",
      "Epoch time :  105.182296\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.778213593991469e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.02428173 \n",
      "Epoch 26, Batch 20, Loss 0.03057933 \n",
      "Epoch 26, Batch 30, Loss 0.02636889 \n",
      "Epoch 26, Batch 40, Loss 0.02896838 \n",
      "Epoch 26, Batch 50, Loss 0.04405583 \n",
      "Epoch 26, Batch 60, Loss 0.04307590 \n",
      "Epoch 26, Batch 70, Loss 0.04820850 \n",
      "Epoch 26, Batch 80, Loss 0.03628642 \n",
      "Epoch 26, Batch 90, Loss 0.01928046 \n",
      "Epoch 26, Batch 100, Loss 0.04131031 \n",
      "Epoch 26, Batch 110, Loss 0.03929662 \n",
      "Epoch 26, Batch 120, Loss 0.02493651 \n",
      "Epoch 26, Batch 130, Loss 0.05098387 \n",
      "Epoch 26, Batch 140, Loss 0.05994111 \n",
      "Epoch 26, Batch 150, Loss 0.04022393 \n",
      "Epoch 26, Batch 160, Loss 0.02543537 \n",
      "Epoch 26, Batch 170, Loss 0.04154061 \n",
      "Epoch 26, Batch 180, Loss 0.06021147 \n",
      "Epoch 26, Batch 190, Loss 0.05790196 \n",
      "Epoch 26, Batch 200, Loss 0.01354566 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.0740256505087018\n",
      "Validation loss :  0.1050293654203415\n",
      "Validation loss :  0.09286445872858166\n",
      "---------\n",
      "Correct :  25566\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9672366828087167\n",
      "---------\n",
      "Epoch time :  105.515408\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.700431458051554e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.04104607 \n",
      "Epoch 27, Batch 20, Loss 0.03269196 \n",
      "Epoch 27, Batch 30, Loss 0.03956337 \n",
      "Epoch 27, Batch 40, Loss 0.04682951 \n",
      "Epoch 27, Batch 50, Loss 0.04338950 \n",
      "Epoch 27, Batch 60, Loss 0.03536923 \n",
      "Epoch 27, Batch 70, Loss 0.03561656 \n",
      "Epoch 27, Batch 80, Loss 0.02670056 \n",
      "Epoch 27, Batch 90, Loss 0.02098525 \n",
      "Epoch 27, Batch 100, Loss 0.04223764 \n",
      "Epoch 27, Batch 110, Loss 0.03731651 \n",
      "Epoch 27, Batch 120, Loss 0.04969342 \n",
      "Epoch 27, Batch 130, Loss 0.02950072 \n",
      "Epoch 27, Batch 140, Loss 0.03146017 \n",
      "Epoch 27, Batch 150, Loss 0.04727216 \n",
      "Epoch 27, Batch 160, Loss 0.02375087 \n",
      "Epoch 27, Batch 170, Loss 0.02345976 \n",
      "Epoch 27, Batch 180, Loss 0.02359710 \n",
      "Epoch 27, Batch 190, Loss 0.03278972 \n",
      "Epoch 27, Batch 200, Loss 0.02725638 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.11822483967989683\n",
      "Validation loss :  0.10160509301349521\n",
      "Validation loss :  0.12907933983951808\n",
      "---------\n",
      "Correct :  25383\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9603132566585957\n",
      "---------\n",
      "Epoch time :  104.78508\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.623427143471038e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.05074196 \n",
      "Epoch 28, Batch 20, Loss 0.03053825 \n",
      "Epoch 28, Batch 30, Loss 0.02694775 \n",
      "Epoch 28, Batch 40, Loss 0.02638695 \n",
      "Epoch 28, Batch 50, Loss 0.02676202 \n",
      "Epoch 28, Batch 60, Loss 0.03537558 \n",
      "Epoch 28, Batch 70, Loss 0.02539195 \n",
      "Epoch 28, Batch 80, Loss 0.05524783 \n",
      "Epoch 28, Batch 90, Loss 0.02534936 \n",
      "Epoch 28, Batch 100, Loss 0.03539773 \n",
      "Epoch 28, Batch 110, Loss 0.04210479 \n",
      "Epoch 28, Batch 120, Loss 0.01938558 \n",
      "Epoch 28, Batch 130, Loss 0.04313950 \n",
      "Epoch 28, Batch 140, Loss 0.06723185 \n",
      "Epoch 28, Batch 150, Loss 0.01690680 \n",
      "Epoch 28, Batch 160, Loss 0.02763655 \n",
      "Epoch 28, Batch 170, Loss 0.04841906 \n",
      "Epoch 28, Batch 180, Loss 0.06480703 \n",
      "Epoch 28, Batch 190, Loss 0.02364122 \n",
      "Epoch 28, Batch 200, Loss 0.02073191 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.09905106131918728\n",
      "Validation loss :  0.1278372747823596\n",
      "Validation loss :  0.14021439007483422\n",
      "---------\n",
      "Correct :  25508\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.965042372881356\n",
      "---------\n",
      "Epoch time :  106.046695\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.547192872036328e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.03766116 \n",
      "Epoch 29, Batch 20, Loss 0.03917155 \n",
      "Epoch 29, Batch 30, Loss 0.03381364 \n",
      "Epoch 29, Batch 40, Loss 0.02287160 \n",
      "Epoch 29, Batch 50, Loss 0.02818933 \n",
      "Epoch 29, Batch 60, Loss 0.02503010 \n",
      "Epoch 29, Batch 70, Loss 0.02348286 \n",
      "Epoch 29, Batch 80, Loss 0.02592641 \n",
      "Epoch 29, Batch 90, Loss 0.03199295 \n",
      "Epoch 29, Batch 100, Loss 0.02229063 \n",
      "Epoch 29, Batch 110, Loss 0.02732322 \n",
      "Epoch 29, Batch 120, Loss 0.02675452 \n",
      "Epoch 29, Batch 130, Loss 0.02485316 \n",
      "Epoch 29, Batch 140, Loss 0.01608554 \n",
      "Epoch 29, Batch 150, Loss 0.03449936 \n",
      "Epoch 29, Batch 160, Loss 0.03981022 \n",
      "Epoch 29, Batch 170, Loss 0.03735116 \n",
      "Epoch 29, Batch 180, Loss 0.02102991 \n",
      "Epoch 29, Batch 190, Loss 0.02724624 \n",
      "Epoch 29, Batch 200, Loss 0.01650720 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.09393324684351682\n",
      "Validation loss :  0.06611122011672706\n",
      "Validation loss :  0.09029891910031437\n",
      "---------\n",
      "Correct :  25651\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9704524818401937\n",
      "---------\n",
      "Epoch time :  105.491209\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.471720943315964e-05]\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch 10, Loss 0.09195768 \n",
      "Epoch 30, Batch 20, Loss 0.04181715 \n",
      "Epoch 30, Batch 30, Loss 0.05581246 \n",
      "Epoch 30, Batch 40, Loss 0.02994771 \n",
      "Epoch 30, Batch 50, Loss 0.03100990 \n",
      "Epoch 30, Batch 60, Loss 0.03135686 \n",
      "Epoch 30, Batch 70, Loss 0.03531913 \n",
      "Epoch 30, Batch 80, Loss 0.02173730 \n",
      "Epoch 30, Batch 90, Loss 0.01977716 \n",
      "Epoch 30, Batch 100, Loss 0.02267402 \n",
      "Epoch 30, Batch 110, Loss 0.01806561 \n",
      "Epoch 30, Batch 120, Loss 0.01826800 \n",
      "Epoch 30, Batch 130, Loss 0.03359252 \n",
      "Epoch 30, Batch 140, Loss 0.02275084 \n",
      "Epoch 30, Batch 150, Loss 0.03170589 \n",
      "Epoch 30, Batch 160, Loss 0.03510435 \n",
      "Epoch 30, Batch 170, Loss 0.02518635 \n",
      "Epoch 30, Batch 180, Loss 0.02936680 \n",
      "Epoch 30, Batch 190, Loss 0.05877093 \n",
      "Epoch 30, Batch 200, Loss 0.03560229 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "Validation loss :  0.12798698879778386\n",
      "Validation loss :  0.09765693005174399\n",
      "Validation loss :  0.11299669295549393\n",
      "---------\n",
      "Correct :  25346\n",
      "Total :  26432\n",
      "Final Validation accuracy :  0.9589134382566586\n",
      "---------\n",
      "Epoch time :  103.699897\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.397003733882805e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  21830\n",
      "Total :  22400\n",
      "Test accuracy is  0.9745535714285715\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2459   517]\n",
      " [   53 19371]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiZ0lEQVR4nO3deZxVdf3H8ddbwARXcEEETTC01AwVtUxTc8fcUnEptVzIUNt+Vma5/zTL7ZdWKu4rSIqCPjBAzDVRUAkEZREhWQQFFRVEZ+bz++OcwQvOzL1zmTsz5/B++vg+5tzPWe7nOsNnvvM933OOIgIzM8uGNVo6ATMzK52LtplZhrhom5lliIu2mVmGuGibmWVI20q/wTc23d3TU+wLpi+e29IpWCv08ZKZWtVjfPbujJJrTruNeqzy+zW3ihdtM7NmVVPd0hlUlIu2meVL1LR0BhXlom1m+VLjom1mlhnhnraZWYZUV7V0BhXlom1m+eITkWZmGeLhETOzDPGJSDOz7PCJSDOzLHFP28wsQ6o/a+kMKspF28zyxcMjZmYZ4uERM7MMcU/bzCxD3NM2M8uOqPGJSDOz7Mh5T9uPGzOzfIma0lsRkm6TtEDSqwWx+yWNT9tMSePT+JaSlhasu7Fgn50lTZQ0XdJ1kpTGO0kaJWla+rVjsZxctM0sX2qqS2/F3QEcVBiIiGMjoldE9AIeBIYUrH6jdl1EnFEQvwE4HeiZttpjnguMjoiewOj0dYNctM0sX5qwpx0RTwOL6lqX9pb7AgMbOoakLsB6ETEmIgK4CzgiXX04cGe6fGdBvF4u2maWLzU1JTdJ/SSNK2j9GvFOewLzI2JaQay7pFckPSVpzzTWFZhdsM3sNAbQOSLmpctvA52LvalPRJpZvjTiIQgRMQAYUOY7Hc+Kvex5wBYRsVDSzsDDkrZrRC4hqeiT5F20zSxfmmH2iKS2wPeBnWtjEbEMWJYuvyTpDWBrYA7QrWD3bmkMYL6kLhExLx1GWVDsvT08Yma5ElFdclsF+wGvR8TyYQ9JG0tqky73IDnhOCMd/lgs6ZvpOPhJwNB0t2HAyenyyQXxerlom1m+NGJMuxhJA4HngW0kzZZ0arrqOL54AvI7wIR0CuADwBkRUXsSsz9wCzAdeAN4LI1fAewvaRrJL4IriuXk4REzy5cmvPdIRBxfT/xHdcQeJJkCWNf244Dt64gvBPZtTE4u2maWLzm/ItJF28zypRGzR7LIRdvM8sW3ZjUzyxAPj5iZZYiLtplZhnh4xMwsQ3wi0swsQzw8YmaWIR4eMTPLEPe0zcwyZHUu2pJ+1dD6iLimadMxM1tFUfSW1JlWrKe9brNkYWbWVKpW49kjEXFxcyViZtYkfCISJK0FnApsB6xVG4+IUyqUl5lZeXI+pl3qQxDuBjYFDgSeInlczoeVSsrMrGwRpbcMKrVofyUizgc+jog7gUOA3SqXlplZmZrwyTWtUalT/j5Lv74vaXuSR71vUpmUzMxWQUaLcalKLdoDJHUEzid5EOU6wAUVy8rMrExRvUoP7G31ShoeiYhbIuK9iHgqInpExCYRcWOlkzMza7SmfbDvbZIWSHq1IHaRpDmSxqetT8G630maLmmKpAML4gelsemSzi2Id5f0Qhq/X9KaxXIqdfbIl4CjgC0L94mIS0rZ38ys2TTtlL87gL8Cd60UvzYirioMSNqW5Cnt2wGbAY9L2jpd/Tdgf2A2MFbSsIiYDPwpPdYgSTeSzNK7oaGESj0RORQ4HKgCPi5oZmatS02U3oqIiKeBRSW+8+HAoIhYFhFvAtOBXdM2PSJmRMSnwCDgcEkCvgs8kO5/J3BEsTcpdUy7W0QcVOK2ZmYtp3lORJ4l6SRgHPA/EfEe0BUYU7DN7DQG8NZK8d2ADYH3I6Kqju3rVWpP+9+Svl7itmZmLae6uuQmqZ+kcQWtXwnvcAOwFdALmAdcXcmPs7JSi/YewEvpQPoESRMlTahkYlnQebNNuOXB6xny9L0MeeoeTjit7wrrTzrjeP7z9r/ZoNP6APTefUeenTqS+x+/g/sfv4Of/OrHy7c94bS+PPjkPQx56h5+cPqKx7Fsm/zas7z44j95fsxwnnl2GABHHtmHseNG8uFHM9hxp8/7Q8ceezjPjxm+vH340Qx22GHblko9mxpxIjIiBkRE74I2oNjhI2J+RFRHRA1wM8nwB8AcYPOCTbulsfriC4ENJLVdKd6gUodHDi5xu9VKdVU1V110Pa9PnEqHtTswaORtjHn6RWZMnUnnzTbhW3vtytzZb6+wzysv/IezT/z1CrGvfLUHR/3wMH5w8Kl89mkVfx94DU+Peo63Zhb9/llGHHzw8Sxc+N7y15MnT+GE48/guusvX2G7++8fyv33DwVgu+22YdD9A5gwYXKz5pp5JYxVrwpJXSJiXvrySKB2Zskw4D5J15CciOwJvAgI6CmpO0lRPg44ISJC0r+Ao0nGuU8mOX/YoAZ72pLWSxc/rKet1t5dsJDXJ04FYMnHS5gxbRabbLoxAL++5Odce+nfiBIule3e88tMfHkSnyxdRnV1NS89/wr7HrJ3JVO3FjZlyhtMmzajwW2O6XsYDzzwSDNllCNRU3orQtJA4HlgG0mzJZ0K/LlgtGEf4JcAETEJGAxMBv4JnJn2yKuAs4ARwGvA4HRbgN8Cv5I0nWSM+9ZiORXrad8HfA94CQiS3xjL/9cAPYp+6tXEZptvyle378nElyex94F7smDeO0ydPP0L2+2w8/YMHn0n78x/l2su/itvTHmT6a/P4Oxzf8L6Hddj2SfL2GPf3Zn8n9da4FNYJUQEwx65m4jg1lvv4/bbBpa031FHfY9j+55e4exyqAl72hFxfB3hegtrRFwGXFZHfDgwvI74DD4fXilJsVuzfi/92r0xB00H8/sBdF23Bxt26NyY3TOnfYf2XH3L5Vx5wV+orq7mtJ+fxBnH/uIL2702YQoH9f4+S5csZY99v8W1t1/BYbsfy5vTZnH7X+/hxkH/x9IlnzBl0lSqq/N9Ke7qZL/9jmbe3PlsvPGGPPLIPUyd8gbPPfdig/v03qUXS5csZfLkqc2UZX5Ezi9jL+lEpKSd6mhbFQygr6BwcD/vBbtt2zZcc+vlDB8yktHDn6Lbl7vSdYvNGPzEXQwf+yCdu2zMoJG3s+HGnfj4oyUsXbIUgGdHP0/bdm2Xn6R8aOCjHH/gKZxyZH8Wv/8hs2a81dDbWobMmzsfgHfeWciwR0bQu/c3iu5zzNGHMvgfwyqdWj41YvZIFpV6IvLvwE7ABJIhkq+TDL6vL+mnETGyQvm1ehddex4zps3k7psGATD99Rnss/0hy9cPH/sgJxx4Cu8v+oANN+7EwneSefrb7/g11pB4f9EHAHTaqCOL3n2PTbt2Zt8+e3PiIf6zOA86dGjPGmuswUcffUyHDu3Zd989ueKP1zW4jyS+f9Qh7L/fMc2UZc5U+ERkSyu1aM8FTq0dPE8v17wE+A0wBFgti/aOu+7AoccczNTJ07n/8TsAuP6PN/Hs6Ofr3H7/Q/eh78lHUlVVzbJPlvHbMz6/59bVt1zG+p3Wp+qzKi7/3VV8uPij5vgIVmGbbLIRgwYls8jatG3D4MFDGTXqKQ497ECuvvoiNtqoE0MevI0JE17j8MNPAmCPPXZj9ux5zJzpv7bKkvPhEZUyu0HSqxGxfV0xSeMjold9+35j093z/WvPyjJ98dyWTsFaoY+XzFTxrYoc44LjSq45a18yaJXfr7mV2tOeJOkGkrmEAMcCk9MbSX1W/25mZs3Mz4gE4EdAf+AX6evngHNICvY+TZ6VmVm5PKYNEbGU5Pr6uq6x9+CrmbUaUZXNWSGlarBoSxocEX0lTSS5mGYFEbFDxTIzMyvHat7T/nn69XuVTsTMrEmszmPaETFPUhvgjojw2LWZtX6reU+biKiWVCNp/Yj4oDmSMjMrV6zuRTv1ETBR0igKHjMWET+rSFZmZuVanU9EFvgn8DjJycgqYGnFMjIzWxWrc087vSHU5cApwCyS+45sAdwOnFfx7MzMGivnRbvYXf6uBDoB3SNi54jYieQe2uun68zMWpWIKLllUbHhke8BW0fBp4uIxZJ+CrzO51dImpm1DjnvaRcr2hF1/DpKZ5Tk+/+MmWVTzot2seGRyZJOWjko6YckPW0zs1YlqmpKbllUrKd9JjBE0ikkz4kE6A20J3kKsZlZ65LNWlyyBnvaETEnInYjeeDBzLRdEhG7RsScyqdnZtY4URMlt2Ik3SZpgaRXC2JXSnpd0gRJD0naII1vKWmppPFpu7Fgn53TJ7hPl3SdJKXxTpJGSZqWfu1YLKeSnhEZEU9ExPVpG13KPmZmLaImSm/F3QEctFJsFLB9esO8qcDvCta9ERG90nZGQfwG4HSgZ9pqj3kuMDoiegKj09cNKqlom5llRk0jWhER8TSwaKXYyIioSl+OAbo1dAxJXYD1ImJMOrHjLuCIdPXhwJ3p8p0F8Xq5aJtZrjRmeERSP0njClq/Rr7dKcBjBa+7S3pF0lOS9kxjXYHZBdvMTmMAnSNiXrr8NtC52BuWehm7mVkmRFXpU/4iYgAwoJz3kfR7ktt63JuG5gFbRMRCSTsDD0varhG5RClTqV20zSxfmmH2iKQfkVx8uG/ttSwRsQxYli6/JOkNYGtgDisOoXRLYwDzJXVJb4PdBVhQ7L09PGJmuRI1pbdySDoI+A1wWEQsKYhvnD5/AEk9SE44zkiHPxZL+mY6a+QkYGi62zDg5HT55IJ4vdzTNrN8acKetqSBwN7ARpJmAxeSzBb5EjAqnbk3Jp0p8h3gEkmfpVmcERG1JzH7k8xEaU8yBl47Dn4FMFjSqSQ35etbLCcXbTPLlaZ82lhEHF9H+NZ6tn0QeLCedeOA7euILwT2bUxOLtpmlivLJ+PllIu2meVKzp/r66JtZvniom1mliWhls6goly0zSxX3NM2M8uQqHFP28wsM2qqXbTNzDLDwyNmZhni4REzswz54qPI88VF28xyxT1tM7MM8YlIM7MMcU/bzCxDwldEmpllh6f8mZllSI172mZm2eHhETOzDPHsETOzDMn77BE/jd3McqUmVHIrRtJtkhZIerUg1knSKEnT0q8d07gkXSdpuqQJknYq2OfkdPtpkk4uiO8saWK6z3Xp09ob5KJtZrkSoZJbCe4ADlopdi4wOiJ6AqPT1wAHAz3T1g+4AZIiT/IU992AXYELawt9us3pBfut/F5f4KJtZrkSUXorfqx4Gli0Uvhw4M50+U7giIL4XZEYA2wgqQtwIDAqIhZFxHvAKOCgdN16ETEmIgK4q+BY9fKYtpnlSmOm/EnqR9IrrjUgIgYU2a1zRMxLl98GOqfLXYG3CrabncYais+uI94gF20zy5WaRpyITAt0sSLd0P4hqVnvK+jhETPLlaY8EVmP+enQBunXBWl8DrB5wXbd0lhD8W51xBtU8Z72pEWzKv0WlkFL5z7T0ilYTjXDxTXDgJOBK9KvQwviZ0kaRHLS8YOImCdpBHB5wcnHA4DfRcQiSYslfRN4ATgJuL7Ym3t4xMxypSkvY5c0ENgb2EjSbJJZIFcAgyWdCswC+qabDwf6ANOBJcCPAdLifCkwNt3ukoioPbnZn2SGSnvgsbQ1nFNU+DEPbdfsmvPnSFg53NO2urTbqMcqV9wxm32/5JrzzblDMncljnvaZpYr1TX5PlXnom1muZLzO7O6aJtZvgSZG/FoFBdtM8uVmpyfRXPRNrNcqXFP28wsOzw8YmaWIdUu2mZm2eHZI2ZmGeKibWaWIR7TNjPLkJw/ItJF28zyxVP+zMwypLqlE6gwF20zy5Wa4g80zzQXbTPLlZxfxe6ibWb54il/ZmYZ4tkjZmYZ4svYzcwyJO897Xw/l8fMVjs1jWgNkbSNpPEFbbGkX0i6SNKcgnifgn1+J2m6pCmSDiyIH5TGpks6d1U+n3vaZpYrTTV7JCKmAL0AJLUB5gAPkTxl/dqIuKpwe0nbAscB2wGbAY9L2jpd/Tdgf2A2MFbSsIiYXE5eLtpmlisVGh7ZF3gjImap/nnghwODImIZ8Kak6cCu6brpETEDQNKgdNuyiraHR8wsVxozPCKpn6RxBa1fPYc9DhhY8PosSRMk3SapYxrrCrxVsM3sNFZfvCwu2maWK9UqvUXEgIjoXdAGrHw8SWsChwH/SEM3AFuRDJ3MA65urs8GHh4xs5ypwMU1BwMvR8R8gNqvAJJuBh5NX84BNi/Yr1sao4F4o7mnbWa50lSzRwocT8HQiKQuBeuOBF5Nl4cBx0n6kqTuQE/gRWAs0FNS97TXfly6bVnc0zazXGnKe49IWptk1sdPCsJ/ltQrfauZtesiYpKkwSQnGKuAMyOiOj3OWcAIoA1wW0RMKjcnF20zy5WmnD0SER8DG64UO7GB7S8DLqsjPhwY3hQ5uWibWa74hlFmZhmS94cglHwiUlJ7SdtUMhkzs1VVo9JbFpVUtCUdCowH/pm+7iWp7LOfZmaVUoHZI61KqT3ti0gux3wfICLGA90rkpGZ2SqIRrQsKnVM+7OI+GCla+6z+pnNLMdqcl6aSi3akySdALSR1BP4GfDvyqVlZlYen4hMnE1yu8FlwH3AYuDnlUrKzKxceR/TLrWnfXxE/B74fW1A0hXAKt3M28ysqWV1VkipSi3aR0n6JCLuBZD0V6B95dIyMyuPx7QTRwHDJNUABwHvR8SplUvLzKw8+S7ZRYq2pE4FL08DHgaeAy6W1CkiFlUwNzOzRsvqWHWpivW0XyL5xaWCr4ekLYAeFc3OzKyRqnPe126waEeEL6Axs0xZ3Xvay0naHtgWWKs2FhF3VSIpM7Ny+UQkIOlCYG+Soj2c5PE7zwIu2mbWquS7ZJd+cc3RJI+Qfzsifgx8A1i/YlmZmZXJF9cklkZEjaQqSesBC1jxQZVmZq3Can0issA4SRsAN5PMKPkIeL5SSZmZlWu1HtOW9P2IGBIR/SV1jIgbJf0TWC8iJjRTjpk1feoYPvzoI6qra6iqquKb3+rDxRf9mkMPPYCamuCdBe9yymm/ZN68+S2dqq2iP1x+DU8/9yKdOm7Aw/fcCMDr02Zw6ZXXs2TpJ2zWZRP+dOFvWGfttZk4eQoX/ek6AIKg/yk/YL+9vs2bs2ZzzgV/XH7M2XPncdZpJ3LisUcy4oln+Put9zBj1lsMvPn/2P5rW7fI58yCJn6w70zgQ5L7UFVFRO/0+pX7gS1JHuzbNyLeU3Ib1L8AfYAlwI8i4uX0OCcDf0gP+78RcWfZOUXU/xElvRwRO6283Bht1+ya7197DZg+dQy7fetgFi58b3ls3XXX4cMPPwLgrDNP4Wtf25ozz1r9buGydO4zLZ1Ckxo3fiId2rfnvEuvWl60jz31Z5xz1mnssuMODHl0BHPmzufsfiex9JNPaNe2HW3btuGddxdx1Mn9eWLovbRt22b58aqrq/nuEScy8OZr2WzTzrwx87+soTW4+MrrOOfM03JbtNtt1GOV7xzyky2PKbnm3DTzHw2+X1q0e0fEuwWxPwOLIuIKSecCHSPit5L6kNxcrw+wG/CXiNgtLfLjgN4kv1NeAnaOiPcoQ7ETkapn2cpUW7AB1l67Aw390rTs6N3r66y/3rorxGa9NYfevb4OwLd22YlRTz0LQPu11lpeoJd9+inoi/+0xowbz+Zdu7DZpp0B2GrLLej+5W6V/Ai50QwnIg8HanvKdwJHFMTvisQYYANJXYADgVERsSgt1KNIbgdSlmJj2u0l7UhS3NdKl5f/hNV2/a1uEcFjwwcSEdx88z3ccuu9AFx6yW/54Q+O5oPFi9lv/2NaOEurlK26f5knnnmefb+zOyP/9Qxvz1/eWWPCpNc5//JrmTt/AX88/5wVetkAj41+ij777dXcKedCNGKARFI/oF9BaEBEDFjhcDBSUgA3pes6R8S8dP3bQOd0uSvwVsG+s9NYffGyFOtpzwOuAa5Kk7sGuDptV9W3k6R+ksZJGldT83G5uWXeXvscya67HcT3Dv0hP/3pj9hzj90AOP+CP9F9q10YOPAhzuz/4xbO0irl0vN+yaAhj9L3lLP5eMlS2rX7vI+0w3ZfZei9NzHolr9wy92DWbbs0+XrPvvsM5589gUO+O6eLZF25lUTJbeIGBARvQvagJUOt0c6LHwwcKak7xSujORP5Wb9c7nYZez7lHPQ9IMPgNV7THvu3LcBeOedhQwd+hi77NKLZ559Yfn6+wYO4ZFhd3PxJVe3VIpWQT2+vDk3/9/lAMz872ye/veLX9hmqy23oEP79kybMXP5OPUzY8bxta23YqNOHZs137xoyvnXETEn/bpA0kMkz8qdL6lLRMxLhz8WpJvPYcWp0N3S2BySixML40+Wm1OpT2NfS9KvJA2R9KCkX0haq/ieq68OHdqzzjprL1/ef7+9mDRpCl/5yue3czns0AOZMuWNlkrRKmzhe+8DUFNTw013DqLvEX0AmD33baqqkodizX17Pm/OeouuXTov32/4qCfps//ezZ1ubtRElNwaImltSevWLgMHAK8Cw4CT081OBoamy8OAk5T4JvBBOowyAjhAUkdJHdPjjCj385U6T/sukmkv16evTwDuBjwgW4/OnTfmgX/cCkDbtm0YNOhhRox8ksH3D2DrrbeipqaG//53Dv3PXP1mjuTRry+8grGvTOD99xez7xE/pP+pJ7Jk6VIGDXkUgP322p0jDzkAgJcnTOLWuwfTtm1b1lhD/OGcM+m4QXKB8ZKln/D82Fe48Dc/W+H4jz/1HH+89gYWvf8B/X99IV/t2YMB117WvB8yI5rwT/vOwEPpA83bAvdFxD8ljQUGSzoVmAX0TbcfTjJzZDrJlL8fA0TEIkmXAmPT7S5ZldtaNzjlb/lG0uSI2LZYrC6r8/CI1S9vU/6saTTFlL8TvnxkyTXnvlkPZW5WXKn3Hnk57e4DIGk3knmHZmatSjTivywqdXhkZ+Dfkv6bvt4CmCJpIskJ1B0qkp2ZWSNVZbQYl6rUol32RHAzs+aU1R50qUoaHomIWSRTWb6bLn8MrBERs9LXZmatgm/NyvKHIPQGtgFuB9YE7gG+XbnUzMwaL++3hih1eORIYEfgZYCImFs7f9HMrDVZrW/NWuDTiIj0+vvaieZmZq1O3h+CUOqUv8GSbiK5a9XpwOMkD0QwM2tVaoiSWxaV1NOOiKsk7Q8sJhnXviAiRlU0MzOzMnhM+3NTSeZkPy6pg6R1I+LDSiVmZlaOrM4KKVWpN4w6HXgAuCkNdQUerlBOZmZly/sVkaWOaZ9JMr1vMUBETAM2qVRSZmbl8ph2YllEfJre7QpJbWnmG3+bmZWiOvI9QFJqT/spSeeRPH5sf+AfwCOVS8vMrDweHkmcC7wDTAR+QnLf2D80uIeZWQtoqocgtFalTvmrkfQw8HBEvFPZlMzMypfNUly6Bnva6WNzLpL0LjCF5Has70i6oHnSMzNrnLyfiCw2PPJLklkju0REp4joBOwGfFvSLyuenZlZI+W9aBcbHjkR2D8i3q0NRMQMST8ERgLXVjI5M7PGWt1nj7QrLNi10nHtdpVJycysfE01e0TS5pL+JWmypEmSfp7GL5I0R9L4tPUp2Od3kqZLmiLpwIL4QWlsuqRVepp3sZ72p2WuMzNrEU1475Eq4H8i4uX0VtQvSaq959K1EXFV4caStgWOA7YDNgMel7R1uvpvwP7AbGCspGERMbmcpIoV7W9IWlxHXMBa5byhmVklNdVYdUTMA+alyx9Keo3kFh71ORwYFBHLgDclTQd2TddNj4gZAJIGpduWVbQbHB6JiDYRsV4dbd2I8PCImbU6EVFyk9RP0riC1q+uY0rakuRBMC+kobMkTZB0m6SOaawr8FbBbrPTWH3xspR6cY2ZWSZUU1Nyi4gBEdG7oA1Y+XiS1gEeBH4REYuBG4CtgF4kPfGrm/PzNebWrGZmrV5TXukoqR1Jwb43IoYARMT8gvU3A4+mL+eQPAC9Vrc0RgPxRnNP28xypQlnjwi4FXgtIq4piHcp2OxI4NV0eRhwnKQvSeoO9AReBMYCPSV1l7QmycnKYeV+Pve0zSxXmrCn/W2Sa1UmShqfxs4DjpfUi+SK+Zkk92MiIiZJGkxygrEKODMiqgEknQWMANoAt0XEpHKTUqUfzdN2za7ZvOzIKmrp3GdaOgVrhdpt1EOreoyvbrJLyTXn9QVjV/n9mpt72maWK1m9e1+pXLTNLFfyfhm7i7aZ5UpWH25QKhdtM8uVcE/bzCw7snrL1VK5aJtZrlR6RlxLc9E2s1xxT9vMLEOqazymbWaWGZ49YmaWIR7TNjPLEI9pm5lliHvaZmYZ4hORZmYZ4uERM7MM8fCImVmG+NasZmYZ4nnaZmYZ4p62mVmG1PjWrGZm2eETkWZmGeKibWaWIfku2aC8/1ZqTST1i4gBLZ2HtS7+ubDGWKOlE1jN9GvpBKxV8s+FlcxF28wsQ1y0zcwyxEW7eXnc0urinwsrmU9EmplliHvaZmYZ4qJtZpYhLtolkNRN0lBJ0yS9IekvktasY7vNJD1QwvGGS9qgzFwuknROOfta+SRVSxovaZKk/0j6H0lN/u9H0pOSpqTvNV7S0Q1sO1PSRk2dg7VuLtpFSBIwBHg4InoCWwPrAJettF3biJgbEfX+I6sVEX0i4v1K5GsVszQiekXEdsD+wMHAhRV6rx+k79UrIop2Amz14qJd3HeBTyLidoCIqAZ+CZwiqb+kYZKeAEZL2lLSqwCSOkgaLGmypIckvSCpd7pupqSN0u1fk3Rz2oMbKal9us3pksamvboHJXVomY9vK4uIBSQXxJylRBtJV6bfrwmSflK7raRfF8QvTmNbSnpd0r3p9/+Bhr6/km6QNC79Gbm4jvXtJT2W/sysLek2SS9KekXS4ZX4f2Atx0W7uO2AlwoDEbEY+C/JvVt2Ao6OiL1W2q8/8F5EbAucD+xcz/F7An9Le3DvA0el8SERsUtEfAN4DTi1CT6LNZGImAG0ATYh+d58EBG7ALsAp0vqLukAku/vrkAvYGdJ30kPsQ3w94j4GrCY5Oel1r0FwyMbAr+PiN7ADsBeknYo2HYd4BFgYETcDPweeCIidgX2Aa6UtHYl/h9Yy3DRXnWjImJRHfE9gEEAEfEqMKGe/d+MiPHp8kvAluny9pKekTQR+AHJLw9rnQ4ATpI0HngB2JCkWB+QtleAl4GvpnGAtyLiuXT5HpKfl1qFwyMLgb6SXk6Psx2wbcG2Q4HbI+KuglzOTXN5ElgL2KLpPqq1NN/lr7jJwArj1JLWI/mHUAV8vIrHX1awXA20T5fvAI6IiP9I+hGw9yq+jzUhST1Ivl8LAAFnR8SIlbY5EPhjRNy0UnxLvngzujovmJDUHTgH2CUi3pN0B0khrvUccJCk+yK56ELAURExpdzPZq2be9rFjQY6SDoJQFIb4GqSorqkgf2eA/qm+2wLfL2R77suME9SO5KetrUSkjYGbgT+mhbKEcBP0+8VkrZOhyRGkJz7WCeNd5W0SXqYLSR9K10+AXi2nrdbj6Rj8IGkziQnQAtdALwH/C19PQI4Oz2BjqQdV+3TWmvjol1E+o/ySOAYSdOAqcAnwHlFdv07sLGkycD/ApOADxrx1ueT/Kn9HPB6Y/O2Jte+dsof8DgwEqg9KXgLyV9kL6cnom8C2kbESOA+4Pl0mOsBkl/GAFOAMyW9BnQEbqjrTSPiPyTDIq+nx3qujs1+nub3Z+BSoB0wIc310lX72Nba+DL2Ckl75O0i4hNJW5H8Q98mIj5t4dSshaXDI49GxPYtnYtlj8e0K6cD8K/0T2YB/V2wzWxVuadtZpYhHtM2M8sQF20zswxx0TYzyxAXbTOzDHHRNjPLkP8HqAznq9Mqg4QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8858689896305312\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.974004424778761, 0.9972714168039539, 0.9855006105006106)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9843944530571868\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9745535714285715,\n",
       " 'precision': 0.974004424778761,\n",
       " 'recall': 0.9972714168039539,\n",
       " 'f1': 0.9855006105006106,\n",
       " 'auc': 0.9843944530571868,\n",
       " 'mcc': 0.8858689896305312}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.09683896 0.13323723 ... 1.         1.         1.        ]\n",
      "[0.         0.         0.         ... 0.95598118 0.95665323 1.        ]\n",
      "2738\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6b1b43590>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f118576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

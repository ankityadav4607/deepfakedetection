{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc81283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "# from torchvision.models import resnet101\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from datetime import datetime\n",
    "import torchvision.models as models\n",
    "# import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "# from CDCNs import Conv2d_cd\n",
    "from pytorch_model_summary import summary\n",
    "# import json\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "# from torchvision.models.resnet import Bottleneck\n",
    "import pandas as pd\n",
    "# from model.attention.ShuffleAttention import ShuffleAttention\n",
    "# from model.attention.CBAM import CBAMBlock\n",
    "\n",
    "from model.attention.CoordAttention import CoordAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '058a (main experiment)  - DeepFake 1'\n",
    "\n",
    "output_savepath = '/home/biometricgpu09/dhruv/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1152b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceTensor3(videopath, num):\n",
    "    \n",
    "    vidTensor = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        \n",
    "        name1 = str(i) + '.png'\n",
    "        \n",
    "        img = Image.open(videopath + name1)\n",
    "        \n",
    "        img = trans(img)\n",
    "        \n",
    "        vidTensor.append(img)\n",
    "        \n",
    "    vidTensor = torch.stack(vidTensor)\n",
    "    \n",
    "#     print(vidTensor.shape)\n",
    "    \n",
    "    return vidTensor\n",
    "\n",
    "# getFaceTensor3('/home/ankit/datasets/DFDC/extractedfaces/0/aaqaifqrwn/', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4a3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUnderScore(name):\n",
    "    \n",
    "    count =0\n",
    "    \n",
    "    for i in range(len(name)):\n",
    "        \n",
    "        if(name[i] == '_'):\n",
    "            count += 1\n",
    "            \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef253f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFClassification(Dataset):\n",
    "    \n",
    "    def __init__(self, alldata, allimages, allindexpath, manipulation_type, transform = None):\n",
    "               \n",
    "        self.alldata = torch.load(alldata)\n",
    "        \n",
    "        self.folders = ['real', 'Deepfakes', 'Face2Face','FaceShifter','FaceSwap', 'NeuralTextures']\n",
    "        \n",
    "        self.transform = transform    \n",
    "        \n",
    "        print('Loading all images data')\n",
    "        \n",
    "        self.allimages = torch.load(allimages)\n",
    "        \n",
    "        print('Loading images complete')\n",
    "        \n",
    "        allindex = torch.load(allindexpath)\n",
    "        \n",
    "        self.allindex = allindex[manipulation_type]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return 1997\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        actualIndex = self.allindex[index]\n",
    "        \n",
    "        data = self.alldata[actualIndex]\n",
    "        \n",
    "        label = data['label']\n",
    "        \n",
    "        vidTensor = self.allimages[actualIndex]\n",
    "        \n",
    "        if(label != 0):\n",
    "            label = 1\n",
    "        \n",
    "        if(self.transform):\n",
    "            vidTensor = self.transform(vidTensor)\n",
    "\n",
    "        return (vidTensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91845e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeBatch(batchinput, batchlabel):\n",
    "    \n",
    "    resizedbatch = torch.flatten(batchinput, start_dim=0, end_dim=1)\n",
    "    \n",
    "#     print('resized batch shape : ', resizedbatch.shape)\n",
    "    \n",
    "    resizedlabels = torch.tensor([], dtype=torch.int64)\n",
    "    \n",
    "    mul = batchinput.shape[1]\n",
    "#     print('mul : ', mul)\n",
    "    \n",
    "    for i in range(len(batchlabel)):\n",
    "        \n",
    "        label = torch.tensor(batchlabel[i])\n",
    "        label = label.repeat(mul)\n",
    "        resizedlabels = torch.cat([resizedlabels, label])\n",
    "        \n",
    "#     print('reshaped label shape : ', resizedlabels.shape)\n",
    "#     print(resizedlabels)\n",
    "\n",
    "    return (resizedbatch, resizedlabels)\n",
    "        \n",
    "# resizeBatch(a,l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9295a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used for training is  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used for training is \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a8acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_types = ['real-deepfake' , 'real-f2f', 'real-faceshifter', 'real-faceswap', 'real-neuraltextures']\n",
    "\n",
    "manipulation = manipulation_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d14981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alldatapath = '/home/biometricgpu09/datasets/FF++/allData.pt'\n",
    "\n",
    "allimagespath = '/home/biometricgpu09/datasets/FF++/allImages.pt'\n",
    "\n",
    "allindexpath = '/home/biometricgpu09/datasets/FF++/allIndexes.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5028e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "\n",
    "num_samples_train = 1500\n",
    "num_samples_validation = 200\n",
    "num_samples_test = 297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ca0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f7f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all images data\n",
      "Loading images complete\n"
     ]
    }
   ],
   "source": [
    "# dataset = FFClassification(rootPath, alldatapath, allimagespath,\n",
    "#                            allindexpath, manipulation, \n",
    "#                            transform = transformation)\n",
    "\n",
    "dataset = FFClassification(alldatapath, allimagespath,\n",
    "                           allindexpath, manipulation, \n",
    "                           transform = transformation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcc2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f0cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validationset, testset = torch.utils.data.random_split(dataset, [num_samples_train, \n",
    "                                                                           num_samples_validation, \n",
    "                                                                           num_samples_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63904272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = trainset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle = True,\n",
    "                         pin_memory=True)\n",
    "\n",
    "validationloader = DataLoader(dataset = validationset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle = True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "testloader = DataLoader(dataset = testset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle = True,\n",
    "                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac119db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "9\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "num_train_batches = len(trainloader)\n",
    "num_validation_batches = len(validationloader)\n",
    "num_test_batches = len(testloader)\n",
    "\n",
    "print(num_train_batches)\n",
    "print(num_validation_batches)\n",
    "print(num_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseNet(models.DenseNet):\n",
    "    \n",
    "    def __init__(self, pretrained = False):\n",
    "        \n",
    "        super(CustomDenseNet, self).__init__(growth_rate = 32, \n",
    "                                             block_config = (6, 12, 24, 16),\n",
    "                                            num_init_features = 64)\n",
    "        \n",
    "        if(pretrained):\n",
    "            pretrained_dict = pretrained.state_dict()\n",
    "            self.load_state_dict(pretrained_dict)\n",
    "            print('Pretrained weights loaded successfully')\n",
    "        else:\n",
    "            print('No pretrained weights loaded')\n",
    "            \n",
    "        self.classifier = nn.Linear(448, 2, bias = True)\n",
    "        \n",
    "        self.features.denseblock3 = nn.Identity()\n",
    "        self.features.transition3 = nn.Identity()        \n",
    "        self.features.denseblock4 = nn.Identity()        \n",
    "        \n",
    "        self.features.transition1.conv = nn.Conv2d(256,64,1)         \n",
    "        self.features.transition2.conv = nn.Conv2d(512,128,1)        \n",
    "#         self.features.transition3.conv = nn.Conv2d(1024,256,1)\n",
    "        \n",
    "        \n",
    "        self.att1 = CoordAtt(128 , 128 , reduction = 32)\n",
    "        self.att2 = CoordAtt(256 , 256 , reduction = 32)\n",
    "#         self.att3 = CoordAtt(512 , 512 , reduction = 32)\n",
    "        \n",
    "        self.att4 = CoordAtt(448 , 448 , reduction = 32)\n",
    "        \n",
    "#         self.conv01 = nn.Conv2d(320 , 256 , 1)\n",
    "#         self.conv02 = nn.Conv2d(640 , 512 , 1)\n",
    "#         self.conv04 = nn.Conv2d(1024 , 512 , 1)\n",
    "    \n",
    "        self.residualMP1 = nn.MaxPool2d(4,4)\n",
    "        self.residualMP2 = nn.MaxPool2d(2,2)\n",
    "#         self.residualMP3 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "#         self.conv05 = nn.Conv2d(1984 , 1024 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.features.conv0(x)\n",
    "        x = self.features.norm0(x)\n",
    "        x = self.features.relu0(x)\n",
    "        x = self.features.pool0(x)\n",
    "        \n",
    "        x1 = x\n",
    "        \n",
    "#         print('Shape before db1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock1(x)\n",
    "        x = self.features.transition1.norm(x)\n",
    "        x = self.features.transition1.relu(x)\n",
    "        x = self.features.transition1.conv(x)        \n",
    "        x = x1 - x\n",
    "        residual1 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x1, x),1)\n",
    "        x = self.att1(x)\n",
    "        x = self.features.transition1.pool(x)\n",
    "        \n",
    "#         \n",
    "#         x = self.conv01(x)\n",
    "        \n",
    "#         print('Shape after db1 : ', x.shape)       \n",
    "        \n",
    "#         x = self.features.transition1(x)\n",
    "        \n",
    "        x2 = x\n",
    "        \n",
    "#         print('Shape after t1 : ', x.shape)\n",
    "        \n",
    "        x = self.features.denseblock2(x)\n",
    "        x = self.features.transition2.norm(x)\n",
    "        x = self.features.transition2.relu(x)\n",
    "        x = self.features.transition2.conv(x)        \n",
    "        x = x2 - x        \n",
    "        residual2 = x\n",
    "#         print('residual shape : ', x.shape)\n",
    "        \n",
    "        x = torch.cat((x2, x),1)\n",
    "        x = self.att2(x)\n",
    "        x = self.features.transition2.pool(x)\n",
    "        \n",
    "        \n",
    "#         \n",
    "#         print('shape : ', x.shape)\n",
    "#         x = self.conv02(x)\n",
    "        \n",
    "#         print('Shape after db2 : ', x.shape)\n",
    "#         x = self.features.transition2(x)\n",
    "#         print('Shape after t2 : ', x.shape)\n",
    "        \n",
    "#         x3 = x\n",
    "        \n",
    "        x = self.features.denseblock3(x)\n",
    "        x = self.features.transition3(x)\n",
    "#         x = self.features.transition3.norm(x)\n",
    "#         x = self.features.transition3.relu(x)\n",
    "#         x = self.features.transition3.conv(x)        \n",
    "#         x = x3 - x   \n",
    "#         residual3 = x\n",
    "# #         print('residual shape : ', x.shape)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         x = self.att3(x)\n",
    "#         x = self.features.transition3.pool(x)\n",
    "        \n",
    "#         x = torch.cat((x3, x),1)\n",
    "#         \n",
    "        \n",
    "#         x = self.conv03(x)\n",
    "        \n",
    "#         print('Shape after db3 : ', x.shape)\n",
    "#         x = self.features.transition3(x)\n",
    "#         print('Shape after t3 : ', x.shape)\n",
    "        \n",
    "#         x4 = x\n",
    "        x = self.features.denseblock4(x)\n",
    "    \n",
    "#         print('Shape after DB2 & T2 : ', x.shape)\n",
    "        \n",
    "#         xx = self.conv04(x)\n",
    "#         residual4 = x4 - xx\n",
    "#         print('residual shape : ', residual4.shape)\n",
    "#         print('Shape after db4 : ', x.shape)\n",
    "        \n",
    "        residual1 = self.residualMP1(residual1)\n",
    "        residual2 = self.residualMP2(residual2)\n",
    "#         residual3 = self.residualMP3(residual3)\n",
    "        \n",
    "        allresidual = torch.cat((residual1,residual2), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3), 1)\n",
    "#         allresidual = torch.cat((residual1,residual2,residual3,residual4), 1)\n",
    "#         print('shape of all residual concatenated : ', allresidual.shape)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = torch.cat((x, allresidual), 1)\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.att4(out)\n",
    "        \n",
    "#         print('Concat shape : ', out.shape)\n",
    "        \n",
    "#         out = self.conv05(out)\n",
    "        \n",
    "#         print('shape before avg pool : ', out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "#         print('shape after avg pool : ', out.shape)\n",
    "        out = torch.flatten(out, 1)\n",
    "#         print('shape after flattening : ', out.shape)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be9b0414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = CustomDenseNet(pretrained = models.densenet121(pretrained=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "aa = torch.rand(16,3,128,128)\n",
    "o1 = model(aa)\n",
    "\n",
    "print(o1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22070ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1      [16, 64, 64, 64]           9,408           9,408\n",
      "     BatchNorm2d-2      [16, 64, 64, 64]             128             128\n",
      "            ReLU-3      [16, 64, 64, 64]               0               0\n",
      "       MaxPool2d-4      [16, 64, 32, 32]               0               0\n",
      "     _DenseBlock-5     [16, 256, 32, 32]         335,040         335,040\n",
      "     BatchNorm2d-6     [16, 256, 32, 32]             512             512\n",
      "            ReLU-7     [16, 256, 32, 32]               0               0\n",
      "          Conv2d-8      [16, 64, 32, 32]          16,448          16,448\n",
      "        CoordAtt-9     [16, 128, 32, 32]           3,352           3,352\n",
      "      AvgPool2d-10     [16, 128, 16, 16]               0               0\n",
      "    _DenseBlock-11     [16, 512, 16, 16]         919,680         919,680\n",
      "    BatchNorm2d-12     [16, 512, 16, 16]           1,024           1,024\n",
      "           ReLU-13     [16, 512, 16, 16]               0               0\n",
      "         Conv2d-14     [16, 128, 16, 16]          65,664          65,664\n",
      "       CoordAtt-15     [16, 256, 16, 16]           6,680           6,680\n",
      "      AvgPool2d-16       [16, 256, 8, 8]               0               0\n",
      "       Identity-17       [16, 256, 8, 8]               0               0\n",
      "       Identity-18       [16, 256, 8, 8]               0               0\n",
      "       Identity-19       [16, 256, 8, 8]               0               0\n",
      "      MaxPool2d-20        [16, 64, 8, 8]               0               0\n",
      "      MaxPool2d-21       [16, 128, 8, 8]               0               0\n",
      "       CoordAtt-22       [16, 448, 8, 8]          19,754          19,754\n",
      "         Linear-23               [16, 2]             898             898\n",
      "=========================================================================\n",
      "Total params: 1,378,588\n",
      "Trainable params: 1,378,588\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, torch.rand(16,3,128,128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf7dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): Identity()\n",
       "    (transition3): Identity()\n",
       "    (denseblock4): Identity()\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=448, out_features=2, bias=True)\n",
       "  (att1): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att2): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (att4): CoordAtt(\n",
       "    (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "    (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "    (conv1): Conv2d(448, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): h_swish(\n",
       "      (sigmoid): h_sigmoid(\n",
       "        (relu): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_h): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_w): Conv2d(14, 448, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (residualMP1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (residualMP2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcd25707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for parameter in model.parameters():\n",
    "    count += 1\n",
    "    \n",
    "#     parameter.requires_grad = False\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7e1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8feac3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "decayLR = scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee75eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss 0.69513616 \n",
      "Epoch 1, Batch 20, Loss 0.69176164 \n",
      "Epoch 1, Batch 30, Loss 0.69302635 \n",
      "Epoch 1, Batch 40, Loss 0.69093394 \n",
      "Epoch 1, Batch 50, Loss 0.68763318 \n",
      "Epoch 1, Batch 60, Loss 0.68234495 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4310\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.6734375\n",
      "---------\n",
      "Epoch time :  37.797944\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.900000000000001e-05]\n",
      "------------------------\n",
      "Epoch 2, Batch 10, Loss 0.66847255 \n",
      "Epoch 2, Batch 20, Loss 0.66465161 \n",
      "Epoch 2, Batch 30, Loss 0.63838158 \n",
      "Epoch 2, Batch 40, Loss 0.62401025 \n",
      "Epoch 2, Batch 50, Loss 0.60080954 \n",
      "Epoch 2, Batch 60, Loss 0.57130100 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5450\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8515625\n",
      "---------\n",
      "Epoch time :  30.432604\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.801e-05]\n",
      "------------------------\n",
      "Epoch 3, Batch 10, Loss 0.54096773 \n",
      "Epoch 3, Batch 20, Loss 0.51108808 \n",
      "Epoch 3, Batch 30, Loss 0.52154202 \n",
      "Epoch 3, Batch 40, Loss 0.47638651 \n",
      "Epoch 3, Batch 50, Loss 0.43019088 \n",
      "Epoch 3, Batch 60, Loss 0.40314105 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  4827\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.75421875\n",
      "---------\n",
      "Epoch time :  30.390703\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.70299e-05]\n",
      "------------------------\n",
      "Epoch 4, Batch 10, Loss 0.34465717 \n",
      "Epoch 4, Batch 20, Loss 0.35522111 \n",
      "Epoch 4, Batch 30, Loss 0.40955586 \n",
      "Epoch 4, Batch 40, Loss 0.32067429 \n",
      "Epoch 4, Batch 50, Loss 0.36341349 \n",
      "Epoch 4, Batch 60, Loss 0.34486002 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5352\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.83625\n",
      "---------\n",
      "Epoch time :  31.640508\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.605960100000001e-05]\n",
      "------------------------\n",
      "Epoch 5, Batch 10, Loss 0.32918881 \n",
      "Epoch 5, Batch 20, Loss 0.32063401 \n",
      "Epoch 5, Batch 30, Loss 0.35467786 \n",
      "Epoch 5, Batch 40, Loss 0.33414714 \n",
      "Epoch 5, Batch 50, Loss 0.31394018 \n",
      "Epoch 5, Batch 60, Loss 0.25646625 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5754\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8990625\n",
      "---------\n",
      "Epoch time :  30.19362\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.509900499000001e-05]\n",
      "------------------------\n",
      "Epoch 6, Batch 10, Loss 0.31586338 \n",
      "Epoch 6, Batch 20, Loss 0.27534284 \n",
      "Epoch 6, Batch 30, Loss 0.24416471 \n",
      "Epoch 6, Batch 40, Loss 0.27290801 \n",
      "Epoch 6, Batch 50, Loss 0.28837324 \n",
      "Epoch 6, Batch 60, Loss 0.23167792 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5384\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.84125\n",
      "---------\n",
      "Epoch time :  30.681708\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.414801494010001e-05]\n",
      "------------------------\n",
      "Epoch 7, Batch 10, Loss 0.23712536 \n",
      "Epoch 7, Batch 20, Loss 0.26127080 \n",
      "Epoch 7, Batch 30, Loss 0.26766459 \n",
      "Epoch 7, Batch 40, Loss 0.22606407 \n",
      "Epoch 7, Batch 50, Loss 0.31787882 \n",
      "Epoch 7, Batch 60, Loss 0.26396574 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5750\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8984375\n",
      "---------\n",
      "Epoch time :  30.674931\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.320653479069902e-05]\n",
      "------------------------\n",
      "Epoch 8, Batch 10, Loss 0.21433235 \n",
      "Epoch 8, Batch 20, Loss 0.28734483 \n",
      "Epoch 8, Batch 30, Loss 0.18647817 \n",
      "Epoch 8, Batch 40, Loss 0.20775892 \n",
      "Epoch 8, Batch 50, Loss 0.21973730 \n",
      "Epoch 8, Batch 60, Loss 0.22906467 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5599\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.87484375\n",
      "---------\n",
      "Epoch time :  30.961833\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.227446944279203e-05]\n",
      "------------------------\n",
      "Epoch 9, Batch 10, Loss 0.26280285 \n",
      "Epoch 9, Batch 20, Loss 0.22030018 \n",
      "Epoch 9, Batch 30, Loss 0.24601046 \n",
      "Epoch 9, Batch 40, Loss 0.23131399 \n",
      "Epoch 9, Batch 50, Loss 0.22353924 \n",
      "Epoch 9, Batch 60, Loss 0.21324556 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5919\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92484375\n",
      "---------\n",
      "Epoch time :  30.587512\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.13517247483641e-05]\n",
      "------------------------\n",
      "Epoch 10, Batch 10, Loss 0.19531698 \n",
      "Epoch 10, Batch 20, Loss 0.20441799 \n",
      "Epoch 10, Batch 30, Loss 0.26761778 \n",
      "Epoch 10, Batch 40, Loss 0.22077097 \n",
      "Epoch 10, Batch 50, Loss 0.24144739 \n",
      "Epoch 10, Batch 60, Loss 0.20907257 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5861\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.91578125\n",
      "---------\n",
      "Epoch time :  30.462106\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [9.043820750088047e-05]\n",
      "------------------------\n",
      "Epoch 11, Batch 10, Loss 0.19556214 \n",
      "Epoch 11, Batch 20, Loss 0.16710136 \n",
      "Epoch 11, Batch 30, Loss 0.17416730 \n",
      "Epoch 11, Batch 40, Loss 0.18589721 \n",
      "Epoch 11, Batch 50, Loss 0.24016932 \n",
      "Epoch 11, Batch 60, Loss 0.17156996 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6005\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.93828125\n",
      "---------\n",
      "Epoch time :  30.5252\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.953382542587167e-05]\n",
      "------------------------\n",
      "Epoch 12, Batch 10, Loss 0.14386582 \n",
      "Epoch 12, Batch 20, Loss 0.18283087 \n",
      "Epoch 12, Batch 30, Loss 0.14564766 \n",
      "Epoch 12, Batch 40, Loss 0.20780216 \n",
      "Epoch 12, Batch 50, Loss 0.17605665 \n",
      "Epoch 12, Batch 60, Loss 0.19005082 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5730\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.8953125\n",
      "---------\n",
      "Epoch time :  30.952365\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.863848717161295e-05]\n",
      "------------------------\n",
      "Epoch 13, Batch 10, Loss 0.13273152 \n",
      "Epoch 13, Batch 20, Loss 0.15292642 \n",
      "Epoch 13, Batch 30, Loss 0.18902025 \n",
      "Epoch 13, Batch 40, Loss 0.12943506 \n",
      "Epoch 13, Batch 50, Loss 0.15349874 \n",
      "Epoch 13, Batch 60, Loss 0.18091773 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5739\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.89671875\n",
      "---------\n",
      "Epoch time :  30.185967\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.775210229989682e-05]\n",
      "------------------------\n",
      "Epoch 14, Batch 10, Loss 0.12521545 \n",
      "Epoch 14, Batch 20, Loss 0.12626782 \n",
      "Epoch 14, Batch 30, Loss 0.10683392 \n",
      "Epoch 14, Batch 40, Loss 0.15171063 \n",
      "Epoch 14, Batch 50, Loss 0.17477325 \n",
      "Epoch 14, Batch 60, Loss 0.18814936 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5913\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92390625\n",
      "---------\n",
      "Epoch time :  30.494792\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.687458127689785e-05]\n",
      "------------------------\n",
      "Epoch 15, Batch 10, Loss 0.16960555 \n",
      "Epoch 15, Batch 20, Loss 0.16469342 \n",
      "Epoch 15, Batch 30, Loss 0.19129874 \n",
      "Epoch 15, Batch 40, Loss 0.14394729 \n",
      "Epoch 15, Batch 50, Loss 0.13222508 \n",
      "Epoch 15, Batch 60, Loss 0.16179618 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5767\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.90109375\n",
      "---------\n",
      "Epoch time :  30.811613\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.600583546412887e-05]\n",
      "------------------------\n",
      "Epoch 16, Batch 10, Loss 0.10676246 \n",
      "Epoch 16, Batch 20, Loss 0.14377025 \n",
      "Epoch 16, Batch 30, Loss 0.12163513 \n",
      "Epoch 16, Batch 40, Loss 0.14149645 \n",
      "Epoch 16, Batch 50, Loss 0.11539848 \n",
      "Epoch 16, Batch 60, Loss 0.11804283 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6059\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94671875\n",
      "---------\n",
      "Epoch time :  30.531697\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.514577710948758e-05]\n",
      "------------------------\n",
      "Epoch 17, Batch 10, Loss 0.13863054 \n",
      "Epoch 17, Batch 20, Loss 0.14650899 \n",
      "Epoch 17, Batch 30, Loss 0.09785020 \n",
      "Epoch 17, Batch 40, Loss 0.10426515 \n",
      "Epoch 17, Batch 50, Loss 0.11700685 \n",
      "Epoch 17, Batch 60, Loss 0.15077506 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5331\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.83296875\n",
      "---------\n",
      "Epoch time :  30.513857\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.429431933839271e-05]\n",
      "------------------------\n",
      "Epoch 18, Batch 10, Loss 0.08579437 \n",
      "Epoch 18, Batch 20, Loss 0.11923858 \n",
      "Epoch 18, Batch 30, Loss 0.08256756 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 40, Loss 0.11200092 \n",
      "Epoch 18, Batch 50, Loss 0.11252012 \n",
      "Epoch 18, Batch 60, Loss 0.10851713 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5928\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92625\n",
      "---------\n",
      "Epoch time :  30.795034\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.345137614500879e-05]\n",
      "------------------------\n",
      "Epoch 19, Batch 10, Loss 0.12539938 \n",
      "Epoch 19, Batch 20, Loss 0.09380010 \n",
      "Epoch 19, Batch 30, Loss 0.11404804 \n",
      "Epoch 19, Batch 40, Loss 0.16765962 \n",
      "Epoch 19, Batch 50, Loss 0.07147749 \n",
      "Epoch 19, Batch 60, Loss 0.09830282 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6038\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9434375\n",
      "---------\n",
      "Epoch time :  30.562372\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.26168623835587e-05]\n",
      "------------------------\n",
      "Epoch 20, Batch 10, Loss 0.09346130 \n",
      "Epoch 20, Batch 20, Loss 0.10582609 \n",
      "Epoch 20, Batch 30, Loss 0.08298046 \n",
      "Epoch 20, Batch 40, Loss 0.11730673 \n",
      "Epoch 20, Batch 50, Loss 0.11462760 \n",
      "Epoch 20, Batch 60, Loss 0.12962656 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6000\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9375\n",
      "---------\n",
      "Epoch time :  33.058823\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.17906937597231e-05]\n",
      "------------------------\n",
      "Epoch 21, Batch 10, Loss 0.09355101 \n",
      "Epoch 21, Batch 20, Loss 0.07143554 \n",
      "Epoch 21, Batch 30, Loss 0.08746107 \n",
      "Epoch 21, Batch 40, Loss 0.09246702 \n",
      "Epoch 21, Batch 50, Loss 0.10965914 \n",
      "Epoch 21, Batch 60, Loss 0.10171847 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6021\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94078125\n",
      "---------\n",
      "Epoch time :  35.112135\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.097278682212587e-05]\n",
      "------------------------\n",
      "Epoch 22, Batch 10, Loss 0.07688344 \n",
      "Epoch 22, Batch 20, Loss 0.09379266 \n",
      "Epoch 22, Batch 30, Loss 0.08224663 \n",
      "Epoch 22, Batch 40, Loss 0.05514725 \n",
      "Epoch 22, Batch 50, Loss 0.09377491 \n",
      "Epoch 22, Batch 60, Loss 0.14630675 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6033\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94265625\n",
      "---------\n",
      "Epoch time :  34.848165\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [8.016305895390461e-05]\n",
      "------------------------\n",
      "Epoch 23, Batch 10, Loss 0.10712246 \n",
      "Epoch 23, Batch 20, Loss 0.07061299 \n",
      "Epoch 23, Batch 30, Loss 0.08630728 \n",
      "Epoch 23, Batch 40, Loss 0.08627277 \n",
      "Epoch 23, Batch 50, Loss 0.09753704 \n",
      "Epoch 23, Batch 60, Loss 0.07416316 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  5929\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.92640625\n",
      "---------\n",
      "Epoch time :  35.12124\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.936142836436556e-05]\n",
      "------------------------\n",
      "Epoch 24, Batch 10, Loss 0.10897400 \n",
      "Epoch 24, Batch 20, Loss 0.07099464 \n",
      "Epoch 24, Batch 30, Loss 0.05418439 \n",
      "Epoch 24, Batch 40, Loss 0.10145736 \n",
      "Epoch 24, Batch 50, Loss 0.11914261 \n",
      "Epoch 24, Batch 60, Loss 0.08575246 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6058\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9465625\n",
      "---------\n",
      "Epoch time :  34.8138\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.856781408072191e-05]\n",
      "------------------------\n",
      "Epoch 25, Batch 10, Loss 0.09498600 \n",
      "Epoch 25, Batch 20, Loss 0.07949087 \n",
      "Epoch 25, Batch 30, Loss 0.06019389 \n",
      "Epoch 25, Batch 40, Loss 0.05836639 \n",
      "Epoch 25, Batch 50, Loss 0.08094810 \n",
      "Epoch 25, Batch 60, Loss 0.08108419 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6058\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9465625\n",
      "---------\n",
      "Epoch time :  34.660287\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.778213593991469e-05]\n",
      "------------------------\n",
      "Epoch 26, Batch 10, Loss 0.05104642 \n",
      "Epoch 26, Batch 20, Loss 0.07396411 \n",
      "Epoch 26, Batch 30, Loss 0.04236965 \n",
      "Epoch 26, Batch 40, Loss 0.07790288 \n",
      "Epoch 26, Batch 50, Loss 0.07781809 \n",
      "Epoch 26, Batch 60, Loss 0.07571105 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6101\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95328125\n",
      "---------\n",
      "Epoch time :  34.78672\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.700431458051554e-05]\n",
      "------------------------\n",
      "Epoch 27, Batch 10, Loss 0.08658082 \n",
      "Epoch 27, Batch 20, Loss 0.06962845 \n",
      "Epoch 27, Batch 30, Loss 0.08365693 \n",
      "Epoch 27, Batch 40, Loss 0.04239221 \n",
      "Epoch 27, Batch 50, Loss 0.06068512 \n",
      "Epoch 27, Batch 60, Loss 0.04778866 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6109\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.95453125\n",
      "---------\n",
      "Epoch time :  34.584533\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.623427143471038e-05]\n",
      "------------------------\n",
      "Epoch 28, Batch 10, Loss 0.06862701 \n",
      "Epoch 28, Batch 20, Loss 0.06123973 \n",
      "Epoch 28, Batch 30, Loss 0.05260089 \n",
      "Epoch 28, Batch 40, Loss 0.05042662 \n",
      "Epoch 28, Batch 50, Loss 0.10310803 \n",
      "Epoch 28, Batch 60, Loss 0.06864887 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6014\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9396875\n",
      "---------\n",
      "Epoch time :  34.420967\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.547192872036328e-05]\n",
      "------------------------\n",
      "Epoch 29, Batch 10, Loss 0.04447830 \n",
      "Epoch 29, Batch 20, Loss 0.04266057 \n",
      "Epoch 29, Batch 30, Loss 0.05888272 \n",
      "Epoch 29, Batch 40, Loss 0.13200506 \n",
      "Epoch 29, Batch 50, Loss 0.07504228 \n",
      "Epoch 29, Batch 60, Loss 0.05619195 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6098\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.9528125\n",
      "---------\n",
      "Epoch time :  34.545632\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.471720943315964e-05]\n",
      "------------------------\n",
      "Epoch 30, Batch 10, Loss 0.07177305 \n",
      "Epoch 30, Batch 20, Loss 0.05501504 \n",
      "Epoch 30, Batch 30, Loss 0.07065021 \n",
      "Epoch 30, Batch 40, Loss 0.05720394 \n",
      "Epoch 30, Batch 50, Loss 0.02827648 \n",
      "Epoch 30, Batch 60, Loss 0.04856445 \n",
      "------------\n",
      "Validating\n",
      "------------\n",
      "---------\n",
      "Correct :  6053\n",
      "Total :  6400\n",
      "Final Validation accuracy :  0.94578125\n",
      "---------\n",
      "Epoch time :  34.715646\n",
      "---------------------------------\n",
      "Previous Learning Rate :  [7.397003733882805e-05]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses=[]\n",
    "vacc = []\n",
    "vlosses = []\n",
    "\n",
    "for j in range(epochs):\n",
    "    \n",
    "    epoch_start = datetime.now()\n",
    "    \n",
    "    add_loss = 0.0\n",
    "    run_loss2 = 0\n",
    "    \n",
    "    for i,data in enumerate(trainloader):\n",
    "        \n",
    "#         s1 = datetime.now()\n",
    "        \n",
    "#         if( i!= 0):\n",
    "#             print('Time : ', (s1-s4).total_seconds())\n",
    "        \n",
    "        image, label = data\n",
    "        \n",
    "        image, label = resizeBatch(image, label)\n",
    "    \n",
    "        image = image.to(device)\n",
    "#         ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "        \n",
    "#         image = torch.transpose(image, 1,2)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         s3 = datetime.now()\n",
    "    \n",
    "        output = model(image)\n",
    "        \n",
    "#         print(output.shape)\n",
    "    \n",
    "        loss = lossFunction(output, label)\n",
    "        \n",
    "        add_loss += loss.item()\n",
    "        run_loss2 += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i % 10 == 9):\n",
    "            print('Epoch %d, Batch %d, Loss %.8f ' % (j+1, i+1, add_loss / 10))\n",
    "#             s2 = datetime.now()\n",
    "#             print('Read time : ', (s3 - s1).total_seconds())\n",
    "#             print('Batch time : ', (s2-s1).total_seconds())\n",
    "#             print('-------')\n",
    "            add_loss = 0.0    \n",
    "    \n",
    "#         s4 = datetime.now()\n",
    "    \n",
    "    losses.append(run_loss2 / num_train_batches)\n",
    "    \n",
    "    print('------------')\n",
    "    print('Validating')\n",
    "    print('------------')\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    vrun_loss=0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        add_vloss = 0.0\n",
    "        \n",
    "        for k, vdata in enumerate(validationloader):\n",
    "            \n",
    "            val_image, val_label = vdata\n",
    "            \n",
    "            val_image, val_label = resizeBatch(val_image, val_label)\n",
    "            \n",
    "            val_image = val_image.to(device)\n",
    "#             val_of = val_of.to(device)\n",
    "            val_label = val_label.to(device)\n",
    "            \n",
    "#             val_image = torch.transpose(val_image, 1,2)\n",
    "            \n",
    "            val_output = model(val_image)\n",
    "            \n",
    "            vloss = lossFunction(val_output, val_label)\n",
    "            \n",
    "            add_vloss += vloss.item()\n",
    "            vrun_loss += vloss.item()\n",
    "            \n",
    "            if(k%10 == 9):\n",
    "                print('Validation loss : ', add_vloss / 10)\n",
    "                add_vloss = 0.0\n",
    "            \n",
    "            class_probability, class_prediction = torch.max(val_output, 1)\n",
    "            \n",
    "            total += len(val_label)\n",
    "            \n",
    "            correct += (class_prediction == val_label).sum().item()\n",
    "            \n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        vlosses.append(vrun_loss / num_validation_batches)\n",
    "        vacc.append(val_accuracy)\n",
    "        print('---------')\n",
    "        print('Correct : ', correct)\n",
    "        print('Total : ', total)\n",
    "        print('Final Validation accuracy : ', val_accuracy)\n",
    "        print('---------')\n",
    "        epoch_end = datetime.now()\n",
    "        print('Epoch time : ', (epoch_end - epoch_start).total_seconds())\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    model.train()\n",
    "    decayLR.step()\n",
    "    \n",
    "    print('Previous Learning Rate : ', decayLR.get_last_lr())\n",
    "#     aa1, aa2 = model.module.getAlpha()\n",
    "#     alpha1List.append(aa1)\n",
    "#     alpha2List.append(aa2)\n",
    "\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c92a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3227baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biometricgpu09/anaconda3/envs/ankit/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct :  9205\n",
      "Total :  9504\n",
      "Test accuracy is  0.9685395622895623\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_labels = torch.tensor([]).to(device)\n",
    "all_predicted_test_probabilities = torch.tensor([]).to(device)\n",
    "all_predicted_fake_probabilities = torch.tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, data in enumerate(testloader):\n",
    "        \n",
    "        test_image, test_label = data\n",
    "        \n",
    "        test_image, test_label = resizeBatch(test_image, test_label)\n",
    "        \n",
    "        test_image = test_image.to(device)\n",
    "#         test_of = test_of.to(device)        \n",
    "        test_label = test_label.to(device)\n",
    "        \n",
    "        all_test_labels = torch.cat([all_test_labels, test_label])\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        \n",
    "        test_output2 = softmax(test_output)\n",
    "        \n",
    "        test_output3, _ = torch.max(test_output2, dim=1)\n",
    "\n",
    "        \n",
    "#         print('Output on Test Batch')\n",
    "#         print(test_output.shape)\n",
    "#         print('------------------------')\n",
    "        \n",
    "        loss = lossFunction(test_output, test_label)\n",
    "        \n",
    "#         print('Loss value : ', loss.item())\n",
    "#         print('Acutal Labels : ', test_label)\n",
    "        \n",
    "        \n",
    "        class_probability, class_prediction = torch.max(test_output, 1)\n",
    "        \n",
    "#         print('Predicted Label : ', class_prediction)\n",
    "#         print('-----------------')\n",
    "        \n",
    "        all_predicted_test_labels = torch.cat([all_predicted_test_labels, class_prediction])\n",
    "        \n",
    "        all_predicted_test_probabilities = torch.cat([all_predicted_test_probabilities, test_output3])\n",
    "        \n",
    "        all_predicted_fake_probabilities = torch.cat([all_predicted_fake_probabilities, test_output2[:, 1]])\n",
    "        \n",
    "        total += len(test_label)\n",
    "        \n",
    "        correct += (class_prediction == test_label).sum().item()\n",
    "        \n",
    "    final_test_accuracy = correct/total\n",
    "    \n",
    "    print('Correct : ', correct)\n",
    "    print('Total : ', total)\n",
    "    print('Test accuracy is ', final_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ee2c0",
   "metadata": {},
   "source": [
    "# Calculate confusion matrix and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56539d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4852  140]\n",
      " [ 159 4353]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrix = confusion_matrix(all_test_labels.cpu(), all_predicted_test_labels.cpu(), labels = range(2))\n",
    "\n",
    "print(confusionMatrix)\n",
    "\n",
    "confusionmatrixpath = output_savepath + experiment_name + '-confusionmatrix.pt'\n",
    "\n",
    "confusion_dictionary = {0:confusionMatrix}\n",
    "\n",
    "torch.save(confusion_dictionary, confusionmatrixpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5de",
   "metadata": {},
   "source": [
    "# Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f28fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# confusionMatrixPath = '/home/ankit/code/k/figures/'\n",
    "\n",
    "# plot_name = 'confusion' + '_' + feature1 + '_' + feature2 + '_' + feature3 + '_' + str(int(a1*100)) + '_' + str(int(a2*100)) + '_' + str(int(a3*100)) + '.png'\n",
    "\n",
    "# sns.set(rc={'figure.figsize':(13.7,10.27)})\n",
    "\n",
    "ax = sns.heatmap(confusionMatrix, annot = True, \n",
    "                 xticklabels=['Original', 'DeepFake'], \n",
    "                 yticklabels=['Original', 'DeepFake'],\n",
    "                 fmt='d')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "\n",
    "# fig.savefig(confusionMatrixPath + plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e9eb3",
   "metadata": {},
   "source": [
    "# MCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8be54a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936912974919448\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "mcc2 = metrics.matthews_corrcoef(all_test_labels.cpu(), all_predicted_test_labels.cpu())\n",
    "print(mcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fcb",
   "metadata": {},
   "source": [
    "# calc precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c6cc384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9688404184286669, 0.9647606382978723, 0.9667962243198224)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_test_labels.cpu(), \n",
    "                                                           all_predicted_test_labels.cpu(), \n",
    "                                                           labels = range(2),\n",
    "                                                           average = 'binary')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae95a3",
   "metadata": {},
   "source": [
    "# calc AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec6d55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9917883018858543\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_score = metrics.roc_auc_score(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), \n",
    "                                  \n",
    "                                  )\n",
    "\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421b2be",
   "metadata": {},
   "source": [
    "# Save all metrics in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d3df972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9685395622895623,\n",
       " 'precision': 0.9688404184286669,\n",
       " 'recall': 0.9647606382978723,\n",
       " 'f1': 0.9667962243198224,\n",
       " 'auc': 0.9917883018858543,\n",
       " 'mcc': 0.936912974919448}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dictionary = {}\n",
    "\n",
    "metrics_dictionary['accuracy'] = final_test_accuracy\n",
    "metrics_dictionary['precision'] = precision\n",
    "metrics_dictionary['recall'] = recall\n",
    "metrics_dictionary['f1'] = f1\n",
    "metrics_dictionary['auc'] = auc_score\n",
    "metrics_dictionary['mcc'] = mcc2\n",
    "\n",
    "savefullpath = output_savepath + experiment_name + '-result-metrics.pt'\n",
    "\n",
    "torch.save(metrics_dictionary, savefullpath)\n",
    "\n",
    "metrics_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769ff7",
   "metadata": {},
   "source": [
    "# calculate TPR and FPR for ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2dcff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01307624 0.01861702 0.0212766  0.0241578  0.0277039\n",
      " 0.03102837 0.03280142 0.03590426 0.0376773  0.03922872 0.04100177\n",
      " 0.04277482 0.04343972 0.04499113 0.04587766 0.04720745 0.04787234\n",
      " 0.04875887 0.05319149 0.05363475 0.05496454 0.0560727  0.05651596\n",
      " 0.05673759 0.05762411 0.05873227 0.0589539  0.06094858 0.06183511\n",
      " 0.0625     0.06338652 0.06360816 0.06493794 0.06626773 0.06648936\n",
      " 0.06693262 0.06737589 0.06826241 0.06848404 0.06937057 0.0695922\n",
      " 0.07003546 0.07070035 0.07136525 0.07158688 0.07225177 0.0724734\n",
      " 0.07335993 0.07358156 0.07402482 0.07468972 0.07557624 0.0760195\n",
      " 0.07712766 0.07779255 0.07890071 0.07934397 0.0802305  0.08067376\n",
      " 0.08156028 0.08200355 0.08289007 0.0831117  0.08510638 0.08577128\n",
      " 0.0866578  0.08754433 0.08843085 0.08887411 0.08953901 0.08998227\n",
      " 0.09086879 0.09131206 0.09175532 0.09264184 0.09308511 0.09352837\n",
      " 0.09441489 0.09485816 0.09507979 0.09552305 0.09574468 0.09640957\n",
      " 0.0972961  0.09818262 0.09840426 0.09929078 0.09995567 0.10039894\n",
      " 0.10128546 0.10195035 0.10239362 0.1043883  0.10527482 0.10638298\n",
      " 0.10682624 0.1072695  0.10859929 0.10882092 0.10948582 0.11015071\n",
      " 0.11059397 0.1108156  0.11125887 0.11192376 0.11236702 0.11303191\n",
      " 0.11369681 0.11414007 0.1150266  0.11546986 0.11635638 0.11702128\n",
      " 0.11746454 0.11768617 0.11812943 0.1185727  0.11923759 0.11990248\n",
      " 0.12056738 0.12234043 0.12300532 0.12344858 0.12367021 0.12411348\n",
      " 0.12455674 0.125      0.1285461  0.12898936 0.1314273  0.13187057\n",
      " 0.13519504 0.13585993 0.13674645 0.13718972 0.13984929 0.14029255\n",
      " 0.14117908 0.14162234 0.14250887 0.14295213 0.14428191 0.14516844\n",
      " 0.1456117  0.15048759 0.15181738 0.15248227 0.15292553 0.15469858\n",
      " 0.15514184 0.15580674 0.15625    0.15802305 0.15846631 0.16001773\n",
      " 0.16046099 0.16289894 0.1633422  0.16954787 0.16999113 0.1704344\n",
      " 0.17109929 0.17176418 0.17265071 0.17907801 0.17952128 0.18085106\n",
      " 0.18129433 0.18262411 0.18306738 0.18439716 0.18484043 0.18572695\n",
      " 0.18617021 0.19304078 0.19348404 0.19725177 0.19769504 0.19791667\n",
      " 0.19835993 0.19991135 0.20035461 0.20079787 0.20146277 0.20190603\n",
      " 0.20234929 0.20301418 0.20390071 0.20434397 0.20478723 0.20789007\n",
      " 0.20855496 0.2087766  0.20921986 0.21476064 0.2152039  0.21852837\n",
      " 0.21897163 0.22074468 0.22140957 0.22185284 0.22695035 0.22739362\n",
      " 0.22983156 0.23071809 0.23182624 0.2322695  0.23404255 0.23448582\n",
      " 0.23537234 0.2358156  0.23603723 0.2364805  0.2400266  0.24046986\n",
      " 0.24534574 0.24578901 0.25066489 0.25110816 0.25243794 0.25288121\n",
      " 0.25421099 0.25465426 0.2564273  0.25687057 0.25753546 0.25797872\n",
      " 0.25908688 0.25953014 0.26263298 0.26307624 0.26662234 0.2670656\n",
      " 0.2677305  0.26817376 0.26950355 0.26994681 0.27039007 0.27083333\n",
      " 0.2712766  0.27171986 0.27371454 0.27437943 0.27504433 0.27548759\n",
      " 0.27681738 0.2777039  0.28058511 0.28102837 0.28302305 0.28346631\n",
      " 0.29410461 0.29454787 0.29609929 0.29654255 0.30518617 0.30562943\n",
      " 0.30629433 0.30673759 0.30718085 0.30762411 0.31139184 0.31183511\n",
      " 0.31205674 0.3125     0.31737589 0.31781915 0.33045213 0.33089539\n",
      " 0.34507979 0.34552305 0.34663121 0.34707447 0.35571809 0.35638298\n",
      " 0.37477837 0.37522163 0.38076241 0.38120567 0.39117908 0.39162234\n",
      " 0.39450355 0.39494681 0.40713652 0.40757979 0.41666667 0.41710993\n",
      " 0.42708333 0.4275266  0.43373227 0.43417553 0.44946809 0.44991135\n",
      " 0.46077128 0.46077128 0.46143617 0.46187943 0.46387411 0.46431738\n",
      " 0.47096631 0.47140957 0.48404255 0.48448582 0.49224291 0.49268617\n",
      " 0.49556738 0.49601064 0.50443262 0.50487589 0.51041667 0.51041667\n",
      " 0.51950355 0.51994681 0.52282801 0.52327128 0.52836879 0.52836879\n",
      " 0.53523936 0.53568262 0.5418883  0.5418883  0.55164007 0.55208333\n",
      " 0.57092199 0.57136525 0.57424645 0.57468972 0.5837766  0.58421986\n",
      " 0.6001773  0.60394504 0.62588652 0.62588652 0.64073582 0.64117908\n",
      " 0.65757979 0.65824468 0.6597961  0.6597961  0.68262411 0.68262411\n",
      " 0.69902482 0.69902482 0.72960993 0.72960993 0.73005319 0.7322695\n",
      " 0.7322695  0.7400266  0.7400266  0.74202128 0.74202128 0.7429078\n",
      " 0.7429078  0.75664894 0.75664894 0.75687057 0.75687057 0.75753546\n",
      " 0.75753546 0.76130319 0.76130319 0.76196809 0.76196809 0.76440603\n",
      " 0.76440603 0.76662234 0.76662234 0.76817376 0.76817376 0.76928191\n",
      " 0.76928191 0.76972518 0.76972518 0.7712766  0.7712766  0.77349291\n",
      " 0.77349291 0.77371454 0.77371454 0.7741578  0.7741578  0.77437943\n",
      " 0.77437943 0.77460106 0.77460106 0.7748227  0.77570922 0.77570922\n",
      " 0.77659574 0.77659574 0.77726064 0.77726064 0.77859043 0.77859043\n",
      " 0.78368794 0.78368794 0.79875887 0.79875887 0.84707447 0.84707447\n",
      " 0.84773936 0.84773936 0.85483156 0.85483156 0.85571809 0.85571809\n",
      " 0.85859929 0.85859929 0.85882092 0.85882092 0.85970745 0.85970745\n",
      " 0.8608156  0.8608156  0.86192376 0.86192376 0.86214539 0.86214539\n",
      " 0.86258865 0.86258865 0.86458333 0.86458333 0.86591312 0.86591312\n",
      " 0.87211879 0.87211879 0.87832447 0.87832447 0.89140071 0.89140071\n",
      " 0.89228723 0.89228723 0.89605496 0.89605496 0.8962766  0.8962766\n",
      " 0.89782801 0.89782801 0.89960106 0.89960106 0.90026596 0.90026596\n",
      " 0.90536348 0.90536348 0.90558511 0.90558511 0.90691489 0.90691489\n",
      " 0.90802305 0.90802305 0.9097961  0.9097961  0.91289894 0.91289894\n",
      " 0.91378546 0.91378546 0.91511525 0.91511525 0.91954787 0.91954787\n",
      " 0.92486702 0.92486702 0.92575355 0.92575355 0.92819149 0.92819149\n",
      " 0.93085106 0.93085106 0.9310727  0.9310727  0.93262411 0.93262411\n",
      " 0.93373227 0.93373227 0.93550532 0.93550532 0.93683511 0.93683511\n",
      " 0.93727837 0.93727837 0.93772163 0.93772163 0.93860816 0.93860816\n",
      " 0.93882979 0.93882979 0.93949468 0.93949468 0.94038121 0.94038121\n",
      " 0.9410461  0.9410461  0.94326241 0.94326241 0.94437057 0.94437057\n",
      " 0.94503546 0.94503546 0.94525709 0.94525709 0.94547872 0.94547872\n",
      " 0.94636525 0.94636525 0.94703014 0.94703014 0.9474734  0.9474734\n",
      " 0.94769504 0.94769504 0.9481383  0.9481383  0.94880319 0.94880319\n",
      " 0.94968972 0.94968972 0.94991135 0.94991135 0.95013298 0.95013298\n",
      " 0.95035461 0.95035461 0.9510195  0.9510195  0.95124113 0.95124113\n",
      " 0.9516844  0.9516844  0.95412234 0.95412234 0.95589539 0.95589539\n",
      " 0.95700355 0.95700355 0.9581117  0.9581117  0.9587766  0.9587766\n",
      " 0.95899823 0.95899823 0.95944149 0.95944149 0.95988475 0.95988475\n",
      " 0.96010638 0.96010638 0.96054965 0.96054965 0.96121454 0.96121454\n",
      " 0.96187943 0.96187943 0.96210106 0.96210106 0.9623227  0.9623227\n",
      " 0.96343085 0.96343085 0.96365248 0.96365248 0.96387411 0.96387411\n",
      " 0.96476064 0.96476064 0.96498227 0.96498227 0.96542553 0.96542553\n",
      " 0.96586879 0.96586879 0.96609043 0.96609043 0.96653369 0.96653369\n",
      " 0.96697695 0.96697695 0.96719858 0.96719858 0.96742021 0.96742021\n",
      " 0.96808511 0.96808511 0.96830674 0.96830674 0.96897163 0.96897163\n",
      " 0.96919326 0.96919326 0.96941489 0.96941489 0.96963652 0.96963652\n",
      " 0.96985816 0.96985816 0.97007979 0.97007979 0.97052305 0.97052305\n",
      " 0.97074468 0.97074468 0.97096631 0.97096631 0.97118794 0.97118794\n",
      " 0.97207447 0.97207447 0.9722961  0.9722961  0.97296099 0.97296099\n",
      " 0.97318262 0.97318262 0.97340426 0.97340426 0.97362589 0.97362589\n",
      " 0.97384752 0.97384752 0.97406915 0.97406915 0.97451241 0.97451241\n",
      " 0.97473404 0.97473404 0.97495567 0.97495567 0.9751773  0.9751773\n",
      " 0.97539894 0.97539894 0.97562057 0.97562057 0.9758422  0.9758422\n",
      " 0.97606383 0.97606383 0.97628546 0.97628546 0.97650709 0.97650709\n",
      " 0.97672872 0.97672872 0.97695035 0.97695035 0.97717199 0.97717199\n",
      " 0.97761525 0.97761525 0.97783688 0.97783688 0.97805851 0.97805851\n",
      " 0.97828014 0.97828014 0.97850177 0.97850177 0.9787234  0.9787234\n",
      " 0.97894504 0.97894504 0.97916667 0.97916667 0.97960993 0.97960993\n",
      " 0.97983156 0.97983156 0.98005319 0.98005319 0.98027482 0.98027482\n",
      " 0.98049645 0.98049645 0.98071809 0.98071809 0.98116135 0.98116135\n",
      " 0.98138298 0.98138298 0.98160461 0.98160461 0.98182624 0.98182624\n",
      " 0.9822695  0.9822695  0.98249113 0.98249113 0.98271277 0.98271277\n",
      " 0.9829344  0.9829344  0.98315603 0.98315603 0.98337766 0.98337766\n",
      " 0.98359929 0.98359929 0.98382092 0.98382092 0.98404255 0.98404255\n",
      " 0.98426418 0.98426418 0.98448582 0.98448582 0.98470745 0.98470745\n",
      " 0.98492908 0.98492908 0.98515071 0.98515071 0.98559397 0.98559397\n",
      " 0.9858156  0.9858156  0.98603723 0.98603723 0.98625887 0.98625887\n",
      " 0.9864805  0.9864805  0.98670213 0.98670213 0.98692376 0.98692376\n",
      " 0.98714539 0.98714539 0.98736702 0.98736702 0.98758865 0.98758865\n",
      " 0.98781028 0.98781028 0.98803191 0.98803191 0.98825355 0.98825355\n",
      " 0.98847518 0.98847518 0.98869681 0.98869681 0.98891844 0.98891844\n",
      " 0.98914007 0.98914007 0.9893617  0.9893617  0.98958333 0.98958333\n",
      " 0.98980496 0.98980496 0.9900266  0.9900266  0.99024823 0.99024823\n",
      " 0.99046986 0.99046986 0.99069149 0.99069149 0.99091312 0.99091312\n",
      " 0.99113475 0.99113475 0.99135638 0.99135638 0.99135638 0.99135638\n",
      " 0.99157801 0.99157801 0.99179965 0.99179965 0.99202128 0.99202128\n",
      " 0.99224291 0.99224291 0.99246454 0.99246454 0.99268617 0.99268617\n",
      " 0.9929078  0.9929078  0.99312943 0.99312943 0.99335106 0.99335106\n",
      " 0.9935727  0.9935727  0.99379433 0.99379433 0.99401596 0.99401596\n",
      " 0.99423759 0.99423759 0.99445922 0.99445922 0.99468085 0.99468085\n",
      " 0.99490248 0.99490248 0.99512411 0.99512411 0.99534574 0.99534574\n",
      " 0.99556738 0.99556738 0.99578901 0.99578901 0.99601064 0.99601064\n",
      " 0.99623227 0.99623227 0.9964539  0.9964539  0.99667553 0.99667553\n",
      " 0.99689716 0.99689716 0.99711879 0.99711879 0.99734043 0.99734043\n",
      " 0.99756206 0.99756206 0.99778369 0.99778369 0.99800532 0.99800532\n",
      " 0.99822695 0.99822695 0.99844858 0.99844858 0.99867021 0.99867021\n",
      " 0.99889184 0.99889184 0.99911348 0.99911348 0.99933511 0.99933511\n",
      " 0.99955674 0.99955674 0.99977837 0.99977837 1.         1.        ]\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.00320513e-04\n",
      " 2.00320513e-04 2.00320513e-04 2.00320513e-04 2.00320513e-04\n",
      " 2.00320513e-04 2.00320513e-04 2.00320513e-04 2.00320513e-04\n",
      " 2.00320513e-04 2.00320513e-04 2.00320513e-04 2.00320513e-04\n",
      " 2.00320513e-04 2.00320513e-04 2.00320513e-04 4.00641026e-04\n",
      " 4.00641026e-04 4.00641026e-04 4.00641026e-04 4.00641026e-04\n",
      " 4.00641026e-04 6.00961538e-04 6.00961538e-04 6.00961538e-04\n",
      " 6.00961538e-04 8.01282051e-04 8.01282051e-04 8.01282051e-04\n",
      " 8.01282051e-04 8.01282051e-04 8.01282051e-04 8.01282051e-04\n",
      " 8.01282051e-04 8.01282051e-04 8.01282051e-04 8.01282051e-04\n",
      " 8.01282051e-04 1.00160256e-03 1.00160256e-03 1.00160256e-03\n",
      " 1.00160256e-03 1.00160256e-03 1.00160256e-03 1.20192308e-03\n",
      " 1.20192308e-03 1.40224359e-03 1.40224359e-03 1.60256410e-03\n",
      " 1.60256410e-03 1.80288462e-03 1.80288462e-03 1.80288462e-03\n",
      " 2.00320513e-03 2.00320513e-03 2.20352564e-03 2.20352564e-03\n",
      " 2.40384615e-03 2.40384615e-03 2.60416667e-03 2.60416667e-03\n",
      " 2.80448718e-03 2.80448718e-03 3.00480769e-03 3.00480769e-03\n",
      " 3.20512821e-03 3.20512821e-03 3.40544872e-03 3.40544872e-03\n",
      " 3.60576923e-03 3.60576923e-03 3.80608974e-03 3.80608974e-03\n",
      " 4.40705128e-03 4.40705128e-03 4.60737179e-03 4.60737179e-03\n",
      " 4.80769231e-03 4.80769231e-03 5.00801282e-03 5.00801282e-03\n",
      " 5.20833333e-03 5.20833333e-03 5.60897436e-03 5.60897436e-03\n",
      " 5.80929487e-03 5.80929487e-03 6.00961538e-03 6.00961538e-03\n",
      " 6.20993590e-03 6.20993590e-03 6.41025641e-03 6.61057692e-03\n",
      " 6.61057692e-03 6.81089744e-03 6.81089744e-03 7.01121795e-03\n",
      " 7.01121795e-03 7.21153846e-03 7.21153846e-03 7.41185897e-03\n",
      " 7.41185897e-03 7.61217949e-03 7.61217949e-03 7.81250000e-03\n",
      " 7.81250000e-03 8.01282051e-03 8.01282051e-03 8.21314103e-03\n",
      " 8.21314103e-03 8.41346154e-03 8.41346154e-03 8.61378205e-03\n",
      " 8.61378205e-03 8.81410256e-03 8.81410256e-03 9.01442308e-03\n",
      " 9.01442308e-03 9.21474359e-03 9.21474359e-03 9.41506410e-03\n",
      " 9.41506410e-03 9.61538462e-03 9.61538462e-03 9.81570513e-03\n",
      " 9.81570513e-03 1.00160256e-02 1.00160256e-02 1.02163462e-02\n",
      " 1.02163462e-02 1.04166667e-02 1.04166667e-02 1.06169872e-02\n",
      " 1.06169872e-02 1.08173077e-02 1.08173077e-02 1.10176282e-02\n",
      " 1.10176282e-02 1.12179487e-02 1.12179487e-02 1.14182692e-02\n",
      " 1.14182692e-02 1.16185897e-02 1.16185897e-02 1.18189103e-02\n",
      " 1.18189103e-02 1.20192308e-02 1.20192308e-02 1.22195513e-02\n",
      " 1.22195513e-02 1.24198718e-02 1.24198718e-02 1.26201923e-02\n",
      " 1.26201923e-02 1.28205128e-02 1.28205128e-02 1.30208333e-02\n",
      " 1.30208333e-02 1.34214744e-02 1.34214744e-02 1.36217949e-02\n",
      " 1.36217949e-02 1.38221154e-02 1.38221154e-02 1.40224359e-02\n",
      " 1.40224359e-02 1.42227564e-02 1.42227564e-02 1.44230769e-02\n",
      " 1.44230769e-02 1.46233974e-02 1.46233974e-02 1.48237179e-02\n",
      " 1.48237179e-02 1.50240385e-02 1.50240385e-02 1.52243590e-02\n",
      " 1.52243590e-02 1.54246795e-02 1.54246795e-02 1.56250000e-02\n",
      " 1.56250000e-02 1.58253205e-02 1.58253205e-02 1.60256410e-02\n",
      " 1.60256410e-02 1.62259615e-02 1.62259615e-02 1.64262821e-02\n",
      " 1.64262821e-02 1.66266026e-02 1.66266026e-02 1.68269231e-02\n",
      " 1.68269231e-02 1.70272436e-02 1.70272436e-02 1.72275641e-02\n",
      " 1.72275641e-02 1.74278846e-02 1.74278846e-02 1.76282051e-02\n",
      " 1.76282051e-02 1.80288462e-02 1.80288462e-02 1.82291667e-02\n",
      " 1.82291667e-02 1.84294872e-02 1.84294872e-02 1.86298077e-02\n",
      " 1.86298077e-02 1.90304487e-02 1.90304487e-02 1.98317308e-02\n",
      " 1.98317308e-02 2.02323718e-02 2.02323718e-02 2.04326923e-02\n",
      " 2.04326923e-02 2.06330128e-02 2.06330128e-02 2.10336538e-02\n",
      " 2.10336538e-02 2.12339744e-02 2.12339744e-02 2.16346154e-02\n",
      " 2.16346154e-02 2.18349359e-02 2.18349359e-02 2.20352564e-02\n",
      " 2.20352564e-02 2.22355769e-02 2.22355769e-02 2.26362179e-02\n",
      " 2.26362179e-02 2.28365385e-02 2.28365385e-02 2.32371795e-02\n",
      " 2.32371795e-02 2.34375000e-02 2.34375000e-02 2.36378205e-02\n",
      " 2.36378205e-02 2.38381410e-02 2.38381410e-02 2.44391026e-02\n",
      " 2.44391026e-02 2.46394231e-02 2.46394231e-02 2.48397436e-02\n",
      " 2.48397436e-02 2.50400641e-02 2.50400641e-02 2.54407051e-02\n",
      " 2.54407051e-02 2.58413462e-02 2.58413462e-02 2.60416667e-02\n",
      " 2.60416667e-02 2.64423077e-02 2.64423077e-02 2.66426282e-02\n",
      " 2.66426282e-02 2.68429487e-02 2.68429487e-02 2.70432692e-02\n",
      " 2.70432692e-02 2.76442308e-02 2.76442308e-02 2.80448718e-02\n",
      " 2.80448718e-02 2.82451923e-02 2.82451923e-02 2.92467949e-02\n",
      " 2.92467949e-02 3.02483974e-02 3.02483974e-02 3.08493590e-02\n",
      " 3.08493590e-02 3.10496795e-02 3.10496795e-02 3.12500000e-02\n",
      " 3.12500000e-02 3.20512821e-02 3.20512821e-02 3.24519231e-02\n",
      " 3.24519231e-02 3.26522436e-02 3.26522436e-02 3.32532051e-02\n",
      " 3.32532051e-02 3.34535256e-02 3.34535256e-02 3.38541667e-02\n",
      " 3.38541667e-02 3.40544872e-02 3.40544872e-02 3.48557692e-02\n",
      " 3.48557692e-02 3.66586538e-02 3.66586538e-02 3.72596154e-02\n",
      " 3.72596154e-02 3.76602564e-02 3.76602564e-02 3.80608974e-02\n",
      " 3.80608974e-02 3.88621795e-02 3.88621795e-02 3.94631410e-02\n",
      " 3.94631410e-02 3.96634615e-02 3.96634615e-02 3.98637821e-02\n",
      " 3.98637821e-02 4.00641026e-02 4.00641026e-02 4.06650641e-02\n",
      " 4.06650641e-02 4.12660256e-02 4.12660256e-02 4.14663462e-02\n",
      " 4.14663462e-02 4.18669872e-02 4.18669872e-02 4.28685897e-02\n",
      " 4.28685897e-02 4.30689103e-02 4.30689103e-02 4.36698718e-02\n",
      " 4.36698718e-02 4.40705128e-02 4.40705128e-02 4.44711538e-02\n",
      " 4.44711538e-02 4.50721154e-02 4.50721154e-02 4.60737179e-02\n",
      " 4.60737179e-02 4.74759615e-02 4.74759615e-02 4.78766026e-02\n",
      " 4.78766026e-02 4.82772436e-02 4.82772436e-02 4.94791667e-02\n",
      " 4.94791667e-02 4.96794872e-02 4.96794872e-02 5.02804487e-02\n",
      " 5.02804487e-02 5.26842949e-02 5.26842949e-02 5.32852564e-02\n",
      " 5.32852564e-02 5.34855769e-02 5.34855769e-02 5.36858974e-02\n",
      " 5.36858974e-02 5.38862179e-02 5.38862179e-02 5.40865385e-02\n",
      " 5.40865385e-02 5.46875000e-02 5.46875000e-02 5.62900641e-02\n",
      " 5.62900641e-02 5.72916667e-02 5.72916667e-02 5.82932692e-02\n",
      " 5.82932692e-02 5.96955128e-02 5.96955128e-02 6.06971154e-02\n",
      " 6.06971154e-02 6.18990385e-02 6.18990385e-02 6.20993590e-02\n",
      " 6.20993590e-02 6.25000000e-02 6.25000000e-02 6.33012821e-02\n",
      " 6.33012821e-02 6.45032051e-02 6.45032051e-02 6.53044872e-02\n",
      " 6.53044872e-02 6.87099359e-02 6.87099359e-02 7.03125000e-02\n",
      " 7.03125000e-02 7.05128205e-02 7.05128205e-02 7.15144231e-02\n",
      " 7.15144231e-02 7.23157051e-02 7.23157051e-02 7.71233974e-02\n",
      " 7.71233974e-02 7.91266026e-02 7.91266026e-02 7.99278846e-02\n",
      " 7.99278846e-02 8.19310897e-02 8.19310897e-02 8.23317308e-02\n",
      " 8.23317308e-02 8.35336538e-02 8.35336538e-02 8.61378205e-02\n",
      " 8.61378205e-02 8.63381410e-02 8.63381410e-02 9.09455128e-02\n",
      " 9.09455128e-02 9.33493590e-02 9.33493590e-02 9.43509615e-02\n",
      " 9.43509615e-02 9.51522436e-02 9.51522436e-02 9.53525641e-02\n",
      " 9.53525641e-02 9.67548077e-02 9.67548077e-02 9.71554487e-02\n",
      " 9.71554487e-02 9.89583333e-02 9.89583333e-02 1.08373397e-01\n",
      " 1.08373397e-01 1.10176282e-01 1.10176282e-01 1.11578526e-01\n",
      " 1.11578526e-01 1.11778846e-01 1.11778846e-01 1.14583333e-01\n",
      " 1.14583333e-01 1.15184295e-01 1.15184295e-01 1.18790064e-01\n",
      " 1.18790064e-01 1.36217949e-01 1.36217949e-01 1.41225962e-01\n",
      " 1.41225962e-01 1.47035256e-01 1.47035256e-01 1.48437500e-01\n",
      " 1.48437500e-01 1.48838141e-01 1.48838141e-01 1.50040064e-01\n",
      " 1.50040064e-01 1.51241987e-01 1.51241987e-01 1.51442308e-01\n",
      " 1.51442308e-01 1.53044872e-01 1.53044872e-01 1.55649038e-01\n",
      " 1.55649038e-01 1.58052885e-01 1.58052885e-01 1.58653846e-01\n",
      " 1.58653846e-01 1.62259615e-01 1.62259615e-01 1.74278846e-01\n",
      " 1.74278846e-01 1.80689103e-01 1.81089744e-01 1.94911859e-01\n",
      " 1.94911859e-01 1.95112179e-01 1.95112179e-01 1.97115385e-01\n",
      " 1.97115385e-01 2.02123397e-01 2.02123397e-01 2.04927885e-01\n",
      " 2.04927885e-01 2.07131410e-01 2.07131410e-01 2.09334936e-01\n",
      " 2.09334936e-01 2.09935897e-01 2.09935897e-01 2.11738782e-01\n",
      " 2.11738782e-01 2.21554487e-01 2.21554487e-01 2.25160256e-01\n",
      " 2.25160256e-01 2.27363782e-01 2.27363782e-01 2.37179487e-01\n",
      " 2.37179487e-01 2.68229167e-01 2.68229167e-01 2.82051282e-01\n",
      " 2.82051282e-01 3.01482372e-01 3.01482372e-01 3.09695513e-01\n",
      " 3.09695513e-01 3.35937500e-01 3.35937500e-01 3.56370192e-01\n",
      " 3.56370192e-01 3.62580128e-01 3.62580128e-01 4.13261218e-01\n",
      " 4.13261218e-01 4.28485577e-01 4.28485577e-01 4.41706731e-01\n",
      " 4.41706731e-01 5.14423077e-01 5.14423077e-01 5.17628205e-01\n",
      " 5.17628205e-01 5.25841346e-01 5.25841346e-01 5.95953526e-01\n",
      " 5.95953526e-01 5.97756410e-01 5.97756410e-01 6.12780449e-01\n",
      " 6.12780449e-01 6.59254808e-01 6.59254808e-01 6.60256410e-01\n",
      " 6.60256410e-01 7.33774038e-01 7.33774038e-01 7.44991987e-01\n",
      " 7.44991987e-01 7.49799679e-01 7.49799679e-01 7.56810897e-01\n",
      " 7.56810897e-01 7.74038462e-01 7.74038462e-01 7.99479167e-01\n",
      " 7.99479167e-01 8.63181090e-01 8.63181090e-01 9.30689103e-01\n",
      " 9.30689103e-01 1.00000000e+00]\n",
      "846\n"
     ]
    }
   ],
   "source": [
    "fpr2, tpr2, threshold = metrics.roc_curve(all_test_labels.cpu(), \n",
    "                                  all_predicted_fake_probabilities.cpu(), pos_label = 1)\n",
    "\n",
    "print(tpr2)\n",
    "print((fpr2))\n",
    "print(len(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff98a52",
   "metadata": {},
   "source": [
    "# save TPR and FPR for auc roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72df20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprfprsavepath = output_savepath + experiment_name + ' AUC Values.csv'\n",
    "\n",
    "pd.DataFrame({'False Positive Rate': fpr2, 'True Positive Rate':tpr2, 'Threshold': threshold}).to_csv(tprfprsavepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a26f1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f333bc3b910>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(fpr2, tpr2, color='blue',  linewidth=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78e5a2",
   "metadata": {},
   "source": [
    "# save and plot training curves - train loss, val loss and val acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4206bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# fig.set_size_inches(15.5, 10.5)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "x_values = range(epochs)\n",
    "\n",
    "losses2 = torch.tensor(losses).cpu()\n",
    "vlosses2 = torch.tensor(vlosses).cpu()\n",
    "vacc2 = torch.tensor(vacc).cpu()\n",
    "\n",
    "ax.plot(x_values, losses2, color='blue',  linewidth=2, label='Training Loss' )\n",
    "ax.plot(x_values, vlosses2, color='red',  linewidth=2, label='Validation Loss')\n",
    "ax.plot(x_values, vacc2, color='green',  linewidth=2, label='Validation Accuracy')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plotsavepath = output_savepath + experiment_name + ' training curve values.csv'\n",
    "\n",
    "pd.DataFrame({'epochs': x_values, 'train loss':losses, \n",
    "              'validation loss': vlosses,\n",
    "             'validation accuracy': vacc}).to_csv(plotsavepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489cea",
   "metadata": {},
   "source": [
    "# save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e4b11ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsavepath = output_savepath + experiment_name + ' saved model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), modelsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93db63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d2885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f118576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
